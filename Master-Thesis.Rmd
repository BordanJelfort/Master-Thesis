---
title: "Master Thesis"
author: "Benedikt Berger"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document:
    toc: true
    toc_float: true
    toc_depth: 6
    mathjax: default
    css: style.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**Note:**

**a) Before you start first have a look at the README.txt file.**\
**b) The Input Parameters are specified at the start of chapter III!**

# I. Packages
Prior to starting, we first need to install and load all required packages (or in this case the "library") necessary for this Problem Set.\
This can be done by first executing the command 'install.packages("packagename", dependencies = TRUE)' and then 'library(packagename)' or 'require(packagename)'. **Therefore, only decomment and perform the following chunk if you never ran the code before and haven't installed/updated the packages yet.**

*Note: if you have to install all the packages first this might take a while (~15-30min).*

```{r, eval=FALSE}
### For data (retrival):
#install.packages("readr")
#install.packages("readxl")
#install.packages("openxlsx")

### For data manipulation:
#install.packages("dplyr")
#install.packages("tidyr")
#install.packages("data.table")
#install.packages("tidyverse")
#install.packages("Matrix")
#install.packages("reshape2")

### For time and date manipulaton:
#install.packages("quantmod")
#install.packages("xts")
#install.packages("lubridate")
#install.packages("scales")
#install.packages("purrr")
#install.packages("TSstudio")
#install.packages("RQuantLib")
#install.packages("timeDate")
#install.packages("feasts")
#install.packages("tsbox")
#install.packages("tseries")

### For the analysis:
## (i) For the implementation of the strategies:
#install.packages("TTR")
#install.packages("PortfolioAnalytics")
#install.packages("nlshrink")
#install.packages("ranger")

#install.packages("NMOF")
#install.packages("pbapply")
#install.packages("tidymodels")
#install.packages("caret")
#install.packages("parallel")
## (ii) For the evaluation:
#install.packages("ggplot2")
#install.packages("htmlTable")
#install.packages("patchwork")
#install.packages("gridExtra")
#install.packages("stargazer")
#install.packages("skimr")
#install.packages("kableExtra")
#install.packages("rpart")
#install.packages("rpart.plot")
```

```{r loadlib, echo=T, results='hide', message=FALSE, warning=FALSE}
# For data (retrival):
library(readr)
library(readxl)
library(openxlsx)

# For data manipulation:
library(dplyr)
library(tidyr)
library(data.table)
library(tidyverse)
library(Matrix)
library(reshape2)

# For time and date manipulaton:
library(quantmod)
library(xts)
library(lubridate)
library(scales)
library(purrr)
library(TSstudio)
library(RQuantLib)
library(timeDate)
library(feasts)
library(tsbox)
library(tseries)

# For the analysis:
## (i) For the implementation of the strategies:
library(TTR)
library(PortfolioAnalytics)
library(nlshrink)
library(ranger)

library(NMOF)
library(pbapply)
library(tidymodels)
library(caret)
library(parallel)
## (ii) For the evaluation:
library(ggplot2)
library(htmlTable)
library(patchwork)
library(gridExtra)
library(stargazer)
library(skimr)
library(kableExtra)
library(rpart)
library(rpart.plot)
```

# II. Data
## 2.1 Load All Required Data
All data has already been downloaded from Refinitiv Datastream and FRED (Federal Reserve Economic Data) in advance, so the data sets now only need to be imported into the working space. \
Our data set consists of two parts: (i) The historical return data of the ETFs under consideration and (ii) macroeconomic measures which are necessary for the machine learning (ML) model - the Random Forest.

### 2.1.1 Import Historical ETF Data
We start by reading in all the historical data of the ETFs. The values display the "Total Return Index" compiled by Refinitiv which corrects the ETF prices by stock splits, dividend payments and corporate actions. Hence, observations are less noisy which allows us to compile more precise returns.\
Note that (i) we already filtered for non-trading days when downloading the data from the Datastream by stating "X(RI)*IF#(X(P#S),NNA,ONE)" which marks non-trading days as negative values and (ii) that we converted the first row in Excel from the format "date" to "standard" because otherwise R doesn't adopt the dates correctly. Therefore, we need to perform some more data manipulation regarding the non-trading days later on.

```{r, warning=FALSE}
# Read Total Return Indices (RIs) and transform to xts-format:
ETFs <- read.xlsx("C:/Users/Berger/Documents/Studium/Master/5. Semester/Masterarbeit/Daten/ETFs/Data.xlsx", sheet = 1)
Dates <- as.Date(ETFs[,1], "%d.%m.%Y")
ETFs <- xts(ETFs[,-1], order.by = Dates)

# Assign the (short) ETF names to columns:
Names <- scan("C:/Users/Berger/Documents/Studium/Master/5. Semester/Masterarbeit/Daten/ETFs/ETFs Namen.txt", character(), sep = ",")
colnames(ETFs) <- Names

head(ETFs)
```

We can see that there are only NAs in the first five rows. This is not an issue though because the data starts at 1989-08-25. At this point of time no ETFs were launched yet. In subsection 2.3 we perform some data operations so that the data set begins at a later point in time.\
But before we get to the next subsection we need to import the rolling total costs (formerly "TER") for each ETF. This is important for the evaluation of the results w.r.t. the turnover. We extract the total costs p.a. for each ETF from the respective factsheets.

```{r, warning=FALSE}
# Import total costs per annum:
TER.pa <- c(0.5, 0.0945, 0.24, 0.06, 0.39, 0.39, 0.4, 0.39, 0.39, 0.4, 0.39, 0.39, 0.39, 0.39, 0.45, 0.35, 
            0.39, 0.39, 0.18, 0.18, 0.15, 0.15, 0.15, 0.19, 0.14, 0.49, 0.4, 0.7)/100
# Divide by 100 to get non percentage values
names(TER.pa) <- colnames(ETFs)

# Transform from annualized values to monthly costs:
TER.monthly <- sapply(TER.pa, function(x) round((1+x)^(1/12)-1, 7))

```

### 2.1.2 Import Macroeconomic Measures
Next, we load the macroeconomic index data which will be injected as features (= explanatory variables) into the Random Forest model later on. All the data except the risk free rate were downloaded from FRED (Federal Reserve Economic Data) (https://fred.stlouisfed.org/tags/series). Thereby, we also need to consider the reporting lags to avoid the look-ahead-bias. I.e. the lag between the occurrence of the new macro index and the official reporting (publication). This is important in the sense of the Efficient Market Hypothesis (EMH) because first after the reporting the information becomes public and thus relevant for investing purposes. Thereby, we also need to consider the reporting lags to avoid the look-ahead-bias. I.e. the lag between the occurrence of the new macro index and the official reporting (publication). This is important in the sense of the Efficient Market Hypothesis (EMH) because first after the reporting the information becomes public and thus relevant for investing purposes. Therefore, we are going to need to manually adjust (lag) some of the macro indices by the length of their reporting lag. For our purposes we will only shift the time series if for some macro index $i$ holds:

$$reporting\;lag_{\,i} > 1\;month$$

The reason for that is because later in our cleaning process (section 2.3.2) macro indices which are reported at the start of the month are assigned to the last trading day of the month (thus we automatically have a 4 weeks time lag for all macro variables). This (as well as the cause that we want a set of pre-selected, specific handful indicators [see overfitting section 2.4.4]) is also the reason why we can't just download an existing real-time data set like the one from Giannone, Reichlin, Small (2008) or Croushore and Stark (2001). Also these data sets often aren't as up-to-date as we need them to be. Furthermore, applying an own method like the Nowcasting method developed by Giannone et al (2008) or creating a real-time data set manually over several years like  Croushore and Stark (2003) did, would go beyond the limits of this thesis.\
In order to identify the indices which have a reporting lag > 1 month, we pass through two checks. First, we assume that if an index is reported on a daily or weekly basis, the reporting lag is smaller than one month. Second, for macro variables with a reporting frequency lower than one day (i.e. monthly or quarterly) we orient at the issued reporting lags on the website of the sources.\
The risk free rate is the one of the Website of Fama/French (https://mba.tuck.dartmouth.edu/pages/faculty/ken.french/data_library.html) since this seems to be the academic standard. Fama and French transform all the daily observations of one month to one monthly observation. Hence, taking the last observation (day) of each month from the daily values wouldn't include all the information and therefore give worse results. Also we need to divide the risk free rate by 100 because Fama/French state it in percent.\
Note that when the data is downloaded directly from FRED the observations are included in one xls-file but different sheets (i.e. different sheets for different time frames [i.e. monthly or quarterly]). Hence, we are reading them in separately according to their time frame. Also note, that the column headers were changed from a rather incomprehensible ID to more common names.\
Furthermore, the data is transformed into an xts object in this step since these allow us to refer to the observations with dates as indices (helpful for the data cleaning process and backtesting later on).

```{r, warning=FALSE}
## DATA FROM FAMA/FRENCH:
FF <- read.csv(file = "C:/Users/Berger/Documents/Studium/Master/5. Semester/Masterarbeit/Daten/Macro/Fama French Three Factor.CSV")
FF <- xts(FF[,-1], order.by = timeLastDayInMonth(ym(FF$X)))
FF$RF <- FF$RF/100

#*************************************************************************

## DATA FROM FRED:
# Indices with monthly observations:
Macro.M <- read_xls(path = "C:/Users/Berger/Documents/Studium/Master/5. Semester/Masterarbeit/Daten/Macro/Macro Data.xls", sheet = 2)
Macro.M <- xts(Macro.M[,-1], order.by = Macro.M$DATE)

# Indices with quarterly observations:
Macro.Q <- read_xls(path = "C:/Users/Berger/Documents/Studium/Master/5. Semester/Masterarbeit/Daten/Macro/Macro Data.xls", sheet = 3)
Macro.Q <- xts(Macro.Q[,-1], order.by = Macro.Q$DATE)

```

Before we start cleaning an manipulating the data set, lets adjust the observations by their reporting lag. We do this right at the beginning to lose as little information as possible when cleaning the data later on. Therefore, we first start with the monthly macro indices and then go on with the quarterly variables. We already identified all variables which need to be lagged manually by researching the individual reporting lags via the source websites. An associated table can be found in the Appendix.

**1. Monthly Macros:**

```{r, warning=FALSE}
# Select the variables that need to be lagged:
ad <- c("S&P CoreLogic Case-Shiller U.S. National Home Price Index","Monthly Supply of New Houses in the United States","Producer Price Index by Industry: Food Manufacturing","Producer Price Index by Industry: Pharmaceutical Preparation","Producer Price Index by Industry: Oil and Gas Field Machinery and","Producer Price Index by Industry: Semiconductor and Other Electronic","Producer Price Index by Industry: Total Manufacturing Industries","Producer Price Index by Commodity: All Commodities","Producer Price Index by Commodity: Industrial Commodities")

# Select the length of the lags:
l <- c(2,1,1,1,1,1,1,1,1)

# Lag the specific variables by the indicated length:
for(i in 1:length(ad)){
  Macro.M[,ad[i]] <- Lag(Macro.M[,ad[i]], k = l[i])
}

```

**2. Quarterly Macros:**

For the quarterly Macros we know that all lags need to be of the length one month. Hence, we just need to lag the index and not specific columns.

```{r, warning=FALSE}
# Lag the index by one month:
index(Macro.Q) <- index(Macro.Q) %m+% months(1)

```

## 2.2 Data Cleaning
The most important aspect of a successful analysis is to have a solid data basis - without a consistent and sophisticated data set the best analysis or algorithm will return flawed results. Therefore, in this step we perform some more checks upon the loaded data and remove/adjust problematic observations.

### 2.2.1 Clean Non-Trading Days in ETF Data
First, we need to replace negative values with NAs because when downloaded from Datastream non-trading days were marked as negative values. Second, even though we already removed non-trading days when downloading the historical ETF data from the Datastream, we manually check whether some holidays were missed. For this purpose, we use the function "getHolidayList(...)" from the package "RQuantLib".

```{r, warning=FALSE}
# Replace negative values with NAs:
tmp <- ETFs
ETFs <- xts(apply(ETFs, 2, function(x) replace(x, which(x<0), NA)), order.by = Dates)

# Manually check again for non-trading days and replace values with NA:
holidays <- Dates %in% getHolidayList("UnitedStates", from = Dates[1], to = Dates[length(Dates)])
# If there are days on which values are reported, replace them with NA:
ETFs[holidays == T,] <- NA

```

### 2.2.2 Clean and Check for NAs
The data goes back further than there are observations. Hence, we need to remove those unnecessary observations. At this point we also need to consider that some ETFs exist longer than others (e.g. launch date of "S&P 500 TRUST" (1993-01-29) versus launch date of the "Gold Shares" (2004-11-18)). The youngest ETF in our set "High Yield Corporate Bond" was launched on 2007-04-11. Note that for now, we cut all NA rows until the launch date of our youngest ETF for better comparability but later we will keep more rows and consider the youngest ETF later in the backtest for a more thorough evaluation of the strategies.\
Afterwards, let's quickly check if any issues occurred by replacing observations on non-trading days with NAs. Therefore, let's have a look at the number of NAs before and after cleaning for holidays.

```{r, warning=FALSE}
# Cut all dates before 2007-04-11 (dates before the launch of the oldest ETF):
first <- which(Dates == "2007-04-11")
tmp.nona <- tmp[first:nrow(tmp),]
tmp.na <- ETFs[first:nrow(ETFs),]

# The data set for all further analysis (return calculation, backtests, etc.) start from 2004-11-18 (launch date of the second youngest ETF [when the MSCI World ETF is disregarded]):
start <- which(Dates == "2004-11-18")
ETFs <- ETFs[start:nrow(ETFs),]

# Compare the number of NAs for all ETFs before and after cleaning for holidays:
na.count.nona <- colSums(is.na(tmp.nona))
na.count.nona
na.count.na <- colSums(is.na(tmp.na))
na.count.na <- data.frame(ETFs = names(na.count.na), NAs = na.count.na)

# Create barplot to compare number of NAs per ETF:
ggplot(na.count.na, aes(x=ETFs, y=NAs))+
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "NAs per ETF",
       x = "ETFs",
       y = "Number of NAs") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# For the MSCI World ETF: how many of the days of the NA-days are at the end of the month
length(which(which(is.na(tmp.na[,1])) %in% endpoints(tmp.na)[-1]))

```

From the results we can see, that almost all ETFs have the same number of missing values which indicates that the data cleaning regarding the non-trading days worked well. However, there is one outsider with 278 NAs - the MSCI World ETF which could be due to common data errors. Compared to the other ETFs which all have 195 and one with 200 NAs this is quite the difference. But this difference doesn't really impose an issue for two reasons: First, the MSCI World isn't included in the RF prediction model but is only used as part of the benchmarking strategies. Second, only 13 of these additional NAs occur at the end of the month (i.e. on the dates which are relevant for our analysis because we look at monthly data at the end of the month) and can be corrected easily by taking the day before the end of the last day of the month for the return calculation.

## 2.3 Data Manipulation
After we cleaned the data we now can start to work with it. Therefore, in this section we're going to edit the data so that it fits our analysis. The goal is to create data sets which suits well for the input for our backtest.

### 2.3.1 Calculation of Monthly and Cumulative Return Data
First of all, we need to compute the monthly historical returns of the ETFs because (i) we are interested in the long-term monthly analysis of the ETF portfolios and (ii) most macroeconomic measures are reported on a monthly basis. For that, we need to a) reduce the data set to the last days of each month and b) compute the monthly returns.\
*Note: For the computation of returns non-trading days, the observations from the last business day before the non-trading is considered.*

```{r, warning=FALSE}
## a) Only consider the last days of the month
ETFs.mon <- ETFs[endpoints(ETFs, on = "months"),]
# Next, let's find all dates where there is no data for all ETFs
NT.days <- index(ETFs.mon[which(rowSums(is.na(ETFs.mon)) == ncol(ETFs.mon)),])
# Find where these dates are in the daily ETF table:
NT.indx <- which(index(ETFs) %in% NT.days)
# Use the observations from the day before
use <- NT.indx-1
# Insert these observations into the monthly table
ETFs.mon[NT.days,] <- ETFs[use,]

# Now let's do the same for the remaining missing values:
na_indices_list <- lapply(1:ncol(ETFs.mon), function(x) {
  # Find the indices (dates) of NAs in the x-th column
  na_indices <- index(ETFs.mon)[is.na(ETFs.mon[, x])]
  return(na_indices)
})
# Find the ETFs where the remaining missing values are
NA.ETFs <- which(sapply(na_indices_list, function(e) !is_empty(e)))
# Save their dates where there are NAs:
for(i in 1:length(NA.ETFs)){
  NA.days <- na_indices_list[[NA.ETFs[i]]]
  NA.indx <- which(index(ETFs[,i]) %in% NA.days)
  use <- NA.indx-1
  ETFs.mon[NA.days,NA.ETFs[i]] <- ETFs[use,NA.ETFs[i]]
}
# One more case-specific adjustment:
ETFs.mon["2008-09-30",15] <- ETFs["2008-09-26",15]

# Now there are no more missing values after the launch of the youngest ETF
sum(is.na(ETFs.mon["2007-04-30:2024-08-26",]))

```

```{r, warning=FALSE}
## b) Compute the returns:
Ret <- ROC(ETFs.mon)
Dates.Ret <- index(Ret)

head(Ret)
```

Last but not least, let's create two more types of return data sets which might help our prediction model later on.

**1. Lagged returns:**

Therefore, we first compute the normal lagged returns with lags ranging from t-1 up to t-12 (one year). We do so, because in section 2.4.3 we show that returns that lay back further exhibit a larger autocorrelation with returns from time t.

```{r, warning=FALSE}
# Lags with lengths ranging from 1 month up to 12 months
Ret.lag1 <- lag.xts(Ret, k = 1)
Ret.lag2 <- lag.xts(Ret, k = 2)
Ret.lag3 <- lag.xts(Ret, k = 3)
Ret.lag4 <- lag.xts(Ret, k = 4)
Ret.lag5 <- lag.xts(Ret, k = 5)
Ret.lag6 <- lag.xts(Ret, k = 6)
Ret.lag7 <- lag.xts(Ret, k = 7)
Ret.lag8 <- lag.xts(Ret, k = 8)
Ret.lag9 <- lag.xts(Ret, k = 9)
Ret.lag10 <- lag.xts(Ret, k = 10)
Ret.lag11 <- lag.xts(Ret, k = 11)
Ret.lag12 <- lag.xts(Ret, k = 12)

```

**2. Cumulative returns:**

Furthermore, we implement a code to calculate the cumulative returns with a rolling window also ranging from one month up to 12 months. We do so because the cumulative performance of the ETFs over a certain time frame might be helpful to categorize the prediction for the next period (see section 2.4.3).

```{r, warning=FALSE}
# Cumulative Returns with rolling window ranging from 1 up to 12 months
cum.Ret1 <- rollapply(Ret, width = 1, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")
cum.Ret2 <- rollapply(Ret, width = 2, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")
cum.Ret3 <- rollapply(Ret, width = 3, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")
cum.Ret4 <- rollapply(Ret, width = 4, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")
cum.Ret5 <- rollapply(Ret, width = 5, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")
cum.Ret6 <- rollapply(Ret, width = 6, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")
cum.Ret7 <- rollapply(Ret, width = 7, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")
cum.Ret8 <- rollapply(Ret, width = 8, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")
cum.Ret9 <- rollapply(Ret, width = 9, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")
cum.Ret10 <- rollapply(Ret, width = 10, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")
cum.Ret11 <- rollapply(Ret, width = 11, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")
cum.Ret12 <- rollapply(Ret, width = 12, FUN = function(x) prod(1 + x) - 1, by = 1, fill = NA, align = "right")

```

### 2.3.2 Synchronize Dates of Return Data with Macroeconomic Data
Since we need standardized data set for our analysis (because only then the backtest can run flawlessly), we need to synchronize the ETF return data set with the macro data set. With respect to the dates, the macro sets follow the dates of the ETF returns data set because the performance analysis of resulting returns will be in the center of our analysis later on.\
Because the reporting frequencies of the macro indices are not exactly the same over the time (monthly and quarterly), we also need to synchronize the dates within the macro data set. Therefore, if an index is reported with a lower frequency than monthly (i.e. quarterly) the announced values are adopted for the months within the following reporting period (i.e. the months between the current report at time t and the next report at time t+1).\
But first of all let us synchronize the time frame of the monthly macro data with the one of the return table. I.e. in the macro table the date "2004-11-01" becomes "2004-11-30" (first observation in return table). This means the observations from the macro table, which are reported at the *start* of the month t are used at the *end* of month t!

```{r, warning=FALSE}
# Find the rows of the macro table which report the months that also occur in the return table
Macro.M.trans <- Macro.M[which(format(index(Macro.M), "%Y-%m") %in% format(Dates.Ret, "%Y-%m")),]
# Assign the dates of the return table to the macro table
index(Macro.M.trans) <- Dates.Ret
# Merge both tables
merged <- merge(Ret, Macro.M.trans, join = "left")

```

Next, we also need to synchronize the quarterly macro table which reports the (real) GDP, personal consumption expenditures and the noncyclical rate of unemployment. Thereby, the reported quarterly observations are adopted for the following time frame until a next quarterly value is reported. This ensures, that the newest quarterly observations are used.

```{r, warning=FALSE}
# First, select the subset of the quarterly macro table:
subs <- which(format(index(Macro.Q), "%Y-%m") %in% format(index(Macro.M.trans), "%Y-%m"))
subs <- c(subs[1]-1, subs)
Macro.Q.subs <- Macro.Q[subs,]

# Next, fill the months between the quarters with the most recent reportings:
tmp <- seq(start(Macro.Q.subs), as.POSIXct(end(Macro.M.trans)), by = "months")
tmp <- xts(, order.by = tmp)
Macro.from.Q.to.M <- na.locf(merge(tmp, Macro.Q.subs, all = T), fromLast = F)[-c(1:3),]
index(Macro.from.Q.to.M) <- index(Macro.M.trans)

# Merge both macro tables:
n1 <- colnames(Macro.M.trans)
n2 <- colnames(Macro.Q)
names <- c(n1,n2)
Macro <- merge.xts(Macro.M.trans, Macro.from.Q.to.M)
colnames(Macro) <- names

```

### 2.3.3 Data Checks and Cleaning Regarding the Macroeconomic Measures
Now where we synchronized our macro data set we need to check for data errors which might have occured while doing so. Therefore, we once more check if there are any anomalies regarding the missing values (NAs).

```{r, warning=FALSE}
# Find rows with NAs:
check.NA <- Macro[!complete.cases(Macro),]
count.NA <- colSums(is.na(check.NA))
count.NA <- data.frame(Macros = names(count.NA), NAs = count.NA)

# Create barplot to compare number of NAs per each macro measure:
ggplot(count.NA, aes(x=Macros, y=NAs))+
  geom_bar(stat = "identity", fill = "steelblue") +
  labs(title = "NAs per Macro Index",
       x = "Macros",
       y = "Number of NAs") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

*Note: If you look at the plot in a cropped window it might appear quite squashed. To have a more clear view just execute the chunk in the console after enlarging the window on the bottom right.*

There are two things we can notice: \
First, there is one variable which stands out with 5 NAs - the Consumer Price Index: All Items: Total for United States.\
Second, for 5 more variables there is one more missing value reported. For all NAs in this graph they only occur towards the end of the data set (from 2024-04-30 to the end). This is because the time frame of the macro measures follows the time frame of the ETF returns (and not the other way round). Since the ETF prices (resp. Total Return Indices) are reported on a more frequent basis than some macroeconomic measures this doesn't surprise us. Hence, we just cut the rows at the end where NAs occur. 

```{r, warning=FALSE}
# Cut NAs in last rows (from 2024-04-30 to the end [i.e. keep all values from 2004-11-30 to 2024-03-29]):
Macro <- Macro["2004-11-30::2024-03-29",]

# For all remaining NAs use the latest reported number:
Macro <- na.locf(Macro, fromLast = TRUE)

```

Next we also want the monthly percentage change of the macroeconomic variables. We have to compute them ourselves because when downloaded directly from FRED there are data errors. They occur because when the values of the measures change from negative to positive from month t-1 to t wrong values are calculated because they don't take the absolute value in the denominator. So let's do that.

```{r, warning=FALSE}
# Compute percentage change:
Macro.p <- Macro
for(i in 2:nrow(Macro)){
  for(j in 1:ncol(Macro)){
    Macro.p[i,j] <- (as.numeric(Macro[i,j])-as.numeric(Macro[i-1,j]))/abs(as.numeric(Macro[i-1,j]))
  }
}
names <- colnames(Macro)
names2 <- paste0("% ", names)
Macro <- merge(Macro, Macro.p)
colnames(Macro) <- c(names, names2)
Macro <- Macro[2:nrow(Macro),]

# Check if there are any NAs left:
sum(is.na(Macro))
```

Now we have both the nominal values and the percentage change and we can see that there are no NAs left in the data set of the Macro variables. \
Note that after we removed the last rows from the Macro set, we cannot forget to also adjust the ETF return data sets for the (non-) lagged and cumulative versions because both sets need to be perfectly synchronized. So let's do that:\
**1. Lagged returns:**

```{r, warning=FALSE}
# Also remove the last rows from the return data set (from 2024-04-30 to the end [i.e. keep all values from 2004-12-31 to 2024-03-29]):
Ret <- Ret["2004-12-31::2024-03-29",]
Ret.lag1 <- Ret.lag1["2004-12-31::2024-03-29",]
Ret.lag2 <- Ret.lag2["2004-12-31::2024-03-29",]
Ret.lag3 <- Ret.lag3["2004-12-31::2024-03-29",]
Ret.lag4 <- Ret.lag4["2004-12-31::2024-03-29",]
Ret.lag5 <- Ret.lag5["2004-12-31::2024-03-29",]
Ret.lag6 <- Ret.lag6["2004-12-31::2024-03-29",]
Ret.lag7 <- Ret.lag7["2004-12-31::2024-03-29",]
Ret.lag8 <- Ret.lag8["2004-12-31::2024-03-29",]
Ret.lag9 <- Ret.lag9["2004-12-31::2024-03-29",]
Ret.lag10 <- Ret.lag10["2004-12-31::2024-03-29",]
Ret.lag11 <- Ret.lag11["2004-12-31::2024-03-29",]
Ret.lag12 <- Ret.lag12["2004-12-31::2024-03-29",]

# To not stress the global environment too much let's save all of them in  a list:
Ret.LAG <- list(Ret.lag1,Ret.lag2,Ret.lag3,Ret.lag4,Ret.lag5,Ret.lag6,Ret.lag7,Ret.lag8,Ret.lag9,Ret.lag10,Ret.lag11,Ret.lag12)
rm(Ret.lag1,Ret.lag2,Ret.lag3,Ret.lag4,Ret.lag5,Ret.lag6,Ret.lag7,Ret.lag8,Ret.lag9,Ret.lag10,Ret.lag11,Ret.lag12)

# Assign Lags to colnames:
Ret.LAG <- lapply(c(1:length(Ret.LAG)), function(x){
  colnames(Ret.LAG[[x]]) <- paste0("L", x, " ", colnames(Ret.LAG[[x]]))
  Ret.LAG[[x]]
  })

```

**2. Cumulative returns:**

```{r, warning=FALSE}
# Do the same for the cumulative return data sets:
cum.Ret1 <- cum.Ret1["2004-12-31::2024-03-29",]
cum.Ret2 <- cum.Ret2["2004-12-31::2024-03-29",]
cum.Ret3 <- cum.Ret3["2004-12-31::2024-03-29",]
cum.Ret4 <- cum.Ret4["2004-12-31::2024-03-29",]
cum.Ret5 <- cum.Ret5["2004-12-31::2024-03-29",]
cum.Ret6 <- cum.Ret6["2004-12-31::2024-03-29",]
cum.Ret7 <- cum.Ret7["2004-12-31::2024-03-29",]
cum.Ret8 <- cum.Ret8["2004-12-31::2024-03-29",]
cum.Ret9 <- cum.Ret9["2004-12-31::2024-03-29",]
cum.Ret10 <- cum.Ret10["2004-12-31::2024-03-29",]
cum.Ret11 <- cum.Ret11["2004-12-31::2024-03-29",]
cum.Ret12 <- cum.Ret12["2004-12-31::2024-03-29",]

# To not stress the global environment too much let's save all of them in  a list:
CUM.ret <- list(cum.Ret1,cum.Ret2,cum.Ret3,cum.Ret4,cum.Ret5,cum.Ret6,cum.Ret7,cum.Ret8,cum.Ret9,cum.Ret10,cum.Ret11,cum.Ret12)
rm(cum.Ret1,cum.Ret2,cum.Ret3,cum.Ret4,cum.Ret5,cum.Ret6,cum.Ret7,cum.Ret8,cum.Ret9,cum.Ret10,cum.Ret11,cum.Ret12)

# Assign rolling window to colnames:
CUM.ret <- lapply(c(1:length(CUM.ret)), function(x){
  colnames(CUM.ret[[x]]) <- paste0("CUM", x, " ", colnames(CUM.ret[[x]]))
  CUM.ret[[x]]
  })

```

Let's do a last check if after all these adjustments and actions all dates (i.e. row indices) are in fact aligned.

```{r, warning=FALSE}
# Check if **all** dates from the significant tables are the same:
all(index(Macro) == index(Ret))

```

### 2.3.4 Merge Macro Table with the Fama/French Data
Last but not least, we shouldn't forget to merge the Fama/French data (including the risk free rate) with the Macro table. Since the data by FF don't have any missing values the only thing we have to be careful about is to merge correctly by the months. Therefore, we first subset the FF data set so it fits the Macro and Return set.

```{r, warning=FALSE}
# Use the correct subset:
FF <-  FF["2004-12-31::2024-03-31",]

# Show that there aren't in fact any missing values for the FF data:
sum(is.na(FF))

# Compare dimensions:
nrow(FF)
nrow(Macro)

```

We can see that the dimensions are the same which is good. But since the Return and Macro sets consider non-trading days and FF does not, we need to adjust the index days of the FF table. For that we first need to identify the months, with different days.

```{r, warning=FALSE}
# Find the months where the (last) days (of the month) aren't the same:
tmp <- index(Macro) %in% as_date(index(FF))
names(tmp) <- index(Macro)
which(tmp == F)

# Check if all months are the same:
all(format(index(Macro), "%Y-%m") == format(as_date(index(FF)), "%Y-%m"))

# Assign the correct days to the FF table:
index(FF) <- index(Macro)

```

Now that the FF table contains the correct indices (in the sense of dates), we can merge both tables.

```{r, warning=FALSE}
# Merge both tables and once more assign the correct variable names to the columns:
n1 <- colnames(Macro)
n2 <- colnames(FF)
names <- c(n1,n2)
Macro <- merge(Macro, FF)
colnames(Macro) <- names

```

From now on, all macro variables are within the Macro table. Hence, we can go on by analyzing some descriptive statistics.

## 2.4 Descriptive Statistics
In order to conduct a comprehensive empirical analysis we need to get a feeling for the underlying data. Therefore, it is important to (i) understand the data we are working with and (ii) to have a look at the descriptive statistics to get an insight into the challenges the data contains. The latter is especially important for time series data because can be decomposed into four components: trends, seasonality, cyclicality and irregular (unpredictable) patterns (see ACF & PACF).\
Financial data is known for being non-stationary (i.e. there is autocorrelation across time [i.e. the observation in t is correlated with the observation in t-k]) because to some degree it consists of all four time series components. From a statistical point of view we use ETFs in this thesis because (i) they often replicate larger indices which brings up the hypothesis that external macroeconomic variables are connected closer to these kinds of ETFs and thus can help explain some non-stationary components and (ii) the consideration of complete industries and sectors rather than e.g. single stocks reduces the possibility of cross-sectional correlation.\
Furthermore, ETFs provide the advantage that they are accessible to private investors while providing high performance (often with wide-spread diversification) (beating over 90% of all actively managed funds) and very little costs.

### 2.4.1 General Summary and Outliers
There are several helpful tools in R to get a good first look at your data. One of them is the "skim"-function from the package "skimr". It returns information about the (monthly) mean and sd as well as the percentile returns (p0 [minimum], p25 ,p50 [Median], p75, p100 [maximum]) and the implied distribution (see column "hist") of returns. Furthermore, we are going to compute some individual measures like the Z-score (to identify outliers) or the Sharpe Ratio to get a picture that is even more complete. We will first take a look at the statistics of the return data and then the macro observations.

**1. Return Data:**

For the Return Data we manually add five more indicators: the annualized return, standard deviation, Sharpe Ratio and the Value at Risk as well as the monthly Maximum Drawdown. The numbers are calculated not upon the shorter backtest time frame but the whole data set ranging from 2004-12-31 until 2024-03-29. The functions "VaR" for the Value at Risk and "maxDrawdown" for the Maximum Drawdown computation come from the sophisticated package "PortfolioAnalytics".

```{r, warning=FALSE}
# Non time-series specific overview:
Ret.overview <- skim(Ret)

# Add annualized return, standard deviation, Sharpe Ratio and Value at Risk as well as the monthly Maximum Drawdown:
RF.ann <- (1+mean(Macro$RF))^12-1
Ret.overview <- Ret.overview %>%
  mutate(Ret.ann = (1+numeric.mean)^12-1) %>%
  mutate(SD.ann = numeric.sd * sqrt(12)) %>%
  mutate(SR.ann = (Ret.ann-RF.ann)/SD.ann) %>%
  mutate(VaR.ann = abs(as.numeric(VaR(Ret, p = 0.95, method = "historical")))*sqrt(12)) %>%
  mutate(Max.Draw = as.numeric(maxDrawdown(Ret)))

Ret.overview

```

*Note: The path where you're saving the .xlsx-file to needs to be adjusted properly.*

Let's go through the results together step by step. But before we do that let's first write some more code to easily identify anomalies and outliers in the statistics.

```{r, warning=FALSE}
## For each variable show the min and max values:
cols <- c("numeric.mean", "numeric.sd", "numeric.p0", "numeric.p25", "numeric.p50", "numeric.p75", "numeric.p100" ,"Ret.ann", "SD.ann", "SR.ann", "VaR.ann", "Max.Draw")
Base.stats.ETFs.min.max <- Ret.overview %>%
  select(skim_variable, all_of(cols)) %>%
  pivot_longer(cols = -skim_variable, names_to = "metric", values_to = "value") %>%
  group_by(metric) %>%
  summarise(
    min_value = min(value, na.rm = TRUE),
    max_value = max(value, na.rm = TRUE),
    min_ETF = skim_variable[value == min_value],
    max_ETF = skim_variable[value == max_value])

## Find the months of the largest and smallest monthly losses (p0):
# Largest loss
print(c("largest p0", as.character(index(Ret[which.min(Ret[,as.character(Ret.overview[which.min(Ret.overview$numeric.p0),2])]),as.character(Ret.overview[which.min(Ret.overview$numeric.p0),2])]))))
# Smallest loss
print(c("smallest p0", as.character(index(Ret[which.min(Ret[,as.character(Ret.overview[which.max(Ret.overview$numeric.p0),2])]),as.character(Ret.overview[which.min(Ret.overview$numeric.p0),2])]))))

## Find the months of the largest and smallest monthly wins (p100):
# Largest win
print(c("largest p100", as.character(index(Ret[which.max(Ret[,as.character(Ret.overview[which.max(Ret.overview$numeric.p100),2])]),as.character(Ret.overview[which.max(Ret.overview$numeric.p100),2])]))))
# Smallest win
print(c("smallest p100", as.character(index(Ret[which.max(Ret[,as.character(Ret.overview[which.min(Ret.overview$numeric.p100),2])]),as.character(Ret.overview[which.max(Ret.overview$numeric.p100),2])]))))

## Find time frame of Maximum Drawdown of Financials ETF:
table.Drawdowns(Ret$Financials)

## Look for outliers via the Z-score:
outliers_zscore <- function(column, threshold = 3) {
  z_scores <- scale(column, center = TRUE, scale = TRUE)
  outliers <- column[abs(z_scores) > threshold]
  return(outliers)
}
apply(na.omit(Ret), 2, outliers_zscore)

Base.stats.ETFs.min.max

```

The skim function together with our manual calculations gives us a lot of information about the basic statistics of our ETFs.\
In the sections before, we already described the data procurement and cleaning process. Hence, it should be no surprise by now that only the MSCI World and High Yield Corporate Bond ETFs are the only ones which display more than one missing value (due to their later launch date) (compare columns n_missing and complete_rate in the table).\
The percentiles (p0, p25, p50, p75, p100) show the largest monthly losses up to the largest monthly gains for each ETF. When looking at p0 (largest losses of all ETFs), the largest loss among all assets was observed for the ETF replicating the energy index with -44.49%. Interestingly, this Drawdown wasn't observed after the invasion of Russia in the Ukraine and the resulting energy crisis but during the Covid crash in March 2020. The smallest monthly loss occured for the Y1-3 Government Bond ETF with -1.41% during the financial crisis in November 2007. Intuitively, one might suggest that the safest asset would be the Y20+ Government Bond ETF. However, the recent economic challenges (Covid, rising inflation, increasing interest, more and more global conflicts (like Ukraine, Middle East, tensions between China and Taiwan), etc.) caused inverse interest curves and declining trust in the economy (bc. of fear of a global recession) and (US-) Government overall. Therefore, the longer-term government bond ETFs became less attractive which is also displayed by the huge Maximum Drawdown of 49.62% for the Y20+ Government Bond ETF. Contrary, the Maximum Drawdown of the Y1-3 Government Bond ETF was only 5.39%. \
This observation, which goes against the intuition, undermines that classic historical trading approaches need to be reconsidered, because for them new patterns which act as an mirror-image to old behavior often arent't taken into account and thus deteriorate the over all portfolio return. Machine Learning approaches like Random Forests represent interesting new approaches which tend to deal better with such challenges (see Literature Review). \
Interestingly but not surprisingly this observation can be inverted for wins. The largest win was observed for Energy (26.92%) one month after it's largest loss, which implies that there was an overreaction by market participants that caused a "bounce-back" effect on 2020-04-30. The smallest monthly gain among all ETFs on the other hand was vice versa reported for the Y1-3 Government Bond ETF with 1.76% during the financial crisis on 2007-11-30. This suggests that investors wanted to hedge the downside risk for equities during that recession by investing in short-term US government bonds. \
Another way to look at outliers is to analyze the Z-Scores. The Z-Score provides insight not only about the nominal values but also into the mean and standard deviation (i.e. each observation gets normalized with the historic mean and sd). Hence, one can get a more general view about outliers. Still, one needs to watch out for two things: (i) the data must be (at least approximately) normally distributed and (ii) there shouldn't be too many really large outliers which might distort the mean and the sd and thus the Z-score. However, for our purposes we can accept (i) (see section 2.4.4) and (ii) shouldn't be such big of an issue since we have 232 data observations (rows) which should compensate for few outliers. The Z-Score is calculated as follows:

$$Z-Score_i = \frac{R_{t,i}-\mu_i}{\sigma_i}$$

Thereby, $R_{t,i}$ describes the return observation for asset $i$ at time t $\mu_i$ is the mean return and $\sigma_i$ is the standard deviation. So, the Z-Score sets each observation in relation (normalizes) with the own mean and sd. Next we set our threshold at 3. Each observation which exceeds this threshold gets savved as an outlier (i.e. each observation which is away more than three standard deviations from the mean). In our data set almost all outliers occur during phases of extreme market shocks (like the financial cirsis 2007-2009, the Covid-19 Crash in 2020 or the invasion of Russia into the Ukraine in Feb/March of 2022). This is a good indication that there are slim to none errors in our data set. This is not surprising because when compared to f.e. Yahoo Finance, the Datastream by Reuters Eikon provides a much higher data quality. Outliers that do not occur during these crash phases (like Biotechnology on 2016-01-29) can be attributed to sector specific market shocks. \
The column "hist" in the table describes the distribution of returns for all ETFs. For more information see section 2.4.4. \
For a thorough analysis it is important to look at the statistics in a normalized way. Hence, let's inspect the annualized values in context to the annualized volatility. Historically, the largest yearly return can be spotted for the Semiconductor ETF with 15.18%! Our benchmark the - the MSCI World ETF - only exhibits an annualized return of 9.28%. So why should we even take it as a benchmark? To answer this question we have to set the returns in relation to the risk. One central measure for that is the Sharpe Ratio. Divides the excess return by the volatility of the asset.

$$SR_i=\frac{R_{t,i}-R^f_t}{\sigma_i}$$

For the calculation we use the mean annualized values. Thereby, $R^f_t$ is calculated with the risk-free rate from the Fama/French website.\
When we compare the Sharpe Ratios the MSCI World ETF has ha higher Sharpe Ratio (0.601) than the Semiconductor ETF (0.547) meaning the MSCI World ETF offers more return for less risk. However, if we compare the Technology or Healthcare ETFs with the MSCI World ETF, they do not only exhibit larger annualized returns with 14.11% and 10.72% but also higher Sharpe Ratios with 0.654 and 0.670. So once again the question - why should we take the MSCI World ETF as the benchmark? Well, risk is not only measured in volatility. Key figures like the Value at Risk (VaR) and Maximum Drawdown (MDD) contain a lot of information about longer term risk one should also definitely have a look at. They are defined as follows: \
*1. Value at Risk:*\
The VaR quantifies the maximum loss over a specific time period given for some confidence level (here: 95%). For example: the largest VaR in our data set (Energy ETF) is 42.84% meaning that for each year there is a 5% chance that the loss will be greater than 42.84% (resp. 95% chance that the loss will be smaller than 42.84%). In other words in one out of 20 years ($\frac{1}{5}*100$) the loss will be greater than 42.84%. The VaR can be computed with three different methods: (i) historical, (ii) Monte Carlo simulation and (iii) variance-covariance procedures. Here, we used the historical method. \
*2. Maximum Drawdown:*\
The MDD is defined as the maximum loss (maximum cumulative loss) a portfolio or asset presents from peak to lowest over a time frame until a new peak is reached. The largest MDD of all ETFs in this data set came from the Financials ETF with loss of 78.26% which occured during the financial crisis from 2007-06-29 until	2009-02-27 and took 129 months to recover from that. By the way, unsurprisingly, the smallest VaR and MDD were observed for the Y1-3 Treasury Bond ETF with 1.50% and 5.34%.\
We can see, that both the VaR and MDD can be regarded as a measure for (long-term) downside risk or tail risk for a portfolio or asset and is really important to look at. Furthermore, the VaR and MDD can not only be used as variables to identify assets not to buy but also to identify assets to short. Since we also consider a long-short strategy, these measures are helpful to analyze whether the short positions were entered "correctly". E.g. were positions for the Financial ETF taken during the correct time frame?\
But let's come back to the question why we use the MSCI World ETF as one of our benchmarks. Among all equity ETFs in our data set the MSCI World ETF provides both the smallest VaR and MDD (also smaller than Semiconductor and Healthcare). This is because the MSCI World ETF is more diversified (i.e. includes a wider range of assets from different industries, regions and investment strategies which lowers the overall cross-correlation between the assets and thus "hedges" against downturn risk) than specific sector focused ETFs and hence is protected better against long-term (external) market risks. Therefore, one could say that the MSCI World ETF provides the best best balance between return, intrinsic risk and (external) long-term risk. Hence, this will be one of our benchmarks.

**2. Macro Data:**

```{r, warning=FALSE}
# Non time-series specific:
Macro.overview <- skim(Macro)

# Look for outliers via the Z-score:
head(apply(Macro, 2, outliers_zscore)[sapply(apply(Macro, 2, outliers_zscore), length) > 0])
# Only display variables for which outliers could be found
```

When it comes to the macroeconomic measures, the reported numbers are more difficult (if not impossible) to compare in a nominal way because often the units are completely different. Therefore, the explanations regarding the Macro indicators have to mainly be done verbally. However, for Random Forests different units don't actually impose an issue since they are based on binary trees which categorize each variable by themselves (see Methodology). \
The idea is that the macro variables shall be used for the RF to build an economic framework on which predictions can be made more precisely. Therefore, (the percentage changes) of a broad set of different macro indices were downloaded. E.g. while bond yields reflect the cost of borrowing and the overall health of the credit market, manufacturing orders can act as a proxy for industrial activity and future output. Since economic key figures like inflation, GDP, unemployment rates, labor force participation, etc. set the economic conditions they also influence financial markets e.g. via corporate profits and investor sentiment. \
Furthermore, we include the three factors ([i] Market risk premium, [ii] size factor (SMB = Small Minus Big) and [iii] value factor (HML = High Minus Low)) and risk-free rate used by Fama/French in their three factor model. Not only are the three factors established and robust predictors of asset returns but they also capture different dimensions of market risk and return characteristics which might help within our prediction model by capturing systematic risk and cross-sectional variations. Also, the risk-free from the website of Fama/French is the 1-month Treasury Bill rate which also reflects other market criteria. Therefore, we're not only using $R_t^f$ to calculate excess returns but also as input for our RF prediction model. \
In addition, there is another thing we can notice when looking at the overview table. The distribution of the variables seem on a broader scale of distributions than the distribution of ETF returns (see column "numeric.hist"). This might be a good indication for the predictions made by our RF model because it means that there are a lot of different expressive opportunities to set the economic conditions. However, it remains to be questioned whether the RF is able to actually capture the *relevant* scenarios (i.e. combination of variables).\
When analyzing the (Z-Score) outliers more closely we can see that similary to the ETF returns they occur during crash phases or times when new government policies were released. This is a good indication that there are only few data errors. Please note that the data downloaded from FRED is not as reliable than the Total Return Indices from the Datastream and if the percentage changes are downloaded dircetly from the website there can be computational errors. However, it remains to be said that it has the advantage that it's open source. My personal experience when creating this macroeconomic data set was, that sometimes there are variables which e.g. only display ones or a lot of missing values. Therefore, pay attention when working with FRED!\
To summarize the thoughts regarding the Macro Data it can be said that it offers a rich set of macroeconomic variables some of them with different units, offering opportunities for a Random Forest model to uncover non-linear and complex relationships with ETF returns. However, challenges such as overfitting, data imbalance, multicollinearity, and non-stationarity must be addressed to ensure accurate predictions. We will do so in the next section.

### 2.4.2 Cross-Sectional Correlation Analysis
Next we are going to have a look at the cross-sectional correlations. Not only with regards to the ETF returns but also for the macro variables. This is an important issue which needs to be addressed because cross-sectional correlations or mulitcollinearity problems can impose quite the challenge to many models. First, we'll once again start with the Return Data of the ETFs:

**1. Return Data:**

For ETFs it is important to look at the cross-correlations in order to identify potential diversification effects. To get an impression of the characteristics of our return data set we are going to create a correlation plot.

```{r, warning=FALSE}
# Visualize the cross-correlations between the ETF returns:
corrplot::corrplot(cor(na.omit(Ret)))
```

At first glance, one can see that there seem to be two big groups of ETFs which differ in their cross correlation to each other. Thereby, equity ETFs belong to the first and bonds to the second group. While the correlations within these groups are quite large, the cross-sectional correlations between those groups appear to be low. Furthermore, there is one more ETF which seems to display a low correlation with all ETF - the Gold ETF. This is the case because it belongs to another asset class, namely commodities.

*Insertion: The first commodity ETF available on Datastream was launched quite late and thus provides not so much data. Hence, we use the Gold ETF as some kind of "proxy" of the commodity sector.*

It is no surprise that the correlations between (within) asset classes are quite low (high) (Kommer [2012]) because the ETFs between the groups have different underlying characteristics. This brings up the opportunity of portfolio diversification. Suppose two assets are negatively correlated (-0.8). Then, if asset A would go down by x%, asset B would go up by 0.8x% by some chance. If we assume an equally weighted portfolio the investor wouldn't have lost all x% but only 0.2x%. This might be highly simplified example but it illustrates the concept. Therefore, it is common practice for portfolio managers to "hedge" (diversify) the portfolio by including various asset classes. However, two problems that arise with this practice are: (i) the correlations during crash phases tend to rise (i.e. the protection might fall away to some degree) and (ii) it is a difficult task to weight the positions efficiently (but there are popular techniques [like Markowitz (1952)] to tackle this issue). \
When we take a closer look at the equity ETFs, we can see that especially for this group the cross-sectional correlations are quite large. This is not surprising, as the demand for equity also depends strongly on the general economic situation. In the summary statistics in section 2.4.1, however, we have already seen that the annualized returns among them can fluctuate from 2.33% to 15.18%. This is partly due to economic trends that change over time which need to be identified and partly because of sector specific developments. Furthermore, equity ETFs offer a higher Sharpe ratio compared to ETFs from the other asset classes (bonds and commodity) and can therefore be seen as a performance booster. \
This shows that equity ETFs can also offer great potential in portfolios like ours and that the exact combination of assets and asset classes is particularly important in terms of risk-adjusted performance.

**2. Macro Data:**

It is equally important to also look at the correlations of our Macro Data because they as input factors for the RF they will heavily influence the predictions and thus the performance results of our backtest. Since there are a lot of variables in our macro data set we are going to remove the names from the plot and focus more on the numbers. For our purposes it is crucial to identify the variables with large correlations to each other because duplicate variables might distort the RF and lower the prediction accuracy. The reason for this lies in the fact that RFs tend to interpret noise as real patterns when many variables show a high correlation to each other. This is called the "multicollinearity problem". \
At this point let me mention the following: RFs are able to handle a large number of variables very well since they only use a subset of the whole data set (usually 1/3) to generate one tree. However, when the number of variables becomes too large (in our case 180 [without lagged returns and cumulative returns], because we also use two lagged versions of our data set) the danger arises that there also might occur dimension-based overfitting.

```{r, warning=FALSE}
# Visualize the cross-correlations between the Macros:
corrplot::corrplot(cor(na.omit(Macro)), tl.pos = "n", cl.pos = "n")

```

*Note: Here, we filter the features ex-post because correlations change over time. In a real world application of the allocation process presented in this paper one would need to constantly calculate the correlations new and maybe with a shorter time frame (because of the EMH). Still, this shouldn't influence our results too much because correlations between macroeconomic factors tend to not change as much over time.*

We can detect that there are two blocks which exhibit really large positive or negative towards each other. The first block consists of the seven producer price indices from different sectors which makes sense. Interestingly, are all of them but one - the producer price index for semiconductors and other electronics - strongly positive correlated. The semiconductor index exhibits a strong negative correlation. In order to get a picture that is as holistic as possible, we are going to discard all producer price indices but the "semiconductor" and "all commodities" one. \
The second block shows up for the macros "(Real) Gross Domestic Product", "Real imports of goods and services","Personal Consumption Expenditures", "Net Exports of Goods and Services" and "Noncyclical Rate of Unemployment". This is because these are the macros that are reported on a quarterly basis. Since we took the latest for the months in between the reportings, the numbers don't change for all four macros during these months. Hence, the large correlation. However, the "Gross Domestic Product" and the "Real Gross Domestic Product" can be seen as kind of a duplicate. Therefore, we also remove the non-real GDP from the data set. Though this adjustment won't set the correlations of all variables to zero, it mitigates the most extreme multicollinearity problems. So let's do that:

```{r, warning=FALSE}
# Remove various Producer Price Indices and nominal GDP:
remove <- which(colnames(Macro) %in% c("Producer Price Index by Industry: Food Manufacturing", 
                                     "Producer Price Index by Industry: Pharmaceutical Preparation",
                                     "Producer Price Index by Industry: Oil and Gas Field Machinery and",
                                     "Producer Price Index by Industry: Total Manufacturing Industries",
                                     "Producer Price Index by Commodity: Industrial Commodities",
                                     "Gross Domestic Product"))
Macro <- Macro[,-remove]

```

Another point that is important to mention is that all the percentage changes seem to offer a correlation close to 0 which, however, isn't surprising but still a good sign with regards to the multicollinearity problem for Random Forests. In the next chapter we will see exactly why the correlation between time series of percentage changes exhibit a low correlation.

### 2.4.3 Time Series Analysis
In this section we will take a closer look at the time series specific features, including the autocorrelation of our data and their four components (trend, seasonality, cyclicality and irregular (unpredictable) pattern). Helpful functions for this purose are the funtion tsfeatures from the package tsfeatures and ts_summary from the package tseries. It helps getting a feel for the intrinsic components of the time series by providing an overview. \
The first question one should ask when starting to analyze a time series is, whether the time series is stationary or non-stationary. A time series is stationary if it doesn't include trends or seasonality. I.e. a stationary time series is one whose properties do not depend on the time at which the series is observed. The presumption is similar to the popular (static, non-time-series-) assumption that some variables are (log-) normally distributed. This means that ACF values can only be computed for stationary functions.
It is so important to get a feel for the data regarding the time series because in the end our backtest will be a time series based analysis. One central measure therefore is the autocorrelation or autocorrelation function (ACF). It measures for different time lags how the current values are related to older values. This can heavily influence the decision we'll have to make for our input data. Once again we are going to start by analyzing the time series characteristics of our Return Data.

**1. Return Data:**

First of all, we are going to test in how far the time series of returns (and the Total Return Index of ETFs) is stationary with the Augmented Dickey-Fuller Test. If the p-values are low, the time series is stationary on a certain confidence interval.\
Second, an overview about the time series is computed as well as the acf and other time series metrics (like trend, entropy, etc.).\
Third, we'll compare the mean autocorrelation with a lag of one month with the mean autocorrelation with a lag of 10 months.

```{r, warning=FALSE}
# 1. Check if time series is stationary (computes p-values of Augmented Dickey-Fuller Test):
rbind(do.call(cbind,lapply(c(1:ncol(Ret)), function(x){adf.test(na.omit(Ret[,x]))}))[4,])
rbind(do.call(cbind,lapply(c(1:ncol(ETFs.mon)), function(x){adf.test(na.omit(ETFs.mon[,x]))}))[4,])

# 2. Time-series specific overview:
#ts_summary(Ret)
TSret.overview <- tsfeatures::tsfeatures(Ret)
rownames(TSret.overview) <- colnames(Ret)
head(TSret.overview)

# 3. Compare means of one-month and ten-month autocorrelation:
paste0("mean e_acf1: ", round(mean(TSret.overview$e_acf1), 4), ", mean e_acf10: ", round(mean(TSret.overview$e_acf10), 4))
paste0("mean x_acf1: ", round(mean(TSret.overview$x_acf1), 4), ",mean x_acf10: ", round(mean(TSret.overview$x_acf10), 4))

```

The time series of returns is stationary, as indicated by the results of the Augmented Dickey-Fuller (ADF) test, which consistently yielded p-values below 0.01. This stationarity is favorable for further analysis. In contrast, the ETF.mon series (representing Total Return Indices) is non-stationary. As such, these indices cannot be directly analyzed without first being (seasonally) differenced to remove seasonal trends, a process commonly referred to as "decomposition." However, since the Total Return Indices do not play a direct role in our analysis, this issue is not relevant in this context. If a time series is already stationary further differencing would yield distorted results. Therefore, regarding the values of the return data set we focus on the columns like "e_acf" and "x_acf" but not the columns which start with "diff_..." since they first decompose the data before the autocorrelation is computed.

*Insertion: The columns with e_acfX describe the autocorrelation of residuals at lag X. I.e. after fitting an autoregressive model to the time series, the residuals are extracted, and the autocorrelation at lag 1 (ACF1) is calculated. In contrast the columns x_acfX describe the autocorrelation of the original time series at lag X (i.e. the "raw" autocorrelation).*

When looking at the mean values of the e_acf and x_acf we can see that in both cases the autocorrelation has risen from -0.0039 to 0.077 (resp. from 0.0167 to 0.0795). This means that in general returns are correlated more positively with returns 10 months ago than with the returns from the last month. I.e. if the returns were large 10 months ago, it is more likely that the returns will be also be large this month. We can learn from that, that it makes sense to also include lagged return data with greater lags and rolling cumulative returns in our Random Forest (calculation in section 2.3.1). \
Another observation we can make is when looking at the column "entropy". It describes the "purity" of the data and thus, at least to some degree, the predictability of the returns. The larger the values the more difficult they are to predict. Here, the entropy is one or close to one for all ETFs meaning that the returns seem to depend almost purely on random factors. This also makes sense when looking at the line plot of the ETF returns. Let's create a plot exemplary with the returns of the MSCI World ETF.

```{r, warning=FALSE}
# Create a line plot for the raw monthly returns of the MSCI World ETF
dates <- index(Ret)
plot.ret <- ggplot(Ret) +
  geom_line(aes(x = dates, y = `MSCI World`, color = "Returns")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual(" ", values = c("Returns" = "skyblue"))+
  labs(x = "Dates", y = "MSCI World ETF Returns")

# Compute the rolling Z-score (over the last 5 months) of the MSCI World
tmp <- as.data.frame(Ret) %>% 
  mutate(mean = rollapplyr(`MSCI World`, 5, mean, partial = T),
         sd = rollapplyr(`MSCI World`, 5, sd, partial = T)) %>% 
  mutate(rolling_Z = (`MSCI World` - mean) / sd)

plot.Z <- ggplot(tmp) +
  geom_line(aes(x = index(Ret), y = `rolling_Z`, color = "Z-Score")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual(" ", values = c("Z-Score" = "blue"))+
  labs(x = "Dates", y = "MSCI World ETF Z-Score")

# Arrange plots
plot.ret + plot.Z + plot_layout(ncol=1, guides = "collect")

# Look at the Z-Score time series charactersitics
head(tsfeatures::tsfeatures(tmp))

```

We can see that the sequence of returns (percentage changes) really seems to be random. I.e. the variance of the MSCI World ETF changes over time, meaning the error term is heteroskedastic which is to be expected with financial returns. So how can we expect to predict the returns correctly? Well for once we know from the literature that returns do not only depend on random factors but also (external) influences, which we hope to catch with the lagged ETF returns (see autocorrelation of lagged returns) and of course the macroeconomic features. Secondly, while these complex relationships between returns and multiple influences might be hard to capture, results from the past have shown that RF are quite performative in catching complicated cross-sectional connections. Thirdly, when we take a look at the rolling Z-score (over the last 5 months) of the returns they seem to be more stationary when compared to the raw returns and thus more appropriate as an input than the raw returns for predictions. This means that the Z-Scores might be able to normalize the returns, at least to some degree. Mueller-Glissmann, Ferrario (2024) also successfully use Z-Score transformed values as input for their RF (though they only used it upon Macro data). However, when looking at the specific time series characteristics of the rolling Z-Scores they still exhibit an entropy close to one or one. So, it remains to be answerd (via the Backtests) if the Z-Scores are superior when compared to the raw returns.

Also, while the entropy for the returns is quite high the entropy for the Total Return Indices is quite low and thus less random. So let's also have a look at the exemplary cumulative performance of the MSCI World ETF.

```{r, warning=FALSE}
# Create a line plot for the returns of the MSCI World ETF
dates <- index(ETFs.mon)
ggplot(ETFs.mon) +
  geom_line(aes(x = dates, y = `MSCI World`, color = "Value")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual(" ", values = c("Value" = "skyblue"))+
  labs(x = "Dates", y = "MSCI World ETF Value")

# Compute the time series summary of the Total Return Indices of all ETFs:
TStotalri.overview <- tsfeatures::tsfeatures(ETFs.mon)
rownames(TStotalri.overview) <- colnames(ETFs.mon)
TStotalri.overview

```

In the plot we can clearly recognize that now there is a clear component of and seasonality which is also confirmed for all other ETFs by the summary output. Especially when looked at in context of with the spike, linearity and curvature values it becomes clear that the cumulative performance definitely depends less on random values. This observation also gets confirmed for the Total Return Indices of all ETFs when looking at the entropy which is lower than 0.5 for all of them. Therefore, it might also makes sense to include the (lagged) Total Return Indices as input factor for our RF.
Next, we will continue with the same analysis for the macroeconomic data.

**2. Macro Data:**

```{r, warning=FALSE}
# 1. Check if time series is stationary (computes p-values of Augmented Dickey-Fuller Test):
rbind(do.call(cbind,lapply(c(1:ncol(Macro)), function(x){adf.test(na.omit(Macro[,x]))}))[4,])

# 2. Time-series specific overview:
head(ts_summary(Macro))
TSmacro.overview <- tsfeatures::tsfeatures(Macro)
rownames(TSmacro.overview) <- colnames(Macro)
head(TSmacro.overview)

# 3. Compare means of one-month and ten-month autocorrelation:
paste0("mean e_acf1: ", round(mean(TSmacro.overview$e_acf1), 4), ",mean e_acf10: ", round(mean(TSmacro.overview$e_acf10), 4))
paste0("mean x_acf1: ", round(mean(TSmacro.overview$x_acf1), 4), ",mean x_acf10: ", round(mean(TSmacro.overview$x_acf10), 4))
paste0("mean diff1_acf1: ", round(mean(TSmacro.overview$diff1_acf1), 4), ",mean diff1_acf10: ", round(mean(TSmacro.overview$diff1_acf10), 4))
paste0("mean diff2_acf1: ", round(mean(TSmacro.overview$diff2_acf1), 4), ",mean diff2_acf10: ", round(mean(TSmacro.overview$diff2_acf10), 4))

```

While the metrics of returns did not exhibit significant differences, a larger variation is immediately noticeable in the output for the macroeconomic indicators. Note that the difference in p-values (i.e. stationary vs non-stationary time series) is once again driven by whether we look at the nominal values or the percentage change. However, a commonality with the ETF returns lies in the fact that these indicators generally exhibit higher autocorrelations with more lagged values (see mean values of acf metrics [e_acf and x_acf for stationary and diff_acf for non-stationary data]). This suggests the logical conclusion that changing macroeconomic conditions tend to reflect with a delay in the financial market. For example, a decrease in demand (e.g., reflected in lower personal consumption expenditures) only reaches companies after a certain time lag. Conversely, changes in supply chain conditions or supplier prices also affect end-consumer prices with a delay (e.g., a rise in oil prices takes time before it is reflected at gas stations). At the same time, demand in financial markets (and consequently asset prices and returns) is heavily influenced by market participants' sentiment, which can be driven by the most current figures. Therefore, it is crucial that the Random Forest is fed with both current and lagged macroeconomic data. The expectation is that the Random Forest can identify and appropriately interpret the complex relationships between these indicators. In the past, machine learning models, particularly Random Forests, have proven to be highly valuable in this context.

### 2.4.4 Distribution of Returns
In this subsection we are going to have a closer look at the distributional characteristics of ETF returns. Therefore, we will create density plots for some representative ETFs and compute the (monthly) mean, skewness and excess kurtosis for them.

```{r, warning=FALSE}
# Create the distributional density plot of a subset consisting of representative equity ETF returns:
p1 <- ggplot(Ret) +
  geom_density(aes(x=`MSCI World`, fill = "MSCI World"), alpha = 0.4) +
  geom_density(aes(x=Semiconductor, fill = "Semiconductor"), alpha = 0.4) +
  geom_density(aes(x=Telecom, fill = "Telecom"), alpha = 0.4) +
  geom_density(aes(x=Financials, fill = "Financials"), alpha = 0.4) +
  geom_density(aes(x=Energy, fill = "Energy"), alpha = 0.4) +
  geom_density(aes(x=`Real Estate`, fill = "Real Estate"), alpha = 0.4) +
  scale_fill_manual(" ", values = c("MSCI World" = "blue", "Semiconductor" = "red", "Telecom" = "green", "Financials" = "purple", "Energy" = "grey", "Real Estate" = "yellow")) +
  labs(title = "Equity", x = "Returns", y = "Frequency") +
  theme(plot.title = element_text(hjust = 0.5, face ="bold"))

# Create the distributional density plot of the bond ETF returns:
p2 <- ggplot(Ret) +
  geom_density(aes(x=`Y1-3 Treasury Bond`, fill = "Y1-3 Treasury"), alpha = 0.4) +
  geom_density(aes(x=`Y7-10 Treasury Bond`, fill = "Y7-10 Treasury"), alpha = 0.4) +
  geom_density(aes(x=`Y20+ Treasury Bond`, fill = "Y20+ Treasury"), alpha = 0.4) +
  geom_density(aes(x=`Inv Grade Corporate Bond`, fill = "Inv Grade Corporate"), alpha = 0.4) +
  geom_density(aes(x=`High Yield Corporate Bond`, fill = "High Yield Corporate"), alpha = 0.4) +
  geom_density(aes(x=`Tips Bond (Inflation)`, fill = "Tips Bond (Inflation)"), alpha = 0.4) +
  scale_fill_manual(" ", values = c("Y1-3 Treasury" = "blue", "Y7-10 Treasury" = "red", "Y20+ Treasury" = "green", "Inv Grade Corporate" = "purple", "High Yield Corporate" = "grey", "Tips Bond (Inflation)" = "yellow")) +
  labs(title = "Bonds", x = "Returns", y = "Frequency") +
  theme(plot.title = element_text(hjust = 0.5, face ="bold"))

# Create the distributional density plot of the Gold ETF returns:
p3 <- ggplot(Ret) +
  geom_density(aes(x=`Gold Shares`, fill = "Gold"), alpha = 0.4) +
  geom_vline(aes(xintercept = mean(Ret$`Gold Shares`, na.rm = T)), color = "black", linetype = "dashed", size = 0.5) +
  annotate("text", x = mean(Ret$`Gold Shares`, na.rm = T), y = 0.02, label = paste("Mean =", round(mean(Ret$`Gold Shares`, na.rm = T), 2)), color = "black", vjust = -0.5, size = 3) +
  scale_fill_manual(" ", values = c("Gold" = "yellow")) +
  labs(title = "Gold Shares", x = "Returns", y = "Frequency") +
  theme(plot.title = element_text(hjust = 0.5, face ="bold"))

# Combine all plots in one:
plot.1 <- p1 + p2 + p3 & theme(legend.position = "bottom")
plot.1

# Compute monthly mean, skewness and excess kurtosis:
stats <- rbind(colMeans(na.omit(Ret)),skewness(Ret), kurtosis(Ret) - 3)
rownames(stats)[1] = "Mean"
stats

```

*Note: If you look at the legends in the plot they might appear quite squashed. To have a more clear view just execute the chunk in the console after enlarging the window on the bottom right.*

Upon examining the distribution curves, it becomes clear that the returns of the bond ETFs seem to most closely resemble a normal distribution. Thereby, the Y1-3 T Bond exhibits the most prominent peak (with a frequency of > 150), confirming our earlier observation that this bond consistently yields stable returns. Additionally, it is noteworthy that the distribution curve of Gold ETFs, despite their low correlation with all other ETFs, is comparable to that of some equity ETFs. However, due to this low correlation, such returns are not expected to occur simultaneously.\
Looking at the specific figures for the monthly average returns and skewness, it becomes apparent (unsurprisingly) that the mean of all monthly returns is positive. Notably, all ETFs, except the Treasury Bond ETFs, exhibit negative skewness. This indicates that most ETFs have a distribution curve with a long left tail, meaning that the majority of returns are concentrated to the right of the mean. In contrast, Treasury Bonds have a right tail (positive skewness), implying that most returns are left of the mean. However, despite this leftward skew, Treasury Bonds still generate positive returns, as their historically stable profits (despite their recent downfall) are more likely to fall within the positive return range rather than the loss range.\
Another metric that reflects the overall shape of the distribution curve is called excess kurtosis. A positive excess kurtosis indicates the presence of fat tails on both sides of the distribution (positive and negative returns), suggesting a higher likelihood of extreme profits or losses. Conversely, negative excess kurtosis describes thinner distribution curves with shorter tails (and a more "circular, round" shape), implying that extreme events are less likely. Unlike skewness, the results for excess kurtosis are more varied. For example, sectors like "Energy" and "Real Estate" exhibit positive excess kurtosis, as both sectors are prone to extreme gains as well as losses. Meanwhile, more stable ETFs, such as Treasury Bonds, unsurprisingly report negative excess kurtosis.\
So, what can we conclude from this analysis? While it is evident that all ETFs, on average, generate positive monthly returns (as assets tend to appreciate over time [Kommer 2012]), it is also clear that ETFs differ significantly in their intrinsic characteristics. The key question is whether our machine learning model can help us better understand the individual characteristics of each ETF, enabling us to make more accurate predictions. In other words, can we develop an investment strategy using AI that combines various ETFs in a portfolio to create a risk-return advantage for investors who would otherwise invest in a single ETF, such as the MSCI World?

## 2.5 General Words Towards the Data Set

For this section we are going to discuss and summarize the data generating process over all and explain the data structure of the final data sets. In total we generated two cleaned data sets. One for the ETFs (ETF returns) and one for the macroeconomic variables. Regarding the dimensions of the return data set, it comprises of 28 columns (ETFs) and 232 rows (months) ranging from 2004-12-31 until 2024-03-29. The data set with the macroeconomic measures consists of the same time frame (i.e. same number of rows) but 66 columns (variables). 28 of them describe the nominal macroeconomic indices, 34 the (monthly) percentage change of the initially downloaded variables and 4 of them are the risk free rate and three factors from Fama and French. Note that for the return data set the returns will be considered in a lagged manner in the Random Forest model later on. I.e., if we want to use the last 12 months of return data as input for our machine learning model we consider them as 12 separate independent variables.

We started by importing the daily Total Return Indices (RIs) for 28 US-focused ETFs each from uniquely different sectors from Reuters Eikon Datastream (section 2.1.1). Thereby, the ETFs were selected by two criteria: (i) they need exhibit a US-focus (according to their factsheets) regarding their assets and index which they replicate, (ii) for each sector/industry we include exactly one ETF and (iii) to obtain the most amount of data quantity, the oldest ETFs for each sector were chosen. Only data from the US is used for three reasons. First, to avoid decision-making and correlation-based overlap problematics when it comes to the portfolio construction (also see point (ii) from the sentence before). Second, the oldest ETFs worldwide come from the US. Therefore, the Datastream provides the qualitatively most sophisticated historical data for US-american ETFs which at the same time give us the most amount possible for the analysis regarding ETFs. Third, a lot of ETFs which state to be diversified globally actually demonstrate a great exposure w.r.t. US-based assets. Therefore, ETFs with a worldwide focus wouldn't contribute to diversification in the portfolio. On the contrary, they only would lift the overall portfolio correlation and thus lower the diversification effect. The only ETF included from another region is an emerging market ETF, since studies show that assets from emerging market display a low correlation with assets from industry nations. However, we also downloaded one MSCI World ETF as a benchmark which, however, won't be included in the tested strategies. A more precise description regarding the ETFs is provided in the Appendix of the thesis.

Next, we continued by importing the macroeconomic data set (section 2.1.2). Therefore, we downloaded our data from the FRED (Federal Reserve Economic Data). The advantage about the FRED database is, that it is open source and it provides 823,994 time series (as of: 24.06.2024). The difficulty for us is, to select the ones which are important for us. Therefore, it is especially important that the variables (i) have a high data quality, (ii) doesn't have too large cross-sectional correlations and (iii) aren't too many. The latter two points refers to the problem of overfitting which is also handled in section 2.4. After analyzing related literature, we downloaded 34 macroeconomic measures which you can look up in the Appendix. It is important to mention that 28 of them were reported on a monthly and four of them ("Gross Domestic Product",	"Real Gross Domestic Product",	"Personal Consumption Expenditures" and	"Noncyclical Rate of Unemployment") on a quarterly basis. \
Thereby, we also need to consider the reporting lags to avoid the look-ahead-bias. I.e. the lag between the occurrence of the new macro index and the official reporting (publication). This is important in the sense of the Efficient Market Hypothesis (EMH) because first after the reporting the information becomes public and thus relevant for investing purposes. Therefore, we are going to need to manually adjust (lag) some of the macro indices by the length of their reporting lag. For our purposes we will only shift the time series if for some macro index $i$ holds:

$$reporting\;lag_{\,i} > 1\;month$$

The reason for that is because later in our cleaning process (section 2.3.2) macro indices which are reported at the start of the month are assigned to the last trading day of the month (thus we automatically have a 4 weeks time lag for all macro variables). This (as well as the cause that we want a set of pre-selected, specific handful indicators [see overfitting section 2.4.4]) is also the reason why we can't just download an existing real-time data set like the one from Giannone, Reichlin, Small (2008) or Croushore and Stark (2001). Also these data sets often aren't as up-to-date as we need them to be. Furthermore, applying an own method like the Nowcasting method developed by Giannone et al (2008) or creating a real-time data set manually over several years like  Croushore and Stark (2003) did, would go beyond the limits of this thesis.\
In order to identify the indices which have a reporting lag > 1 month, we pass through two checks. First, we assume that if an index is reported on a daily or weekly basis, the reporting lag is smaller than one month. Second, for macro variables with a reporting frequency lower than one day (i.e. monthly or quarterly) we orient at the issued reporting lags on the website of the sources.

Furthermore, we included the three factors ([i] Market risk premium, [ii] size factor (SMB = Small Minus Big) and [iii] value factor (HML = High Minus Low)) as well as the risk-free rate from the website of Fama and French which is the 1-month Treasury Bill rate. We do so because the three factors are not only well established and robust predictors of asset returns but they also capture different dimensions of market risk and return characteristics which might help within our prediction model by capturing systematic risk and cross-sectional variations.

### 2.5.1 Data Cleaning and Manipulations

The basis of a good analysis rests on the quality of the data set. Hence, let's dive into how the data was cleaned and what further calculations were performed.

Before we calculated the monthly returns, we filtered the dates for non-trading and checked for missing values (sections 2.2.1 and 2.2.2). If any missing values in the daily data set are identified they are being replaced with the latest observation. While we controlled for non-trading days when downloading the RIs from Datastream (which is why we downloaded daily data [so we don't get missing values at the end of the month, which would downside our monthly data set significantly]) we also manually double checked them up in R with the function "getHolidayList" from the package "RQuantLib". After checking for any further missing values (NAs) we calculated the monthly returns (section 2.3.1). Therefore, we searched the last day for each months with the function "endpoints" from the package "xts" and then calculating the returns as usual.

Since the macroeconomic variables consist of different reporting time frames (monthly and quarterly) we first need to synchronize the dates (i.e. the number of rows), and thus the dimensions, correctly (section 2.3.2). For that, the dates of the macroeconomic set are aligned with the dates of the ETF returns. We do so because (i) the analysis of the return performance of our portfolio is located in the center of this thesis and (ii) shifting reported numbers of macros doesn't have such great of an impact as shifting ETF returns, since the latter vary a lot faster. Note that the observations from the macro table, which are reported at the *start* of the month t are used at the *end* of month t, meaning the macros are assigned to the end of the month.

If a macro index is reported quarterly the report at time t is also used for each months until the next report in t+1 and t+1. I.e. if the variable "Personal Consumption Expenditures" reports a value of 81.02 on 2005-01-31 the same value is used for the months 2005-02-28 and 2005-03-31 but not 2005-04-29 because then the next reporting is public. In section 2.3.3, the data set is scanned for any missing values which might emerged during all the customizations where any NAs get assigned with the latest reported value. Thereby, it becomes evident that there are some more missing values towards the end of the dataset. They occur because the macroeconomic measures have a slower reporting frequency than the ETF returns. Therefore, we cut the last five rows and get our final time frame from 2004-12-31 until 2024-03-29.

After merging the two tables we need also calculate the monthly percentage change for the macro variables manually (section 2.3.2). It is important to mention, that it is not wise to download the percentage change directly from FRED because then computational errors can occur when some variable changes negative to positive. My best guess is that they didn't divide by the absolute but the nominal value. Hence, it is important to manually calculate the change with the following equation.

$$p_t=\frac{x_t-x_{t-1}}{|x_{t-1}|}$$

$p_t$ denotes the percentage change on month t and $x$ the reported number on day $t$ and $t-1$.

Subsequently, we merge the Fama/French table with the "Macro" table in section 2.3.4, check if the dimensions stayed the same and if any new NAs emerged. Note that  Fama and French transform all the daily observations of one month to one monthly observation meaning that the numbers in their data set are the numbers at the end of the month.

In a last step we did one more filtering process. In section 2.4.2, 2. a cross sectional analysis was done on the macro data set to remove potential mulitcollinearity problems. The results showed that there were 6 variables which displayed either large positive (negative) correlation towards each other. These variables were the seven different Producer Price indices as well as the real and nominal GDP. For our macro data set we don't want this multicollinearity because otherwise we would have a redundant variables as input for our RF model. This in turn, would lead to the RF model tending to interpret noise as real patterns (overfitting) and thus achieving a lower prediction accuracy. Therefore, we remove 6 of those variables, keeping the Producer Price inices for "All Commodities" and "Semiconductors and other electronics" as well as the "Real GDP". Another reason for this cross-sectional analysis is, that if a data set includes a lot of variables this can lead to further overfitting. Although, RFs can handle large numbers of variables quite well, if we consider the lagged versions (with lags of 12 months) of both our sets (Ret and Macro) there can be up to 4776 observations per month (62x12+28x12x12).

### 2.5.2 Descriptive Statistics
*Outliers hier rein, da es dabei nichts zu cleanen gab*
(see section 2.4)

# III. Empirical Analysis
In this chapter all the necessary functions are defined and implemented into the backtest. Therefore, we first need to define some input parameters like the holding period (horizon), the transaction cost assumptions, etc.

**INPUT PARAMETERS:**

**1. ret:** Describes the (subset of) return data set with the ETFs whose returns we want to predict.

**2. bench:** Defines the benchmark we want to use. Pay attention that you use the correct column index (we use the first column [i.e. the MSCI-World ETF]).

**3. macro:** Represents the (subset of) macro data set.

**4. rf:** Store the monthly risk risk-free rate seperately.

**5. lag:** How much historical information of the ETF returns shall the Random Forest consider (if looback <- "all" then all available data up to point t is used). Also note that f.e. if lag == 5*12 initially the first 5 years aren't included in the backtest but only as the training set. This is done to insure a consistent (walk-forward) out-of-sample test.

**6. horizon:** How many months until the next rebalancing? I.e. the number of future months the RF needs to estimate. E.g. if horizon == 12 then the RF needs to estimate the cumulative return over the next 12 months.

**7. lookback:** If for overfitting reasons you don't want to also include the time series of every macro variable you can specify the lookback variable. It states how many past observations to use at maximum in order to compute the exponential moving average (EMA) of each macro variable. I.e. if lookback == 5*12 at max. the last 60 months are usedt to calculate the EMA at time t. Then, we don't have 60 more variables for each macro index at time t but one measure which summarizes all the information.

**8. train.perc:** Defines the size of the training data set in percent of the number of rows. I.e. if train.perc == 0.5, then 50% (0.5*232 = 116 months) of all rows are used to train the Random Forest initially.\
**Attention:** train.perc shouldn't be too small w.r.t. the variable "lag" and "horizon" because otherwise there is not enough data to train a forest for the first investment period over "horizon" months. For example, consider train.perc == 0.3 (meaning round(0.3x232) = 70 rows), lag == 5x12 == 60 time series observations (also rows) and horizon == 12. Then for the first iteration the RF runs into issues when trying to compute the 10-months ahead return (see inner workings of the RF-algorithm section 3.1.3.2) because at that point the training data set shrinked to only one observation! This is not sufficient to train a RF. Hence, the condition*

$$train.perc*N-lag\overset{!}{\ge}horizon+1$$

needs to strictly hold! Thereby, N is the number of rows of our cleaned data set. Note that a similar condition needs to be considered for the variable "limit".

**9. limit:** The variable limit narrows down (limits) the size of the walk-forward window. I.e. if limit == 5x12 then only the last 5 years (or 60 months) are used for the training data set (resp. calculation of the prevailing mean) in the RF return prediction. Furthermore, the variable also limits the historical window for the calculation of the variance-covariance matrix in the context of the minimum variance optimization. The idea behind that is that the influence of new observations isn't diminished in consideration of the percentage quantity of the new observations towards the whole data set. Note that if limit == NA no limit is set and all available data is used.\
**Attention:** Between the two variables "limit" and "lag" must lay at least "horizon + 1" months. Otherwise, the code will return an error. This is because for the last iteration (regarding the prediction of "horizon" months ahead) there will be only one row left if the exact distance between them is "horizon" (because for the predictions further than one month ahead in the future the indices of the training data set are adjusted by removing rows) which is not enough to train a model with the package ranger. For more information on why this is an issue take a look at the start of subsection 3.1.3.2. However, to generalize the statement from above, the condition in this case reads:

$$limit-lag\overset{!}{\ge}horizon+1$$

**10. trans.Z: ** If trans.Z is TRUE, then the monthly ETF returns are transformed with their rolling Z-Score over the last "last" months. This might be an interesting transformation to look at because in section 2.4.3 we showed that (rolling) Z-scores seem to make the time series more stationary.

**11. last:** This means that the variable "last" describes the rolling window for the Z-Score transformation (see the variable before). So, if last == 6 the Z-scores of the monthly ETF-returns are computed for the observations over the last 6 months.
  
**12. clusters:** Refers to the numbers of cores (of your CPU) R is allowed to use for the computation of the Random Forest predictions. It speeds up the process of predictions significantly because then the main apply-function usees more cores from your CPU and thus can perform multiple computations parallel to each other. For example: if clusters == 8 then 8 (logical) cores from your CPU are used which means that 8 tasks can be performed parallel to each other. Note, that you should consider leaving the command "clusters <- parallel::detectCores()" as it is because then you don't assign more cores than available to the computation task which could cause problems. Later the variable "clusters" is subtracted by one, because then the machine is less likely to crash, if you want to perform other tasks on the computer.

**13 tune_grid:** This variable defines the variables for the hyperparameter tuning of our Random Forest model. Therefore, the combinations of input parameters to try are determined in this variable (as table of combinations). If no hyperparameter tuning is desired train_control is set as NULL. However, if one wants to tune the hyperparameters the arguments are defined as follows:\
  *(i) mtry*: Number of variables randomly sampled as candidates at each split (for regression tasks [what we have here] this value is typically set around one third of all features). For our purposes the variable *split* (typically the number of features) defines around which value the number of splits shall be distributed.\
  *(ii) splitrule:* Describes the split rule for the regression trees. Here, we use the default "variance". The package "ranger" can apply various splitting rules like "variance", "extratrees", "max-stat" or "beta". Note that for classification or survival trees other splitting rules would be neccessary.\
  *(iii) min.node.size:* Refers to the minimum number of observations (or samples) that a node in a decision tree must contain in order to be considered for splitting. Thereby, lower min.node.size lead to more splits, deeper trees but potentially overfitting. Conversely, larger values for min.node.size lead to lesser splits, less deeper trees and potential underfitting (but reduced risk of overfitting).

**14. train_control:** Describes the resampling method to use. Thereby, "cv" stands for cross-validation with the argument "number" defining the number of folds (typically 5) and "search" describing how the tuning parameter grid is determined (we use "grid"). Note that applying cv on time series data can be an issue but Bergmeir et al. (2018) found that k-fold CV can actually be applied with time series models. But only if they are purely autoregressive. In other words, we can use k-fold CV on time series data, but only if the predictors in our model are lagged versions of the response which is the case in this thesis.\
When train_control is set to "trainControl(method = "none")" only one model is fit to the whole training data set no resampling method is used.\
**Attention:** setting parameters for tuning and resampling may lead to a significantly increased runtime!

**15. n.trees:** Sets the number of trees to create for each forest. This number is set to 500 by default.
 
**16. trans.costs:** Is a vector of numbers describing the transactions cost scenarios in basispoints (bps). Hence, the vector is divided by 10000 (conversion rate == 0.01%). Transaction costs are costs which occur when old assets (ETFs) in the portfolios are sold and new ones are bought. Depending on how often positions change in large numbers they influence the performance more or less. For example: If trans.costs == c(10,20,30) then the performance of the portfolio strategies is evaluated for transaction costs of 10, 20 and 30 bps. Note that the number of transaction costs can be set of transaction costs you want to analyze is not limited because the result vector gets created automatically.

**17. fix.tc:** Represents the percentage share of transaction costs which shall be considered as fixed. F.e. if fix.tc == 0.01 then 1% of the transaction costs (see variable "trans.costs") are independent from the size of position i in the portfolio and arise regardless of the weight (change) within the portfolio.

**18. VaR.CI:** Defines the confidence interval at what we want to evaluate the tail risks of the backtested portfolios. Within the functions this variable is set to 0.95 by default.

**19. use.long.only:** Refers to what upper share of the predicted ETFs shall be bought for the long-only portfolios. E.g. if use.long.only == 0.25 the top 25% ETFs are bought. Note that, if use.long.only == 1 no such selection is performed and all available ETFs are bought.\
**Attention:** When the use.long.only == 1 and the equal weight procedure is used, the return predictions are effectively ignored from a logical perspective.

**20. use.long.short:** Refers to the upper (lower) percentile of the predicted ETFs to be bought (sold) for the long-short portfolio. E.g. if use.long.short == 0.25 the predicted top (bottom) 25% ETFs are bought (sold). Note that use.long.short can be at max. 50%!

**21. disc.positive:** If disc.positive == TRUE, then the ETFs wiith a positive predicted return within the bottom 25% of the long-short portfolio are disregarded. Thereby, the whole invested money gets distributed on the remaining short positions (i.e. the short exposure rises). If no ETF has a predicted negative cumulative return for the next investment horizon, all money flows into the worst predicted ETF. By default this variable is set to FALSE.

**22. lend:** The variable "lend" is either 1 or 2 and describes whether 100% of the money should be invested  across all (long and short) positions [i.e. 50% long and 50% short] (1) or if money should be borrowed (2) so that the long position invests 100% and the short positions also 100%. To avoid too extreme exposures, this variable is to 1 by default.

**23. use.minvar:** Refers to what upper share of the predicted ETFs shall be bought for the long-only portfolios. E.g. if use.minvar == 0.25 the top 25% ETFs with the best predicted cumulative returns for the next investment hoorizon are bought. Note that, if use.minvar == 1 no such selection is performed and all available ETFs are bought.\
**Attention:** When the use.minvar == 1 the return predictions are effectively ignored from a logical perspective and the Minimum Variance procedure is performed on all available ETFs.

**24. min.max:** Is either "rank" or a numeric vector with two numbers between -1 and 1. F.e. if min.max == c(0,1) this means that we impose a long-only constraint (i.e. the minimum amount invested per position in the portfolio is 0 and the maximum 100%).\
**Attention:** The first number in the vector which describes the minimum amount per position to be invested might interfere with the number of ETFs in the portfolio. E.g. if min.max == c(0.3,1) than each ETF gets at minimum a weight of 30%. However, if the portfolio consists of 4 ETFs, then the max weight would be 4*30% = 120%. Since the side assumption of the Minimum Variance Optimization problem states that one has to invest 100% this would return an error in that case! I.e.

$$\frac{1}{N}\overset{!}{\ge} w_{max}$$

has to hold, in order for the code to throw no error!\
Also note, that rank-based weight constraints (min.max == "rank") can only be imposed if a predicted cumulative returns are available.\
Furthermore, it is important to consider that equally-weighted based weight constraints aren't possible to implement because if 1/N is defined is the maximum weight than each ETF in the portfolio automatically gets assigned the weight 1/N. This means that in this case we would just get the equally weighted portfolio.

**25. asset.classes:** Categorizes the specific ETFs in our data set to the respective asset classes. This becomes relevant when analyzing the exposures of the strategies against the asset classes. If asset.classes == NULL then no analysis regarding the asset classes is done.

**26. init:** The variable "init" describes the initial investment amount for the wealth development simulations (sections 3.1.4.8 and 3.4).

```{r, warning=FALSE}
ret <- Ret[,-1] # Remove MSCI World
bench <- Ret[,"MSCI World"] # MSCI World as benchmark
macro <- Macro[,-c(29:62)]
# Remove percentage changes to reduce risk of overfitting by reducing number of (time-series variables) and redundant information
rf <- macro$RF
lag <- 4*12
horizon <- 12
lookback <- 5*12
train.perc <- 0.5
limit <- 7*12
trans.Z <- FALSE
last <- 5
split <- round((lag+ncol(macro))/3,0) # set to 1/3 of all features
clusters <- parallel::detectCores()
tune_grid <- expand.grid(
  mtry = c(split-10, split-5, split, split+5, split+10),
  splitrule = "variance",
  min.node.size = c(1, 5, 10, 20)
)
# Alternatively:
tune_grid <- NULL
train_control <- trainControl(
  method = "cv",
  number = 5,
  search = "grid"
)
# Alternatively:
train_control <- trainControl(method = "none")
n.trees <- 1000
trans.costs <- c(10,20,30,40,50)/10000
fix.tc <- 0.01
VaR.CI <- 0.95
use.long.only <- 0.25
use.long.short <- 0.25
disc.positive <- FALSE
lend <- 1
use.minvar <- 0.25
min.max <- c(0,1) # Or "rank"
asset.classes <- list(equity = c("MSCI World","S&P 500 TRUST","S&P Midcap 400","S&P Smallcap","Technology","Financials","Telecom",
                                 "Basic Materials","Consumer Discretionary","Consumer Staples","Energy","Healthcare",
                                 "Industrials","Utilities","Biotechnology","Semiconductor","Transportation","S&P 500 Growth",
                                 "S&P 500 Value","Emerging Markets"),
                      real.estate = c("Real Estate"),
                      bonds = c("Y1-3 Treasury Bond","Y7-10 Treasury Bond","Y20+ Treasury Bond","Tips Bond (Inflation)",
                                "Inv Grade Corporate Bond","High Yield Corporate Bond"),
                      commodities = c("Gold Shares"))
init <- 1

```

## 3.1 Basic Functions
To ensure that the code runs as efficient as possible we first need to create basic individual helper functions. This is done because it is easier and more efficient to optimize smaller individual functions rather than improving the whole Analysis. Furthermore, this approach allows us to automize the software to a large degree. Later these functions are applied in the backtest to conduct the performance analysis.

### 3.1.1 Technical Helper Functions
First, let's start with some smaller atomic technical functions which are used for smart efficient workaround solutions and cannot be broken down further.\
**(i) "%notin%":**

The %in%-operator checks if an element *is* part of some vector. However, there is no such operator which examines whether the element *isn't* part of some vector. We need something like this for the evaluation of our portfolio strategies when it comes to the transaction costs. Specifically, we use this operator to identify which positions were discarded in our portfolio from one period to another to correctly and precisely compute the transaction costs with respect to the size of the positions (section 3.1.4.2). Hence, this is operator is defined in the following chunk:

```{r, warning=FALSE}
`%notin%` <- Negate(`%in%`)
```

*Note: Make sure that the path of the functions is set correctly.*

**(ii) "linshrink_cov2":**

For the Minimum Variance portfolio optimization one customization will be to used the shrinked covariance matrix (see Ledoit and Wolf [2004]). We do so because shrinkage aims to reduce the error term of the covariance matrix by pulling more extreme values. Therefore, we use the function from the package "nlshrink" written by Pratik Ramprasad. Thereby, I improved the linshrink_cov-function so now it takes an object which can contain NAs. Hence, it returns more precise colMeans which in turn leads to a more accurate shrinkage estimator.

```{r, warning=FALSE}
source("C:/Users/Berger/Documents/Studium/Master/5. Semester/Masterarbeit/Code/linshrink_cov2.R")
```

*Note: Make sure that the path of the functions is set correctly.*

**(iii) "Z.TRANS":**

The function Z.TRANS computes the rolling Z-scores over the last "last" months. This transformation can be used in order to decompose the return time series to make it more stationary (see section 2.4.3). It works to some degree because the Z-Score normalizes the returns w.r.t. their mean and sd and thus also w.r.t. their outliers.

```{r, warning=FALSE}
Z.TRANS <- function(ret, Names, last){
  
  ret.Z <- as.data.frame(ret) %>%
    # Compute mean
    mutate(across(everything(), ~ rollapplyr(.x, last, mean, partial = TRUE), .names = "mean_{.col}")) %>%
    # Compute SD
    mutate(across(everything(), ~ rollapplyr(.x, last, sd, partial = TRUE), .names = "sd_{.col}"))
  
  # Compute Z-Score
  ret.Z <- xts(do.call(cbind, lapply(1:ncol(ret), function(x){
    z_score <- (ret.Z[,x] - ret.Z[,(x+ncol(ret))]) / ret.Z[,(x+ncol(ret)*2)]
    return(z_score)
    })), 
    order.by = index(ret)
    )
  
  # Assign names
  colnames(ret.Z) <- Names[-1]
  ret.Z <- ret.Z[-c(1:2),]
  
  return(ret.Z)
}
```

### 3.1.2 Prevailing Mean Function
When developing a new investment strategy a central question regarding the predictive power of the model one needs to ask is whether the new strategy improves upon the simplest strategy possible - the prevailing mean. This strategy simply calculates the past return and uses them as the forecast for the next investment period. Subsequently, the RMSE and MAE of the both models are compared. This is a common approach in asset pricing literature. Fama and French also used this technique when evaluating their models.\
In order to conduct all the calculations we need a function to extract the training and thus also the out-of sample window for each point in time t from our input parameters. This is done in the function "Train.Rows" in subsection 3.1.3.1 for the Random Forest model. Since the training and test windows are the same for both models we are going to use the same functions for the windows.\
Like the RF-function the following Prevailing Mean prediction model returns the performance predictions for all ETFs for the specific months as well as the predicted cumulative performance over the investment horizon. Note that both, the RF as well as the Prevailing Mean function return their results in a list. A list is an R-object which allows us to store multiple tables, data frames, matrices, vectors, etc. in one place.

```{r Prevailing Mean, warning=FALSE}
PREVAILING.MEAN <- function(ret, horizon, train.rows, limit = NA, counter = 1, mean.ret.mon.all, mean.ret.cum.all, y_test){
  
  # Create list to store all results:
  if(counter == 1){
    mean.ret.mon.all <- matrix(data = NA, nrow = nrow(y_test), ncol = ncol(ret))
    colnames(mean.ret.mon.all) <- colnames(ret)
  }
  
  # Adjust horizon if it's the last iteration:
  if((counter+horizon-1) > nrow(y_test)){
    horizon <- nrow(y_test) - counter + 1
  }
  
  # Adjust training data set accordingly to the training frame:
  if(is.na(limit)){
    tmp <- ret[train.rows,]
  }
  if(!is.na(limit) && limit > length(train.rows)){
    tmp <- ret[train.rows,]
  }
  if(!is.na(limit) && limit < length(train.rows)){
    tmp <- ret[train.rows[(length(train.rows) - limit + 1):length(train.rows)],]
  }
  
  # Compute mean monthly return:
  res.mon <- lapply(1:ncol(tmp), function(x){
    mean.ret.mon <- mean(tmp[,x], na.rm = T)
    return(mean.ret.mon)
  })
  res.mon <- do.call(cbind, res.mon)
  
  # Compute cumulative return over the horizon:
  n <- nrow(tmp)
  group_indices <- rep(1:ceiling(n / horizon), each = horizon)[1:n]
  tmp$group <- group_indices
  mean.ret.cum <- aggregate(. ~ group, data=tmp, FUN = function(x) prod(1 + x) - 1)
  mean.ret.cum <- mean.ret.cum[, -which(names(mean.ret.cum) == "group")]
  mean.ret.cum <- colMeans(mean.ret.cum)
  
  # Store all the results
  for(j in 1:ncol(mean.ret.mon.all)){
    mean.ret.mon.all[counter:(counter + horizon-1),j] <- res.mon[j]
  }
  mean.ret.cum.all <- rbind(mean.ret.cum.all, mean.ret.cum)
  
  # Update the index
  train.rows <- c(train.rows, c(train.rows[length(train.rows)]+c(1:horizon)))
  counter <- counter + horizon
  
  return(list(mean.ret.mon.all = mean.ret.mon.all, 
              mean.ret.cum.all = mean.ret.cum.all, 
              train.rows = train.rows, 
              counter = counter))
}
```

### 3.1.3 Random Forest Prediciton Functions
This section might be the most important one in the whole thesis. Here, we implement the functions which compute the Random Forest ETF return predictions for the forecast/investment horizon. Random Forests are a supervised machine learning method first introduced by Leo Breiman (2001) which models a large number (often 500) of binomial (regression) trees for some different independent training data sets (because of bagging [i.e. a form of bootstrapping]) and takes the mean of all regression trees with the lowest RMSE as the result. Hence, RF can be seen as some kind of "swarm intelligence". In many empirical analysis RF have proven that they are effective in reducing overfitting and improving predictive accuracy compared to single decision trees which is particulary interesting for our case since we include a lot of variables in our data set.\
Since, we also train the models with the macro indices we hope that the RFs catch some kind of "framework conditions" which in turn enables the prediction to make more precise forecasts when also considering past time series returns. On more technical information how the RF models are trained and tests out-of-sample in this thesis, have a look at subsection 3.1.3.2. But first, let's have a more general look on Random Forests.

Regression trees continuously predict outcomes by recursively partitioning the data space and fitting a simple model (often a constant) within each partition. In the case of this thesis the goal for each split within a tree is to minimize the RSS (residual sum of squares). To insure each tree is different, RFs use two different methods:

**1. Bagging:** Bagging is a procedure inspired by bootstrapping which means that the observations are re-selected and shuffled. I.e. that some observations in the bagging sample occur twice or more times while others don't occur at all (which then form the so called "out-of-bag" sample). Out-of-bag samples can then be used as validation sets to get unbiased predictions by only using unused observations for from the training data set. As you might guess, in order for this to work all the input variables need to be independent. **Therefore, it is essential to perform a thorough data cleaning process in advance - especially when working with time series data!**

**2. Random feature selection:** This means, that for each tree which is built only a random subset of the original set of features is used to compute each tree. Normally, the share of random features includes one third of the features in the original set. When a random subset is defined each node split is performed with the variable which minimizes the RSS. This is done by computing the RSS for each variable and choosing the variable for the split for which the RSS was the lowest. Hence, the optimization problem for each tree can be defined as

$$\min_{S_1,\,S_2}\Bigg\{\sum_{i \in S_1} (y_i-\overline{y}_{S_1})^2-\sum_{i \in S_2} (y_i-\overline{y}_{S_2})^2\Bigg\}$$

This means that we need to find a combination of subsets $S_1$ and $S_2$ which minimizes the RSS. To get a more visual understanding on how such a tree looks like, let's have look at a static simulation example .

```{r Tree Example, warning=FALSE}
set.seed(42) # Reproducible results

# Generate simulation data
n <- 100
x <- runif(n, 0, 10)
y <- 3 * x + rnorm(n, mean = 0, sd = 2)

# Create a data frame
data <- data.frame(x = x, y = y)

# Fit a regression tree
tree_model <- rpart(y ~ x, data = data)

# Print example tree
rpart.plot(tree_model)

set.seed(NULL) # Remove seed
```

When all trees are estimated, the mean of all predictions (for the given input values) across all trees is calculated to receive the overall result. This last step is called "aggregation".

To further enhance the performance of RFs there are we apply the most popular method:

**1. Hyperparameter tuning:** This technique is a critical tool to enhance the precision and accuracy of RF models. In this thesis hyperparameter tuning is applied for three parameters: the split size, the split rule ans the node size. Thereby, the split size determines the minimum number of samples required to split an internal node. Adjustments regarding this parameter affects the depth of the trees and the model's ability to capture data patterns.\
The split rule is another important hyperparameter that specifies the criterion for selecting the best split at each node. For regression trees/forests we are going to consider the variance split rule.\
Last but not least the node size refers to the minimum number of observations (or samples) that a node in a decision tree must contain in order to be considered for splitting. Thereby, lower node sizes lead to more splits, deeper trees but potentially overfitting. Conversely, larger values for min.node.size lead to lesser splits, less deeper trees and potential underfitting (but reduced risk of overfitting).\
For a given set of parameters, all possible combinations are then compared within a grid search (see cross-validation). This process aims to find the optimal combination of hyperparameters that yield the best performance metrics on the validation data sets. In the algorithm of this thesis the grid of hyperparameters is defined in the variable "tune_grid" (see start of chapter III [input parameters]).

**2. Cross-Validation:** The cross-validation (cv) procedure applies the grid search for the hyperparameter combinations defined in 1. to enhance the predictability of RF models. For this resampling method, the training data set is first divided into k folds (usually k=5). I.e. you receive k=5 training data sets each divided into k=5 subsets. For each performance estimation and testing run a different subset is chosen as the validation set. The different hyperparameters are then trained among the remaining subsets within each fold and tested upon the validation set of each fold. After the training and testing the RMSE for each fold is returned. Subsequently, for each group of hyperparameter combinations the mean RMSE is computed where the hyperparameter combination with the lowest RMSE is chosen.\
Note that applying cv on time series data can be an issue but Bergmeir et al. (2018) found that k-fold CV can actually be applied with time series models. But only if they are purely autoregressive. In other words, we can use k-fold CV on time series data, but only if the predictors in our model are lagged versions of the response which is the case in this thesis.\
In the algorithm we look at in here, the grid search method is defined via the variable "train_control" (see start of chapter III [input parameters]).

Regarding the concept and implementation inspiration was drawn from Manuel Tilgner (2019) who wrote two great articles on R-bloggers ("https://www.r-bloggers.com/2019/09/time-series-forecasting-with-random-forest/" and "https://www.r-bloggers.com/2019/11/tuning-random-forest-on-time-series-data/"). However, since here a more complex data set is considered many adjustments needed to be made to receive consistent out-of-sample results.

#### 3.1.3.1 Data Manipulation Functions
First we need to do a little more data processing so the RF works. Therefore, we need to define some functions which later will be applied in the context of the RF-prediction model.\
We start by adjusting our macros so they display not the raw time-series values but their Exponential Moving Averages (EMAs) with max. *lookback* months of data laying back for Macro variables. This is done because otherwise we would have 32*lookback more variables which would highly increase the risk of overfitting. Since RF consider variables not as time-series but as static data both the time-series of the ETFs (considering they are stationary) and the EMAs of the Macros can be combined with no issues.

**1. TRANS.MACRO:**

Note that the function uses at maximum *lookback* months of data to compute the EMA. I.e. if there are less observations available, not NAs are returned, but the EMA with all observations available up to the time t. For more information on why this transformation is done, have a look at the paragraph before. Regarding the calculation of the EMA we orient ourselves at the proposed formula by Chong et al (2014). However, since we look at real-world data, we add one degree of freedom to the smoothing ratio (weight) of the EMA. Hence, the formula of the EMA in our case looks like this:

$$EMA_{\,t}(n)=\left[\frac{2}{n+1}*\left(P_t-EMA_{\,t-1}(n)\right)\right]+EMA_{\,t-1}(n)$$

Thereby, $n$ describes the number of periods to look back. Hence, in our algorithm n is called "lookback". From this formula it becomes visible that more recent information flow in with a greater weight ($weight = \frac{2}{n}$). This formula is based on the idea of the Efficient Market Hypothesis (EMH) (i.e. newer data contains more information) and has its roots in the technical analysis (for traders), but with larger n it can also be applied for our purposes. Note that for the computation we use the function "EMA" of the package "TTR".

```{r Transform Macro Data, warning=FALSE}
TRANS.MACRO <- function(data, lookback){
  
  macro.ema <- lapply(data, function(x){
    ema_col <- rep(NA, length(x))
    
    for (i in seq_along(x)){
      # If not enough observations are available (to match *lookback*) use all remaining observations
      n_periods <- min(i, lookback)
      # Compute EMA
      ema_col[i] <- EMA(x[1:i], n = n_periods)[i]
      }
    
    return(ema_col)
    
    })
  # Transform list to xts data frame
  macro.ema <- do.call(cbind, macro.ema)
  macro.ema <- xts(macro.ema, order.by = index(macro))
  
  return(macro.ema)
  
}
```

**2.Train.Rows:**

Next, we need a function to specify the *initial* number of training rows for the training and test data set. Therefore, the following function creates a **vector** starting from one to the absolute number of training rows.

```{r Training Rows, warning=FALSE}
Train.Rows <- function(ret, train.perc){
  c(1:round(train.perc*nrow(ret), 0))
}
```

**3.Test_DS:**

Also, we need a function for our test data set (i.e. the data set we use to evaluate our performance statistics of the predictions). This set will be used in conjunction to the functions in subsection 3.1.4.4 to calculate the accuracy measures. Furthermore, Test_DS determines the time frame of the out-of-sample tests when evaluating the portfolio strategies!

```{r Test Data Set, warning=FALSE}
Test_DS <- function(ret, train.rows, horizon){
  
  # Actual monthly test values (returns)
  y_test <- ret[-train.rows,]
  
  # Actual cumulative test values (returns) over the investment horizon
  tmp <- y_test
  n <- nrow(tmp)
  group_indices <- rep(1:ceiling(n / horizon), each = horizon)[1:n]
  tmp$group <- group_indices
  # Compute cumulative return
  y_test.cum <- aggregate(. ~ group, data=tmp, FUN = function(x) prod(1 + x) - 1)
  # Remove the 'group' column
  y_test.cum <- y_test.cum[, -which(names(y_test.cum) == "group")]
  
  return(list(y_test = y_test,
              y_test.cum = y_test.cum))
}
```

**4. Train_DS:**

Within the RF prediction loop the training set must be adjusted continuously to get an out of sample walk forward test. Thereby, for each iteration the training set is extended by the new observations. If specified the function can also limit the window of the training data set. The idea behind that is that the influence of new observations isn't diminished in consideration of the percentage quantity of the new observations towards the whole data set.

```{r Training Data Set, warning=FALSE}
Train_DS <- function(ret, macro.ema, train.rows, lag, limit=NA){
  
  # If a limit is set we first need to check whether this limit is breached
  if(!is.na(limit) && limit < length(train.rows)){
    train.rows.tmp <- train.rows[(length(train.rows) - limit + 1):length(train.rows)]
  }
  if(!is.na(limit) && limit > length(train.rows)){
    train.rows.tmp <- train.rows
  }
  # If no limit is set do nothing
  if(is.na(limit)){
    train.rows.tmp <- train.rows
  }
  
  # For the last iteration
  if(!is.na(limit) && max(train.rows) >= nrow(ret)){
    train.rows.tmp <- c(min(train.rows):nrow(ret))[(length(train.rows) - limit + 1):length(train.rows)]
  }
  if(is.na(limit) && max(train.rows) >= nrow(ret)){
    train.rows.tmp <- c(min(train.rows):nrow(ret))
  }
  
  train <- ret[train.rows.tmp,]
  train.macro.ema.compl <- macro.ema[train.rows.tmp[-c(1:(lag-1))]]
  # -c(1:(lag-1)) is necessary so the indices are aligned correctly later when merging with x_train
  # --> Macro information from t is used to predict t+1
  # --> Specifically speaking the command "embed" shrinks down the training data set from N to N-lag
  # --> To insure a consistent training data set the above command is executed
  train.macro.ema <- train.macro.ema.compl[-nrow(train.macro.ema.compl),]
  # Cut last row because it is the month which needs to be predicted (i.e. t+1 and NOT t)
  
  ret.lagged <- lapply(c(1:ncol(ret)), function(x){
    embed(train[,x], lag + 1)
    # +1 is necessary because the LAST column is always lag == 0
  })
  
  ret.lagged <- lapply(ret.lagged, function(x){ 
    colnames(x) <- paste0("L", lag:0)
    return(x)
  })
  
  # We want to estimate the return in *lag* months (i.e. column 1 == response)
  y_train <- lapply(ret.lagged, function(x){x[,1]})
  # use all other (lagged) time series variables as features
  x_train <- lapply(ret.lagged, function(x){x[,-1]})
  # Also use macro information and store data with dates and as matrix
  x_train <- lapply(x_train, function(x){
    as.matrix(merge.xts(x, train.macro.ema))
  })
  
  # Test features (last available observation in our window) for our predictions over the next *horizon* months
  # Note: The last row can't just be selected by itself because otherwise we wouldn't consider all data correctly and the index would shift by one
  x_test <- lapply(1:length(ret.lagged), function(x){
    tmp <- c(ret.lagged[[x]][nrow(ret.lagged[[x]]),-ncol(ret.lagged[[x]])], train.macro.ema.compl[nrow(train.macro.ema.compl),])
    # Remove last column from ret.lagged because otherwise we would have one time-series observation too many
    tmp <- matrix(tmp, nrow = 1)
    colnames(tmp) <- colnames(x_train[[1]])
    return(tmp)
    })
  
  return(list(x_train,
              y_train,
              x_test,
              train))
  
}
```

#### 3.1.3.2 Random Forets Prediction Functions
Now this is where the magic happens. The following section produces the RF models which estimate the (cumulative) returns for the next *horizon* month(s). The function returns a list of results which contains all predicted monthly returns as well as the predicted cumulative (summed up) return performance over the next holding period (see variable "horizon"). Note that also the training rows and the counter (which is neccessary for the code to know in which iteration we are) are adjusted in here.

Regarding the inner workings of the function let me explain the process. First, for each iteration in the return prediction (section 3.2.2) the training set (for the following function) is created with the function "Train_DS" from the last chunk. For each iteration the the training set is extended by the latest past observations - this is called a "walk-forward-backtest". The function "Train_DS" also transforms the return data set (according to the variable "lag") so that the time series of returns are displayed in the columns rather than rows. This is an essential step, because it allows the RF to consider the time series observations as own variables. Since RF models aren't designed to perform time series predictions (but static forecasts) this is the only way to make the code work.

In a second step this training data set is passed into the "RANDOM_FOREST" function (which is initially created by the "Train_DS" function). For each ETF a RF is then trained to estimate the returns for the month in t+1, t+2, t+3, ..., until t+horizon. This is done in an iterative manner within a for loop. Within the loop for each iteration the training set is adjusted such that the last row of the explanatory variables (features) and the first row of the dependent variable (response) are discarded. If we consider Y as the return to be forecasted, x as the time-series returns (explanatory set 1) and m as the macro features (computed with the EMA [see section 3.1.3.1]) (explanatory set 2) (with horizon = 12 months for this specific example) then the process can be visualized as below.

**Iteration 1:**

$$\begin{equation}
Training\;Set_{\,Iteration\, 1} = 
\begin{pmatrix}
  Y_{t_6} & x_{t_5} & \cdots & x_{t_0} & m_{t_5}^1 & \cdots & m_{t_5}^M \\
  Y_{t_7} & x_{t_6} & \cdots & x_{t_1} & m_{t_6}^1 & \cdots & m_{t_6}^M \\
  \vdots  & \vdots  & \ddots & \vdots & \vdots & \ddots & \vdots\\
  Y_{t_{n+6}} & x_{t_{n+5}} & \cdots & x_{t_n} & m_{t_{n+5}}^1 & \cdots & m_{t_{n+5}}^M 
\end{pmatrix}
\end{equation}$$

We can see that the difference between column one (return for the next month [in-sample]) and two (first lagged return) is always equal to one! This means that the RF in this case is trained to forecast the return one month ahead. It is also important to understand that it holds $Y_{t_6}=x_{t_6}$ and so on which is conclusive with the walk-forward procedure we conduct. Furthermore, note that the macro variables which were computed with the exponential moving average are always from the same date as the first time-series feature x. I.e. for the non-time-series based macros we use the most recent information available.\
Note that in this example the last observation (current time) isn't $t_n$ but $t_{n+6}$ because otherwise we wouldn't look at a consistent out-of-sample test later on. Next, we continue by removing the first row of the response and last row of the feature set. Hence, the RF for the subsequent iteration gets trained with the following set.

**Iteration 2:**

$$\begin{equation}
Training\;Set_{\,Iteration\, 2} = 
\begin{pmatrix}
  Y_{t_7} & x_{t_5} & \cdots & x_{t_0} & m_{t_5}^1 & \cdots & m_{t_5}^M  \\
  Y_{t_8} & x_{t_6} & \cdots & x_{t_1} & m_{t_6}^1 & \cdots & m_{t_6}^M  \\
  \vdots  & \vdots  & \ddots & \vdots  & \vdots & \ddots & \vdots \\
  Y_{t_{n+6}} & x_{t_{n+5-1}} & \cdots & x_{t_{n-1}} & m_{t_{n+5-1}}^1 & \cdots & m_{t_{n+5-1}}^M
\end{pmatrix}
\end{equation}$$

**...**

**Iteration 12**

Now, the difference between column one (return for the next month [in-sample]) and two (first lagged return) is always equal to two! Therefore, the return for two months ahead is estimated. The number of iterations is therefore determined by the forecast horizon == 12 (see variable horizon).\
Note that the dimension of the training set shrinks from iteration to iteration. Specifically speaking this means, that the number of rows within the training data set reduces by the number of months in our investment horizon. For that reason, the difference between the two variables "limit" and "lag" must be at least "horizon + 1" months because otherwise there would be only one observation left for the last prediction. Hence, it is crucial to not set the variable limit too small because otherwise one won't get consistent, reliable, conclusive results or no results at all!

Regarding the R-function which actually estimates the RF models we are going to use the sophisticated packages "caret" and "ranger". Thereby, the function "train" from the package "caret" applies the "ranger" function from the package "ranger" which computes the models. We are using these two functions in conjunction because (i) they fit in our framework and (ii) this allows us to also perform hyperparameter tuning as well as cross-validation. There are a lot of other packages which enable functions for RF-predictions like "h2o", "randomForest" and "tidymodels". However, these functions often don't provide the variety of options or are complex to reliably set up (see h2o).

```{r Random Forest, warning=FALSE}
RANDOM_FOREST <- function(input, horizon, y_test, counter = 1, old.forecasts, cum.perf, tune_grid = NULL, train_control, clusters = NULL, limit, n.trees = 500){
  
  x_train <- input[[1]]
  y_train <- input[[2]]
  x_test <- input[[3]]
  train <- input[[4]]
  y_test <- y_test$y_test
  
  # Check if horizon is set correctly (i.e. if we are in the last iteration)
  if((counter+horizon-1) > nrow(y_test)){
    horizon <- nrow(y_test) - counter + 1
  }
  
  # Create lists to save the forecasts
  if(counter == 1){
    old.forecasts <- lapply(1:length(x_train), function(x){
      return(array(NA,dim = nrow(y_test)))
    })
    old.forecasts <- lapply(old.forecasts, function(x){
      names(x) <- index(y_test)
      return(x)
    })
    cum.perf <- lapply(1:length(x_train), function(x){
      return(NULL)
    })
  }
  forecasts_rf <- lapply(1:length(x_train), function(x){
    return(array(0,dim = horizon))
  })
  
  print(index(y_test[counter]))
  
  # If wished, create clusters for faster computation
  if(!is.null(clusters)){
    cl <- makeCluster(clusters-1) # Leave one core on leave
    
    # Necessary variables need to be exported to the "workers" (i.e. cores):
    clusterExport(cl, varlist = c("x_train", "y_train", "x_test","train_control", "tune_grid", "forecasts_rf", 
                                  "old.forecasts", "counter", "horizon", "limit","n.trees"),
                  envir = environment())
  }
  if(is.null(clusters)){
    cl <- NULL
  }
  
  # Random Forest prediction
  res <- pblapply(c(1:length(x_train)), function(x){
    
    # Check if any ETF still contains NAs and ignore them in the following
    if(!is.na(limit) && any(is.na(x_train[[x]]))){
      return(list(old.forecasts = old.forecasts[[x]], forecasts_rf = forecasts_rf[[x]]))
    }
    
    x_train_temp <- x_train[[x]]
    y_train_temp <- y_train[[x]]
    
    # Here the RF return prediction for the next holding period starts
    for(i in 1:horizon){
      
      train_data <- data.frame(y = y_train_temp, x_train_temp)
      
      # fit the model
      if(!is.na(limit)){
        fit_rf <- caret::train(
          y ~ ., 
          data = train_data,
          method = "ranger",          # Use the RF function from the package ranger
          metric = "RMSE",            # Use appropriate metric for regressions
          trControl = train_control,
          tuneGrid = tune_grid,
          num.trees = n.trees         # Number of trees per model
        )
      }
      if(is.na(limit)){
        fit_rf <- caret::train(
          y ~ ., 
          data = train_data,
          method = "ranger",          # Use the RF function from the package ranger
          metric = "RMSE",            # Use appropriate metric for regressions
          trControl = train_control,
          tuneGrid = tune_grid,
          num.trees = n.trees,        # Number of trees per model
          na.action = na.omit
        )
      }
      # predict using the test set
      forecasts_rf[[x]][i] <- predict(fit_rf, x_test[[x]])
      # here is where we repeatedly reshape the training data to reflect the time distance
      # corresponding to the current forecast horizon.
      # i.e. per iteration we shift the prediction horizon by one month
      y_train_temp <- y_train_temp[-1]
      x_train_temp <- x_train_temp[-nrow(x_train_temp), ]
    }
    
    # Store the results in the forecast vector:
    old.forecasts[[x]][counter:(counter+horizon-1)] <- forecasts_rf[[x]]
    return(list(old.forecasts = old.forecasts[[x]], forecasts_rf = forecasts_rf[[x]]))
    
  }, cl = cl) # Pass over the clusters
  
  # Stop clusters to keep CPU free
  if(!is.null(clusters)){
    stopCluster(cl)
  }
  
  # Extract the results
  old.forecasts <- lapply(res, `[[`, "old.forecasts")
  names(old.forecasts) <- colnames(y_test)
  
  forecasts_rf <- lapply(res, `[[`, "forecasts_rf")
  
  # Save the cumulative performance
  cum.perf <- lapply(1:length(forecasts_rf), function(x){
    c(cum.perf[[x]], prod(1+forecasts_rf[[x]], na.rm = T)-1)
  })
  names(cum.perf) <- colnames(y_test)
  
  # Update the indices
  train.rows <- c(train.rows, c(train.rows[length(train.rows)]+c(1:horizon)))
  counter <- counter + horizon
  
  return(list(old.forecasts = old.forecasts,
              forecasts_rf = forecasts_rf,
              cum.perf = cum.perf,
              train.rows = train.rows, 
              counter = counter))
  
}
```

### 3.1.4 Evaluation Functions
In this subsection all functions are defined which are necessary for some kind of evaluation or calculation.

#### 3.1.4.1 Turnover Function
This function computes the raw cumulative turnover, which is a measure  of how often positions within a portfolio are bought and sold in a portfolio. This measure is computed for all transaction cost scenarios (including the scenario of TC of zero!). Thereby, the turnover for each ETF is calculated like follows. First, for each point in time t (t = time of rebalancing) the Turnover of each ETF is calculated.

$$Turnover_{\,i,t}^{\,cum}= Turnover_{\,i,t-1}+{|\Delta}w_{i,t}|$$

Subsequently, all Turnovers are summed up to receive the portfolio Turnover.

$$Turnover_{\,Portfolio, t}^{\,cum} = \sum_{i=1}^nTurnover_{\,i,t}$$

Thereby, we consider all possible types of changes within the portfolio from the sale (purchase) of old (new) ETFs to the reweighting of ETFs which remain in the portfolio. Note, that this raw cumulative Turnover is later normalized (section 3.1.4.4) so the Turnovers become comparable across the different portfolio strategies.

```{r Turnover, warning=FALSE}
TURNOVER <- function(res.costs, ret.portf, weights, remPos, disc, newPos, old.portf){
  
  #print("Turnover")
  
  names(weights) <- colnames(ret.portf)
  
  ## CASE 1: There are new ETFs and some old ETFs got discarded
  # --> Compute TC for ETFs that we sold, as well as for ETFs that we newly bought
  # --> Also compute TC for ETFs that stayed in the portfolio but whose weights changed
  if(!identical(newPos, character(0)) && !identical(disc, character(0))){
    
    res.costs[2:length(res.costs)] <- lapply(2:length(res.costs), function(x){
      
      weights.disc <- res.costs[[x]]$`Weights towards the end of the horizon`[[length(res.costs[[x]]$`Weights towards the end of the horizon`)-1]][disc]
      weights.rem.old <- res.costs[[x]]$`Weights towards the end of the horizon`[[length(res.costs[[x]]$`Weights towards the end of the horizon`)-1]][remPos]
      res.costs[[x]]$Turnover <- res.costs[[x]]$Turnover + sum(abs(weights[remPos] - weights.rem.old)) + as.numeric(sum(abs(weights[newPos]))) + as.numeric(sum(abs(weights.disc)))
      
      return(res.costs[[x]])
    })
    # Turnover of no costs need to be considered separately because the old weights are assigned to another point in time
    # --> index to extract old weights shifted by +1 for weights of portf with no cost consideration
    weights.disc <- res.costs[[1]]$`Weights towards the end of the horizon`[[length(res.costs[[1]]$`Weights towards the end of the horizon`)]][disc]
    weights.rem.old <- res.costs[[1]]$`Weights towards the end of the horizon`[[length(res.costs[[1]]$`Weights towards the end of the horizon`)]][remPos]
    res.costs[[1]]$Turnover <- res.costs[[1]]$Turnover + sum(abs(weights[remPos] - weights.rem.old)) + as.numeric(sum(abs(weights[newPos]))) + as.numeric(sum(abs(weights.disc)))
  }
  
  ## CASE 2: There are new ETFs but no ETFs got discarded (sold)
  # --> Compute TC for weight changes
  # --> Also compute TC for ETFs that got bought additionally
  if(!identical(newPos, character(0)) && identical(disc, character(0))){
    
    res.costs[2:length(res.costs)] <- lapply(2:length(res.costs), function(x){
      
      weights.rem.old <- res.costs[[x]]$`Weights towards the end of the horizon`[[length(res.costs[[x]]$`Weights towards the end of the horizon`)-1]][remPos]
      res.costs[[x]]$Turnover <- res.costs[[x]]$Turnover + sum(abs(weights[remPos] - weights.rem.old)) + as.numeric(sum(abs(weights[newPos])))
      
      return(res.costs[[x]])
    })
    weights.rem.old <- res.costs[[1]]$`Weights towards the end of the horizon`[[length(res.costs[[1]]$`Weights towards the end of the horizon`)]][remPos]
    res.costs[[1]]$Turnover <- res.costs[[1]]$Turnover + sum(abs(weights[remPos] - weights.rem.old)) + as.numeric(sum(abs(weights[newPos])))
  }
    
  ## CASE 3: old portfolio ETFs = new portfolio ETFs 
  # --> Only compute TC for weight changes
  if(identical(newPos, character(0)) && length(old.portf)==length(weights)){
    
    res.costs[2:length(res.costs)] <- lapply(2:length(res.costs), function(x){
      
      weights.rem.old <- res.costs[[x]]$`Weights towards the end of the horizon`[[length(res.costs[[x]]$`Weights towards the end of the horizon`)-1]][remPos]
      res.costs[[x]]$Turnover <- res.costs[[x]]$Turnover + sum(abs(weights[remPos] - weights.rem.old))
      
      return(res.costs[[x]])
    })
    weights.rem.old <- res.costs[[1]]$`Weights towards the end of the horizon`[[length(res.costs[[1]]$`Weights towards the end of the horizon`)]][remPos]
    res.costs[[1]]$Turnover <- res.costs[[1]]$Turnover + sum(abs(weights[remPos] - weights.rem.old))
  }
  
  ## CASE 4: There are no new ETFs but some got sold 
    # --> Compute TC for weight changes
    # --> Also compute TC for ETFs that got discarded (sold)
    if(identical(newPos, character(0)) && length(old.portf)>length(weights)){
      
      res.costs[2:length(res.costs)] <- lapply(2:length(res.costs), function(x){
      
      weights.disc <- res.costs[[x]]$`Weights towards the end of the horizon`[[length(res.costs[[x]]$`Weights towards the end of the horizon`)-1]][disc]
      weights.rem.old <- res.costs[[x]]$`Weights towards the end of the horizon`[[length(res.costs[[x]]$`Weights towards the end of the horizon`)-1]][remPos]
      res.costs[[x]]$Turnover <- res.costs[[x]]$Turnover + sum(abs(weights[remPos] - weights.rem.old)) + as.numeric(sum(abs(weights.disc)))
      
      return(res.costs[[x]])
    })
    weights.disc <- res.costs[[1]]$`Weights towards the end of the horizon`[[length(res.costs[[1]]$`Weights towards the end of the horizon`)]][disc]
    weights.rem.old <- res.costs[[1]]$`Weights towards the end of the horizon`[[length(res.costs[[1]]$`Weights towards the end of the horizon`)]][remPos]
    res.costs[[1]]$Turnover <- res.costs[[1]]$Turnover + sum(abs(weights[remPos] - weights.rem.old)) + as.numeric(sum(abs(weights.disc)))
  }
  
  return(res.costs)
}
```

#### 3.1.4.2 Transaction Costs and TER Function
This function computes the returns for the portfolio strategies within the backtest under consideration of transaction costs and total rolling costs (ex. "Total Expense Ratio" TER). It gets applied in the return calculation function (section 3.1.4.3). In general, this function identifies the positional changes of the ETFs in the portfolio from one period to another (i.e. the weight changes regarding remaining, discarded and new ETFs) under consideration of weight developments during the holding period over "horizon" months. Subsequently, it computes the transaction costs on this basis.\
In order for the calculations to be performed correctly, we store the weights towards the end of the period for each portfolio and compare the positions of the ones from t-1 with the positions of the new portfolios in t. Afterwards, for each transaction costs scenario we differ between four cases to achieve consistent results:

*Case 1: There are new ETFs and some old ETFs got discarded (sold).*\
  --> Compute TC for ETFs that we sold, as well as for ETFs that we newly bought.\
  --> Also compute TC for weight changes of the remaining positions.

*Case 2: There are new ETFs but no ETFs got discarded (sold)*.\
  --> Compute TC for weight changes of the remaining positions.\
  --> Also compute TC for ETFs that got bought additionally.
  
*Case 3: Old portfolio ETFs = New portfolio ETFs*.\
  --> Only compute TC for weight changes ot the remaining positions.
  
*Case 4: There are no new ETFs but some got sold.*\
  --> Compute TC for weight changes of the remaining positions.\
  --> Also compute TC for ETFs that got discarded (sold)
  
Mathematically speaking we are applying three steps. First, we compute the monthly returns of each ETF i in our portfolio under consideration of the weighted **monthly** TER (total costs or Total Expense Ratio).

$$R_{i,t}^{After\,TER}=R_{i,t}-TER_{\,i,t}^{\,weighted}$$

With:

$$TER_{\,i,t}^{\,weighted}=w_{i,t}*TER_{\,i,t}^{\,unweighted}$$

Second, the monthly returns after transaction costs (TC) are calculated for each ETF i in our portfolio under consideration of the specific case we look at.

$$R_{\,i,t}^{\,After\,Costs}=R_{\,i,t}^{\,After\,TER}-TC_{\,i}^{\,weighted}$$

Where:

$$TC_{\,i}^{\,weighted}=|{\Delta}w_{i,t}|*TC$$

Thereby, $|{\Delta}w_{i,t}|$ is determined under consideration of the four cases (i.e. by comparing the (changed) positions and weights of the old portfolio and the ones from the new portfolio). Third, the monthly portfolio return is computed which is just the sum of the monthly weighted ETF returns after taking the costs into account.

$$R_{\,Portfolio,\,t}^{\,After Costs}=\sum_{i=1}^nR_{\,i,t}^{\,After\,Costs}$$

```{r Transaction Costs and TER, warning=FALSE}
TC.AND.TER <- function(ret.portf, portf, weights, trans.costs, TER.monthly, old.portf, t, fix.tc, res.costs){
  
  #print("Transaction costs")
  
  # Select which TER to use and assign the portfolio weights to them
  TER.portf <- TER.monthly[colnames(ret.portf)]
  TER.portf <- TER.portf*abs(weights)
  
  # Monthly weighted returns with TER for given period
  ret.mon.all.TER <- t(apply(ret.portf, 1, function(x){x-as.numeric(TER.portf)}))
  # Portfolio weighted returns for the given period
  ret.mon.portf.TER <- rowSums(ret.mon.all.TER, na.rm = T)
  ret.mon.portf.TER <- xts(ret.mon.portf.TER, order.by = as.Date(names(ret.mon.portf.TER)))
  
  ######## For the first iteration (whole transaction costs in the first month, no turnover consideration and creation of storage tables) ########
  
  if(t==1){
    
    # Create list to store the results with sublists (nested lists) for Returns, Weights and Turnover:
    res.costs <- lapply(c(1:(length(trans.costs)+1)), function(i){
      list(
        `Monthly Portfolio Return` = NULL,
        `Weights towards the end of the horizon` = list(),
        Turnover = 0
        )
      })
    
    # Compute returns and weights
    res.costs[2:length(res.costs)] <- lapply(c(1:length(trans.costs)), function(x){
    # "[2:length(res.costs)]" is necessary, because first entry is for zero costs and thus needs to stay empty
      
      # TC with consideration of weights and fixed percentage share of TC
      TC.costs <- weights*(1-fix.tc)*trans.costs[x] + trans.costs[x]*fix.tc
      ret.mon.all.TER[1,] <- ret.mon.all.TER[1,] - TC.costs
      
      # Monthly portfolio weighted returns (monthly sum of weighted ETF returns) for the given period and given TC
      ret.mon.portf.TER <- rowSums(ret.mon.all.TER, na.rm = T)
      ret.mon.portf.TER <- xts(ret.mon.portf.TER, order.by = as.Date(names(ret.mon.portf.TER)))
      
      # Cumulative return of the specific assets (ETFs)
      ret.cum.TER <- apply(ret.mon.all.TER, 2, function(x){ prod(1 + x, na.rm = TRUE) - 1 })
      
      # Value of the positions (weights) towards the end of the given period
      total.assets <- sum(abs(weights)*(1+ret.cum.TER))
      weights.new <- abs(weights)*(1+ret.cum.TER)/total.assets
      
      # Write results in result-list
      res.costs[[x+1]]$`Monthly Portfolio Return` <- rbind(res.costs[[x+1]]$`Monthly Portfolio Return`, ret.mon.portf.TER)
      res.costs[[x+1]]$`Weights towards the end of the horizon` <- append(res.costs[[x+1]]$`Weights towards the end of the horizon`, list(weights.new))
      
      return(res.costs[[x+1]])
    })
    
    # Assign names for levels of transaction costs
    names(res.costs)[1] <- "No costs"
    names(res.costs)[2:length(res.costs)] <- paste0(trans.costs*10000, "bps")
  }
  
  ######## For all other iterations (targeted transaction costs and turnover consideration) ########
  
  if(t!=1){
    
    # Check, which ETFs remained in the portf, which got discarded and which were newly added :
    remPos <- colnames(old.portf)[which(colnames(old.portf) %in% colnames(ret.portf))]
    disc <- colnames(old.portf)[which(colnames(old.portf) %notin% colnames(ret.portf))]
    newPos <- colnames(ret.portf)[which(colnames(ret.portf) %notin% remPos)]
    
    ## CASE 1: There are new ETFs and some old ETFs got discarded
    # --> Compute TC for ETFs that we sold, as well as for ETFs that we newly bought
    # --> Also compute TC for ETFs that stayed in the portfolio but whose weights changed
    #print("CASE 1")
    if(!identical(newPos, character(0)) && !identical(disc, character(0))){
      
      res.costs[2:length(res.costs)] <- lapply(c(1:length(trans.costs)), function(x){
      
        # 1. TC for discarded (sold) positions
        weights.disc <- res.costs[[x+1]]$`Weights towards the end of the horizon`[[length(res.costs[[x+1]]$`Weights towards the end of the horizon`)]][disc]
        TC.costs.disc <- sum(abs(weights.disc)*(1-fix.tc)*trans.costs[x] + trans.costs[x]*fix.tc)
        
        # 2. TC for new (bought) positions
        TC.costs.new <- abs(portf[,newPos])*(1-fix.tc)*trans.costs[x] + trans.costs[x]*fix.tc
        ret.mon.all.TER[1,newPos] <- ret.mon.all.TER[1,newPos] - TC.costs.new
        
        # 3. TC for remaining positions (consider weight changes)
        weights.rem.old <- res.costs[[x+1]]$`Weights towards the end of the horizon`[[length(res.costs[[x+1]]$`Weights towards the end of the horizon`)]][remPos]
        TC.costs.rem <- abs(weights.rem.old-portf[,remPos])*(1-fix.tc)*trans.costs[x] + trans.costs[x]*fix.tc
        ret.mon.all.TER[1,remPos] <- ret.mon.all.TER[1,remPos] - TC.costs.rem
        
        # Monthly portfolio weighted returns (monthly sum of weighted ETF returns) for the given period and given TC
        ret.mon.portf.TER <- rowSums(ret.mon.all.TER, na.rm = T)
        # Subtract sum of TC for discarded positions (from 1.)
        ret.mon.portf.TER[1] <-  ret.mon.portf.TER[1] - TC.costs.disc
        ret.mon.portf.TER <- xts(ret.mon.portf.TER, order.by = as.Date(names(ret.mon.portf.TER)))
        
        # Cumulative return of the specific assets (ETFs)
        ret.cum.TER <- apply(ret.mon.all.TER, 2, function(x){ prod(1 + x, na.rm = TRUE) - 1 })
        
        # Value of the positions (weights) towards the end of the given period
        total.assets <- sum(abs(weights)*(1+ret.cum.TER))
        weights.new <- abs(weights)*(1+ret.cum.TER)/total.assets
        
        # Write results in result-list
        res.costs[[x+1]]$`Monthly Portfolio Return` <- rbind(res.costs[[x+1]]$`Monthly Portfolio Return`, ret.mon.portf.TER)
        res.costs[[x+1]]$`Weights towards the end of the horizon` <- append(res.costs[[x+1]]$`Weights towards the end of the horizon`, list(weights.new))
        
        return(res.costs[[x+1]])
      })
    
      # Compute Turnover
      res.costs <- TURNOVER(res.costs = res.costs, ret.portf = ret.portf, weights = weights, remPos = remPos, disc = disc, newPos = newPos, old.portf = old.portf)
    
      # Assign names for levels of transaction costs
      names(res.costs)[1] <- "No costs"
      names(res.costs)[2:length(res.costs)] <- paste0(trans.costs*10000, "bps")
      
    }
    
    ## CASE 2: There are new ETFs but no ETFs got discarded (sold)
    # --> Compute TC for weight changes
    # --> Also compute TC for ETFs that got bought additionally
    #print("CASE 2")
    if(!identical(newPos, character(0)) && identical(disc, character(0))){
      
      res.costs[2:length(res.costs)] <- lapply(c(1:length(trans.costs)), function(x){
        
        # 1. TC for new (bought) positions
        TC.costs.new <- abs(portf[,newPos])*(1-fix.tc)*trans.costs[x] + trans.costs[x]*fix.tc
        ret.mon.all.TER[1,newPos] <- ret.mon.all.TER[1,newPos] - TC.costs.new
        
        # 2. TC for remaining positions (consider weight changes)
        weights.rem.old <- res.costs[[x+1]]$`Weights towards the end of the horizon`[[length(res.costs[[x+1]]$`Weights towards the end of the horizon`)]][remPos]
        TC.costs.rem <- abs(weights.rem.old-portf[,remPos])*(1-fix.tc)*trans.costs[x] + trans.costs[x]*fix.tc
        ret.mon.all.TER[1,remPos] <- ret.mon.all.TER[1,remPos] - TC.costs.rem
        
        # Monthly portfolio weighted returns (monthly sum of weighted ETF returns) for the given period and given TC
        ret.mon.portf.TER <- rowSums(ret.mon.all.TER, na.rm = T)
        ret.mon.portf.TER <- xts(ret.mon.portf.TER, order.by = as.Date(names(ret.mon.portf.TER)))
        
        # Cumulative return of the specific assets (ETFs)
        ret.cum.TER <- apply(ret.mon.all.TER, 2, function(x){ prod(1 + x, na.rm = TRUE) - 1 })
        
        # Value of the positions (weights) towards the end of the given period
        total.assets <- sum(abs(weights)*(1+ret.cum.TER))
        weights.new <- abs(weights)*(1+ret.cum.TER)/total.assets
        
        # Write results in result-list
        res.costs[[x+1]]$`Monthly Portfolio Return` <- rbind(res.costs[[x+1]]$`Monthly Portfolio Return`, ret.mon.portf.TER)
        res.costs[[x+1]]$`Weights towards the end of the horizon` <- append(res.costs[[x+1]]$`Weights towards the end of the horizon`, list(weights.new))
        
        return(res.costs[[x+1]])
      })
      
      # Compute Turnover
      res.costs <- TURNOVER(res.costs = res.costs, ret.portf = ret.portf, weights = weights, remPos = remPos, disc = disc, newPos = newPos, old.portf = old.portf)
    
      # Assign names for levels of transaction costs
      names(res.costs)[1] <- "No costs"
      names(res.costs)[2:length(res.costs)] <- paste0(trans.costs*10000, "bps")
      
    }
    
    ## CASE 3: old portfolio ETFs = new portfolio ETFs 
    # --> Only compute TC for weight changes
    #print("CASE 3")
    if(identical(newPos, character(0)) && length(old.portf)==length(weights)){
      
      res.costs[2:length(res.costs)] <- lapply(c(1:length(trans.costs)), function(x){
        
        # 1. TC for remaining positions (consider weight changes)
        weights.rem.old <- res.costs[[x+1]]$`Weights towards the end of the horizon`[[length(res.costs[[x+1]]$`Weights towards the end of the horizon`)]][remPos]
        TC.costs.rem <- abs(weights.rem.old-portf[,remPos])*(1-fix.tc)*trans.costs[x] + trans.costs[x]*fix.tc
        ret.mon.all.TER[1,remPos] <- ret.mon.all.TER[1,remPos] - TC.costs.rem
        
        # Monthly portfolio weighted returns (monthly sum of weighted ETF returns) for the given period and given TC
        ret.mon.portf.TER <- rowSums(ret.mon.all.TER, na.rm = T)
        ret.mon.portf.TER <- xts(ret.mon.portf.TER, order.by = as.Date(names(ret.mon.portf.TER)))
        
        # Cumulative return of the specific assets (ETFs)
        ret.cum.TER <- apply(ret.mon.all.TER, 2, function(x){ prod(1 + x, na.rm = TRUE) - 1 })
        
        # Value of the positions (weights) towards the end of the given period
        total.assets <- sum(abs(weights)*(1+ret.cum.TER))
        weights.new <- abs(weights)*(1+ret.cum.TER)/total.assets
        
        # Write results in result-list
        res.costs[[x+1]]$`Monthly Portfolio Return` <- rbind(res.costs[[x+1]]$`Monthly Portfolio Return`, ret.mon.portf.TER)
        res.costs[[x+1]]$`Weights towards the end of the horizon` <- append(res.costs[[x+1]]$`Weights towards the end of the horizon`, list(weights.new))
        
        return(res.costs[[x+1]])
      })
      
      # Compute Turnover
      res.costs <- TURNOVER(res.costs = res.costs, ret.portf = ret.portf, weights = weights, remPos = remPos, disc = disc, newPos = newPos, old.portf = old.portf)
    
      # Assign names for levels of transaction costs
      names(res.costs)[1] <- "No costs"
      names(res.costs)[2:length(res.costs)] <- paste0(trans.costs*10000, "bps")
        
    }
    
    ## CASE 4: There are no new ETFs but some got sold 
    # --> Compute TC for weight changes
    # --> Also compute TC for ETFs that got discarded (sold)
    #print("CASE 4")
    if(identical(newPos, character(0)) && length(old.portf)>length(weights)){
      
      res.costs[2:length(res.costs)] <- lapply(c(1:length(trans.costs)), function(x){
      
        # 1. TC for discarded (sold) positions
        weights.disc <- res.costs[[x+1]]$`Weights towards the end of the horizon`[[length(res.costs[[x+1]]$`Weights towards the end of the horizon`)]][disc]
        TC.costs.disc <- sum(abs(weights.disc)*(1-fix.tc)*trans.costs[x] + trans.costs[x]*fix.tc)
        
        # 2. TC for remaining positions (consider weight changes)
        weights.rem.old <- res.costs[[x+1]]$`Weights towards the end of the horizon`[[length(res.costs[[x+1]]$`Weights towards the end of the horizon`)]][remPos]
        TC.costs.rem <- abs(weights.rem.old-portf[,remPos])*(1-fix.tc)*trans.costs[x] + trans.costs[x]*fix.tc
        ret.mon.all.TER[1,remPos] <- ret.mon.all.TER[1,remPos] - TC.costs.rem
        
        # Monthly portfolio weighted returns (monthly sum of weighted ETF returns) for the given period and given TC
        ret.mon.portf.TER <- rowSums(ret.mon.all.TER, na.rm = T)
        # Subtract sum of TC for discarded positions (from 1.)
        ret.mon.portf.TER[1] <-  ret.mon.portf.TER[1] - TC.costs.disc
        ret.mon.portf.TER <- xts(ret.mon.portf.TER, order.by = as.Date(names(ret.mon.portf.TER)))
        
        # Cumulative return of the specific assets (ETFs)
        ret.cum.TER <- apply(ret.mon.all.TER, 2, function(x){ prod(1 + x, na.rm = TRUE) - 1 })
        
        # Value of the positions (weights) towards the end of the given period
        total.assets <- sum(abs(weights)*(1+ret.cum.TER))
        weights.new <- abs(weights)*(1+ret.cum.TER)/total.assets
        
        # Write results in result-list
        res.costs[[x+1]]$`Monthly Portfolio Return` <- rbind(res.costs[[x+1]]$`Monthly Portfolio Return`, ret.mon.portf.TER)
        res.costs[[x+1]]$`Weights towards the end of the horizon` <- append(res.costs[[x+1]]$`Weights towards the end of the horizon`, list(weights.new))
        
        return(res.costs[[x+1]])
      })
      
      # Compute Turnover
      res.costs <- TURNOVER(res.costs = res.costs, ret.portf = ret.portf, weights = weights, remPos = remPos, disc = disc, newPos = newPos, old.portf = old.portf)
      
      # Assign names for levels of transaction costs
      names(res.costs)[1] <- "No costs"
      names(res.costs)[2:length(res.costs)] <- paste0(trans.costs*10000, "bps")
      
    }
  }
  
  return(res.costs)
}
```

#### 3.1.4.3 Return Calulation Function
This function is used to compute the return of the portfolio strategies during the holding period. Hence, it is *not* utilized for the calculation of returns in our data set.\
Within this function we not only compute the monthly portfolio returns but also the cumulative returns of the ETFs as well as the change of weights towards the end of the period. The cumulative return for an ETF i is computed as:

$$Cumulative\;Return_{\,i}=\prod_{t=1}^T(1+R_{\,t,i})-1$$

The corresponding weight changes towards the end of the period for each ETF (position) in the portfolio are then calculated with:

$$w_i^{end\,of\,period}=w_i^{start\,of\,period}*\frac{1+Cummulative\;Return_{\,i}}{total\;assets_{\,t}}$$

Where: 

$$total\;assets_{\,t}=\sum_{i=1}^Tw_i^{start\,of\,period}*(1+Cumulative\;Return_{\,i})$$

With $n$ being the number of ETFs in the portfolio.\
On this basis the turnover function can then be calculated.

```{r Return, warning=FALSE}
RET <- function(ret, portf, trans.costs, TER.monthly, old.portf, all.ret.mon.portf, t, fix.tc, res.costs){
  
  #print("Return")
  
  # Select returns of portfolio
  ret.hor.portf <- ret[,colnames(portf)]
  weights <- as.numeric(portf)
  
  # Monthly weighted returns for given period
  ret.mon.all <- t(apply(ret.hor.portf, 1, function(x){ x*weights}))
  # Monthly portfolio weighted returns (monthly sum of weighted ETF returns) for the given period and given TC
  ret.mon.portf <- rowSums(ret.mon.all, na.rm = T)
  ret.mon.portf <- xts(ret.mon.portf, order.by = as.Date(names(ret.mon.portf)))
  
  # Save monthly portfolio returns
  all.ret.mon.portf <- rbind(all.ret.mon.portf, ret.mon.portf)
  
  # Cumulative return of the portfolio
  ret.cum.portf <- prod(1 + ret.mon.portf, na.rm = TRUE) - 1
  
  # Cumulative return of the specific assets (ETFs)
  ret.cum <- apply(ret.hor.portf, 2, function(x){ prod(1 + x, na.rm = TRUE) - 1 })
  
  # Value of the positions (weights) towards the end of the given period
  total.assets <- sum(abs(weights)*(1+ret.cum))
  weights.new <- abs(weights)*(1+ret.cum)/total.assets
  
  # Consideration of transaction costs and TER:
  res.costs <- TC.AND.TER(ret.portf = ret.mon.all, portf = portf, weights = weights, trans.costs = trans.costs, 
                          TER.monthly = TER.monthly, old.portf = old.portf, t = t, fix.tc = fix.tc,
                          res.costs = res.costs)
  
  # Bind results without and with costs:
  res.costs$`No costs`$`Monthly Portfolio Return` <- all.ret.mon.portf
  res.costs$`No costs`$`Weights towards the end of the horizon` <- append(res.costs$`No costs`$`Weights towards the end of the horizon`, list(weights.new))
  
  res.all <- res.costs
  
  return(res.all)
  
}
```

#### 3.1.4.4 Summary Statistics Function
Next, a function for the (annualized) summary performance statistics of the portfolio strategies is implemented. Thereby, we consider eight different (annualized) measures to capture the performance, (tail-) risk and impact of transaction costs.

**1. Annualized Return:** Obviously, we cannot implement an analysis without addressing the raw performance. This is done with the annualized returns of the portfolio strategy. The annualized returns are computed as follows:

$$R_{\,S}^{\,ann}=\left(1+\overline{R}_{\,S}^{\,mon}\right)^{12}-1$$

Where $\overline{R}_{\,Strategy}^{\,monthly}$ is the mean monthly return of the strategy over the out-of-sample backtesting period.

**2. Annualized Standard Deviation:** Still, in order to receive a comprehensive picture of the strategy, we also need to consider the risk. The most basic measure for that is the annualized standard deviation:

$$\sigma_{\,S}^{\,ann}=\sigma_{\,S}^{\,mon}*\sqrt{12}$$

**3. Annualized Sharpe Ratio:** However, it is better to directly set performance and risk into relation because it is even more important to know how much return the investor gets for some level of risk. The most popular key figure for this purpose is the annualized Sharpe Ratio. It measures the outperformance of some annualized strategy returns versus some benchmark (the annualized risk free rate) and sets it into relation regarding the annualized standard deviation of the strategy.

$$Sharpe \;Ratio_{\,S}^{\,ann}=\frac{R_{\,S}^{\,ann}-R_{\,risk-free}^{\,ann}}{\sigma_{\,S}^{\,ann}}$$

**4. Sharpe Ratio Loss:** The Sharpe Ratio loss measures how much performance, in terms of the Sharpe Ratio, the strategy loses when we compare the various TC scenarios with the no cost scenario. Therefore, the SR-loss for TC scenario $j$ is computed like so:

$$SR-Loss_{\,S}^{\,ann}=\frac{Sharpe\;Ratio_{\,S,\,TC_j}^{\,ann}}{Sharpe\;Ratio_{\,S,\,no\,costs}^{\,ann}}-1$$

**5. Annualized Sortino Ratio:** The Sortino Ratio is a variation of the Sharpe ratio that differentiates harmful volatility from total overall volatility by using the asset's standard deviation of negative portfolio returns—downside deviation—instead of the total standard deviation of portfolio returns. Hence, it takes an asset or portfolio's return and subtracts the risk-free rate, and then divides that amount by the asset's downside deviation.

$$Sortino \;Ratio_{\,S}^{\,ann}=\frac{R_{\,S}^{\,ann}-R_{\,risk-free}^{\,ann}}{\sigma_{\,S,\,downside}^{\,ann}}$$

**6. Annualized Value at Risk:** In order to get an even more complete picture about a portfolio strategy it is not sufficient to just look at the risk-adjusted performance w.r.t. the volatility. One needs to also consider the so called tail-risk. Key figures like the Value at Risk (VaR) and Maximum Drawdown (MDD) contain a lot of information about longer term risk one should also definitely have a look at. The VaR is defined as follows (all values are annualized):

$$VaR_{\,\alpha}=|\mu_{S}+\phi^{-1}(\alpha)*\sigma_{S}|$$

Hence, the VaR quantifies the maximum loss over a specific time period given for some confidence level (by default: 95%) (note that $\alpha=1-CI$). For example, if the VaR 20%, this means that for each year there is a 5% chance that the loss will be greater than 20% (resp. 95% chance that the loss will be smaller than 20%). In other words in one out of 20 years ($\frac{1}{\alpha}*100 = \frac{1}{5}*100$) the loss will be greater than 20%. The VaR can be computed with three different methods: (i) historical, (ii) Monte Carlo simulation and (iii) variance-covariance procedures. Here, we use the historical method.

**7. Maximum Drawdown:** The MDD is defined as the maximum loss (maximum cumulative loss) a portfolio or asset presents from peak to lowest over a time frame until a new peak is reached. We can see, that both the VaR and MDD can be regarded as a measure for (long-term) downside risk or tail risk for a portfolio or asset and is really important to look at. This is relevant, because even though sometimes the Sharpe and Sortino Ratio indicate better performance for some strategy the long-term risk performance might be better for some other strategy.

**8. Normalized Turnover:** For further analysis, the normalized turnover for each portfolio strategy is determined, which is a generalized a measure of how often positions within a portfolio are bought and sold. This turnover is then being normalized by the number of months in the out-of-sample backtest and the number of rebalancing events that occured for better comparability. Hence, it is computed as so:

$$Turnover_{\,S}^{\,norm}=\frac{Turnover_{\,S}^{\,cum}}{nT-nR-1}$$

Thereby, $nT$ is equal to the number of months in the backtest and $nR$ corresponds to the number of rebalancing events (depends on the horizon). For more information on how to compute the Turnover of the strategy see section 3.1.4.1.

```{r Summary Statistics, warning=FALSE}
STATISTICS <- function(res, RF, VaR.CI, horizon, trans.costs){
  
  # Annualized Return
  ret.ann <- lapply(1:length(res), function(x){
    (1+mean(res[[x]]$`Monthly Portfolio Return`))^12-1
    })
  names(ret.ann)[1] <- "no costs"
  names(ret.ann)[2:length(ret.ann)] <- paste0(trans.costs*10000, "bps")
  
  # Annualized SD
  sd.ann <- lapply(1:length(res), function(x){
    sd(res[[x]]$`Monthly Portfolio Return`)*sqrt(12)
    })
  names(sd.ann)[1] <- "no costs"
  names(sd.ann)[2:length(sd.ann)] <- paste0(trans.costs*10000, "bps")
  
  # Annualized Sharpe Ratio
  RF.ann <- (1+mean(RF))^(12)-1
  SR.ann <- lapply(1:length(res), function(x){
    (ret.ann[[x]]-RF.ann)/sd.ann[[x]]
  })
  names(SR.ann)[1] <- "no costs"
  names(SR.ann)[2:length(SR.ann)] <- paste0(trans.costs*10000, "bps")
  
  # Annualized Sharpe Ratio Loss
  SR.loss <- lapply(1:length(SR.ann), function(x){
    SR.ann[[x]]/SR.ann[[1]]-1
  })
  names(SR.ann)[1] <- "no costs"
  names(SR.ann)[2:length(SR.ann)] <- paste0(trans.costs*10000, "bps")
  
  # Annualized Sortino Ratio
  SortinoR.ann <- lapply(1:length(res), function(x){
    as.numeric((SortinoRatio(res[[x]]$`Monthly Portfolio Return` - RF[index(res[[x]]$`Monthly Portfolio Return`)], MAR = 0))*sqrt(12))
  })
  names(SortinoR.ann)[1] <- "no costs"
  names(SortinoR.ann)[2:length(SortinoR.ann)] <- paste0(trans.costs*10000, "bps")
  
  # Annualized Value at Risk
  VaR.ann <- lapply(1:length(res), function(x){
    abs(as.numeric(VaR(res[[x]]$`Monthly Portfolio Return`, p = VaR.CI, method = "historical")))*sqrt(12)
  })
  names(VaR.ann)[1] <- "no costs"
  names(VaR.ann)[2:length(VaR.ann)] <- paste0(trans.costs*10000, "bps")
  
  # Maximum Drawdown
  Max.Draw <- lapply(1:length(res), function(x){
    as.numeric(maxDrawdown(res[[x]]$`Monthly Portfolio Return`))
  })
  names(Max.Draw)[1] <- "no costs"
  names(Max.Draw)[2:length(Max.Draw)] <- paste0(trans.costs*10000, "bps")
  
  # Normalized Turnover
  Turnover.norm <- lapply(1:length(res), function(x){
    res[[x]]$`Turnover`/(length(res[[x]]$`Monthly Portfolio Return`)-ceiling(length(res[[x]]$`Monthly Portfolio Return`)/horizon)-1)
  })
  names(Turnover.norm)[1] <- "no costs"
  names(Turnover.norm)[2:length(Turnover.norm)] <- paste0(trans.costs*10000, "bps")
  
  return(do.call(cbind, list(ret.ann = ret.ann,
                             sd.ann = sd.ann,
                             SR.ann = SR.ann,
                             SR.loss = SR.loss,
                             SortinoR.ann = SortinoR.ann,
                             VaR.ann = VaR.ann,
                             Max.Draw = Max.Draw,
                             Turnover.norm = Turnover.norm)))
}
```

#### 3.1.4.5 Return Distribution Function
In this section we are going to provide a function which plots the distributions of the monthly out-of-sample returns resulting from the different portfolio strategies. Furthermore, it displays the values for skewness and excess kurtosis in the plots in order to give an even more precise feeling for the distributional characteristics of the returns. This might give the investor an even better feel for the tail risks of the portfolios.

```{r Return Distribution, warning=FALSE}
DISTRIBUTION <- function(res){
  
  return_df <- as.data.frame(res)
  
  # Reshape data from wide to long format and separate 'Type' and 'Cost'
  long_data <- return_df %>%
    pivot_longer(cols = everything(), names_to = "Var", values_to = "Return") %>%
    separate(Var, into = c("Type", "Cost"), sep = "\\.")
    
  # Ensure 'Type' and 'Cost' are factors to preserve order
  long_data$Type <- factor(long_data$Type, levels = unique(long_data$Type))
  long_data$Cost <- factor(long_data$Cost, levels = unique(long_data$Cost))
  
  # Get unique 'Cost' and 'Type' levels
  unique_Costs <- levels(long_data$Cost)
  unique_Types <- levels(long_data$Type)
  
  # Initialize a matrix to store plots with 'Cost' as rows and 'Type' as columns
  nrow <- length(unique_Costs)
  ncol <- length(unique_Types)
  plot_matrix <- matrix(list(), nrow = nrow, ncol = ncol, dimnames = list(unique_Costs, unique_Types))
  
  # Loop over 'Cost' (rows) and 'Type' (columns) to create plots
  for (i in seq_along(unique_Costs)) {
    for (j in seq_along(unique_Types)) {
      cost <- unique_Costs[i]
      type <- unique_Types[j]
      subset_data <- filter(long_data, Type == type, Cost == cost)
      returns <- subset_data$Return
      
      # Compute skewness and excess kurtosis
      skew <- skewness(returns, na.rm = TRUE)
      kurt <- kurtosis(returns, na.rm = TRUE) - 3  # Subtract 3 for excess kurtosis
      
      # Create plot with annotations
      p <- ggplot(subset_data, aes(x = Return)) +
        geom_density(fill = "skyblue", alpha = 0.5) +
        ggtitle(paste("", cost, "", type)) +
        theme_minimal() +
        theme(plot.title = element_text(hjust = 0.5)) +
        annotate("text", x = Inf, y = Inf, label = sprintf("Skewness: %.2f\nExcess Kurtosis: %.2f", skew, kurt),
                 hjust = 1.1, vjust = 1.1, size = 4, color = "blue")
        
      # Store the plot in the matrix
      plot_matrix[i, j] <- list(p)  # Use 'list(p)' to store the plot correctly
    }
  }
  
  # Convert the plot matrix to a list in the correct order
  plot_list <- as.vector(t(plot_matrix))  # Transpose before unlisting to maintain row-wise order
  
  # Arrange the plots with 'Cost' as rows and 'Type' as columns
  grid.arrange(grobs = plot_list, nrow = nrow, ncol = ncol)
  
}
```

#### 3.1.4.6 Positional Exposure Function
The following function should give a feeling about in how far the different strategies prefer some ETFs over others. I.e. the size of the "focus" (exposure) of the strategy against some ETF i. **Hence, the exposure should also give a feeling for the degree of diversification in the portfolio!** E.g. if the focus of some strategy is distributed on more asset classes the tail risks (VaR and MDD) should be smaller when compared to strategies which have a larger focus on one specific asset class. Therefore, the sum of the initial weights $w_{i,t}^{init}$ for all ETFs (i.e. the weights at the start of a new investment period) included in the portfolio is computed and then normalized (divided) by the number of rebalancings.

$$Exposure_{\,i}=\frac{1}{T}\sum_{t=1}^Tw_{i,t}^{init}$$

Subsequently, the exposure is also categorized w.r.t. the asset classes included in our data set (equity, real estate, bonds, commodity).\
At this point we expect the exposure to be the largest for the equity ETFs because (i) over half of the data set consists of equity ETFs and (ii) in section 2.4.1 we showed that equity ETFs historically provide the biggest mean returns. Since our prediction strategies are based upon historical information and primarily orient at past returns they might favor equity ETFs.

```{r Exposure, warning=FALSE}
EXPOSURE <- function(weights.init, horizon, y_test, asset.classes){
  
  # Delist input if necessary and save values as long format
  if(is.list(weights.init)){
    weights.init <- do.call(rbind, lapply(weights.init, function(x) {
      
      trans <- melt(x, value.name = "Weights", varnames = c("Weights", "ETF"))
      trans <- trans[, -1]
      
      return(trans)
    }))
  }
  
  ## Exposure for the specific ETFs:
  # Compute grouped sums and normalize them by the number of rebalancings
  Exposure <- weights.init %>%
    group_by(ETF) %>%
    summarize(Exposure = sum(Weights)/ceiling((nrow(y_test)/horizon)))
  
  # Plot the Exposures:
  # Consider all ETFs
  all.ETFs <- data.frame(ETF = colnames(y_test))
  Exposure <- all.ETFs %>%
    full_join(Exposure, by = "ETF") %>%
    mutate(Exposure = ifelse(is.na(Exposure), 0, Exposure))
  
  Exposure.ETF.plot <- ggplot(Exposure, aes(x = ETF, y = Exposure)) +
    geom_bar(stat = "identity", fill = "skyblue") +
    labs(x = "ETF", y = "Exposure") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
  ## Analyze the exposure against the asset classes:
  if(!is.null(asset.classes)){
    asset.class.df <- do.call(rbind, lapply(names(asset.classes), function(x){
      data.frame(ETF = asset.classes[[x]], AssetClass = x)
      }))
    # Assign ETF exposures
    Exposure <- Exposure %>%
      left_join(asset.class.df, by = "ETF")
    
    # Compute Exposure for asset classes
    Exposure.asset.classes <- Exposure %>%
      group_by(AssetClass) %>%
      summarize(TotalExposure = sum(Exposure))
    # Plot the exposures
    Exposure.asset.classes.plot <- ggplot(Exposure.asset.classes, aes(x = AssetClass, y = TotalExposure)) +
      geom_bar(stat = "identity", fill = "skyblue") +
      labs(x = "Asset Class", y = "Total Exposure") +
      theme_minimal() +
      theme(axis.text.x = element_text(angle = 45, hjust = 1))
  }
  
  if(!is.null(asset.classes)){
    return(list(Exposure.ETFs = Exposure,
                Exposure.ETFs.plot = Exposure.ETF.plot,
                Exposure.asset.classes = Exposure.asset.classes,
                Exposure.asset.classes.plot = Exposure.asset.classes.plot))
  }
  if(is.null(asset.classes)){
    return(list(Exposure.ETFs = Exposure,
                Exposure.ETFs.plot = Exposure.ETF.plot))
  }
}
```

#### 3.1.4.7 Accuracy and Precision Function
The following function addresses the evaluation measures of the predictions of the Prevailing Mean and Random Forest. Thereby, we consider MAE,

$$MAE=\frac{1}{n}\sum_{i=1}^n|Y_i-\hat{Y_i}|$$

RMSE

$$RMSE=\sqrt{\frac{1}{n}\sum_{i=1}^n{(Y_i-\hat{Y_i})}^2}$$

and R-squared

$$R^2=1-\frac{\sum_{i=1}^n{(Y_i-\hat{Y_i})}^2}{\sum_{i=1}^n(Y_i-\overline{Y_i})^2}$$

for the monthly as well as the cumulative performance predictions. Thereby, R-squared can be understood as some kind of percentage "precision" measure, since it captures the deviations in a normalized way in relation to the deviations of the actual values compared to their mean (i.e. it gives a feeling for the residuals). The closer R-squared comes to one, the more precise were the predictions. If R-squared would be one, the predicted out-of-sample values $\hat{Y_t}$ would be perfect and thus equal to the actual values $Y_t$. However, this is not a realistic case in a real-world application. Only if the model is overfitted and an in-sample test is performed, R-squared of one are common with real-world data.

```{r Accuracy and Precision, warning=FALSE}
EVAL <- function(y_predictions, y_actual, y_predictions.cum, y_actual.cum){
  
  # Compute measures for monthly return predictions
  if(all(class(y_predictions) == "list") == T){
    y_predictions <- do.call(cbind, y_predictions)
  }
  precision <- lapply(1:ncol(y_predictions), function(x){
    caret::postResample(pred = y_predictions[,x], obs = y_actual[,x])
    })
  names(precision) <- colnames(y_predictions)
  precision <- do.call(cbind, precision)
  rownames(precision) <- paste0("monthly ", rownames(precision))
  
  # Compute measures for cumulative return predictions
  if(all(class(y_predictions.cum) == "list") == T){
    y_predictions.cum <- do.call(cbind, y_predictions.cum)
  }
  precision.cum <- lapply(1:ncol(y_predictions.cum), function(x){
    caret::postResample(y_predictions.cum[,x], y_actual.cum[,x])
    })
  names(precision.cum) <- colnames(y_predictions.cum)
  precision.cum <- do.call(cbind, precision.cum)
  rownames(precision.cum) <- paste0("cumulative ", rownames(precision.cum))
  
  return(list(monthly = precision,
              cumulative = precision.cum))
}
```

#### 3.1.4.8 Wealth Development Function
Now, the wealth development simulation function is necessary to get a better feel for the performance of the strategies. Because until now we only have functions to evaluate the numbers of the strategies. However, a wealth development visualizes the performance of a portfolio strategy in an intuitive way and therefore gives a better feeling for the performance results. The following function takes the portfolio returns as input with an initial investment size and computes the resulting wealth development. In addition to that, it also plots the growth of the portfolio value over the time frame of the out-of-sample test.

```{r Wealth Simulation, warning=FALSE}
WEALTH.SIMULATION <- function(ret, init){
  
  # We need one more row because we invest at the start (i.e. first row == amount invested)
  Wealth <- matrix(nrow = length(ret)+1)
  Wealth <- xts(Wealth, order.by = c(floor_date(index(ret)[1], "month"), index(ret)))
  colnames(Wealth) <- "Wealth"
  dates <- index(Wealth)
  
  # Compute Wealth
  for(i in 1:nrow(Wealth)){
    if(i == 1){
      Wealth[i,] <- init
    }
    if(i != 1){
      Wealth[i,] <- as.numeric(Wealth[i-1,])*(1+as.numeric(ret[i-1,])) #Indices are shifted by one
    }
  }
  
  # Compute absolute and relative return over time
  abs.ret <- as.numeric(Wealth[nrow(Wealth),]) - as.numeric(Wealth[1,])
  rel.ret <- as.numeric(Wealth[nrow(Wealth),]) / as.numeric(Wealth[1,]) - 1
  
  # Maximum Drawdown
  maxDraw <- table.Drawdowns(ret, top = 1, geometric = T)
  maxDraw <- maxDraw[-c(5:7)]
  
  # Plot the result
  Plot <- ggplot(Wealth) +
    geom_line(aes(x = dates, y = `Wealth`, color = "Value")) +
    scale_x_date(labels = date_format("%d-%m-%Y")) +
    scale_color_manual(" ", values = c("Value" = "skyblue"))+
    labs(x = "Dates", y = "Wealth")+
    theme_minimal()
  
  return(list(Wealth = Wealth,
              abs.ret = abs.ret,
              rel.ret = rel.ret,
              Plot = Plot,
              maxDraw = maxDraw))
  
}
```

### 3.1.5 Portfolio Functions
Next, we need to create the functions for the portfolio strategies which we want to backtest regarding their performance later on. Therefore, we take a closer look at four concepts. The (i) buy-and-hold portfolio (benchmark), (ii) the long-only concept, (iv) the long-short-portfolio as well as (v) the (constrained) (shrinked) Minimum Variance strategie (Markowitz [1952]). Thereby, for the long-only and long-short strategies we use two different weighting strategies: The equally weighting concept as well as the rank weighted method.\
But before we get to the specific portfolio functions let me first explain how they are executed in conjunction with the evaluation functions from subsection 3.1.4.1 to 3.1.4.3 because these functions are implemented in a nested manner.\
First. the portfolio functions (section 3.1.5) are created to receive the portfolio for the next investment horizon. Second, the returns are computed (section 3.1.4.3). Third, the TC and TER are considered (section 3.1.4.2). Fourth, the cumulative Turnover (section 3.1.4.1) is computed. This applied process of the nesed  functions (execution of the out-of-sample backtest) can be visualized as follows:

Start loop\
**1. Layer:** "Section 3.1.5"{\
>  1.1 Select ETFs upon return predictions (if available)\
>  1.2 Weight the ETFs according to the Portfolio (EW, RW or MinVar) Strategy\
>  --> Portfolio in t is created\
>    **2. Layer:** "Section 3.1.4.3"{\
> >      Compute weighted ETF returns and Portfolio return without costs\
> >        **3. Layer:** "Section 3.1.4.2"{\
> > >          3.1 Consider transaction cost scenarios and TER\
> > >          3.2 Save Weights at the beginning and towards the end of the period\
> > >            **4. Layer:** "Section 3.1.4.1"{\
> > > >              Compute Cumulative Turnover\
> > >            }\
> >        }\
>    }\
}\
Next iteration

#### 3.1.5.1 Weighting Strategy Functions
First, we create the functions for the weighting strategies which are applied later within the portfolio functions.

##### 3.1.5.1.1 Equally Weighted
Each ETF gets the weight 1/n where n == number of ETFs in the portfolio. Therefore, in the literature the equally weighted portfolio is also called the 1/n portfolio.

```{r Equal Weights, warning=FALSE}
EQUAL.WEIGHTS <- function(portf.names, short = FALSE){
  
  # Should a long portfolio be weighted
  if(short == FALSE){
    n <- length(portf.names)
    wi <- rep(1/n, n)
    portf <- matrix(wi, nrow = 1)
    colnames(portf) <- portf.names
    return(portf)
  }
  
  # Or a short portfolio
  if(short == TRUE){
    n <- length(portf.names)
    wi <- -rep(1/n, n) # Assign negative weights
    portf <- matrix(wi, nrow = 1)
    colnames(portf) <- portf.names
    return(portf)
  }
}
```

##### 3.1.5.1.2 Rank Weighted
For the rank weighted approach we proceed as follows. First, the weights proportional to the inverse ranks are calculated:

$$w_{i, raw}=\frac{1}{r_i}$$

Thereby, the ranks $r_i$ are sorted ascendingly from 1 to n from the lowest to the highest predicted cumulative return for the next investing period (i.e. for the next "horizon" months). Hence, the ETF with the highest predicted return gets the raw weight $r_{i, raw}$ 1 assigned to it, the second highest 0.5, the third highest 0.333 and so on.\
Afterwards the final weights are computed by dividing the raw weights of each ETF in the portfolio by the sum of all raw weights. This means that the weights are normalized so they sum up to 1:

$$w_i=\frac{w_{i, raw}}{\sum_{i=1}^{n} w_{i, raw}}$$

```{r Rank Weights, warning=FALSE}
RANK.WEIGHTS <- function(portf.names, short = FALSE){
  
  # For long portfolios
  if(short == FALSE){
    n <- length(portf.names)
    # Assign weights proportional to the inverse of their rank
    # Works, because ETFs are already sorted by their ranks (left to right == highest to lowest predicted cumulative return)
    wi_raw <- 1 / (1:n)
    # Normalize weights so that they sum to 1
    wi <- wi_raw / sum(wi_raw)
    # Create a matrix with one row (the normalized weights)
    portf <- matrix(wi, nrow = 1)
    # Set the column names to be the ETF names
    colnames(portf) <- portf.names
    return(portf)
  }
  
  # For short portfolios
  if(short == TRUE){
    n <- length(portf.names)
    wi_raw <- 1 / (1:n)
    wi <- -wi_raw / sum(wi_raw) # Assign negative weights
    portf <- matrix(wi, nrow = 1)
    colnames(portf) <- portf.names
    return(portf)
  }
  
}
```

#### 3.1.5.2 Buy-and-Hold Portfolio
We start with the easiest portfolio to allocate. We use it to compute the performance of the benchmark strategy with the MSCI World Index. Since we only use one ETF for this strategy, this strategy is programmed differently when compared to the more complex strategies. Specifically, this means that all calculations are done in this one function and not within many layered functions.

```{r, warning=FALSE}
B.A.H <- function(bench, BT.Dates, trans.costs, TER.monthly, RF, VaR.CI = 0.95){
  
  ret.bench <- bench[BT.Dates,]
  
  # Return:
  mean.ret.mon <- mean(ret.bench, na.rm = T)
  mean.ret.ann <- (1+mean.ret.mon)^(12)-1
  
  # Standard deviation:
  SD.mon <- sd(ret.bench, na.rm=T)
  SD.ann <- SD.mon*sqrt(12)
  
  # Risk free rate:
  mean.RF.mon <- mean(RF[BT.Dates], na.rm = T)
  mean.RF.ann <- (1+mean.RF.mon)^(12)-1
  
  # Sharpe Ratio:
  SR.mon <- (mean.ret.mon-mean.RF.mon)/SD.mon
  SR.ann <- (mean.ret.ann-mean.RF.ann)/SD.ann
  
  # Sharpe Ratio Loss for no costs:
  SR.loss <- 0
  
  # Sortino Ratio:
  SortinoR.mon <- SortinoRatio(ret.bench-RF[BT.Dates], MAR = 0)
  SortinoR.ann <- SortinoR.mon*sqrt(12)
  
  # Value at Risk:
  VaR.mon <- abs(as.numeric(VaR(ret.bench, p = VaR.CI, method = "historical")))
  VaR.ann <- VaR.mon*sqrt(12)
  
  # Maximum Drawdown:
  MDD <- as.numeric(maxDrawdown(ret.bench))
  
  ## With costs:
  # Total (rolling) costs (TER):
  Returns_TER <- ret.bench - as.numeric(TER.monthly[colnames(bench)])
  
  # Transaction costs:
  # Note:   Since we look at a buy-and-hold strategy we only buy one time
  #         Hence, we only need to consider the transaction costs in month one!
  SR.first <- SR.ann
  res.costs <- lapply(c(1:length(trans.costs)), function(x){
    # Consider transaction costs only in the first month:
    Returns_TER[1] <- Returns_TER[1] - trans.costs[x]
    
    # Returns:
    mean.ret.mon.costs <- mean(Returns_TER, na.rm = T)
    mean.ret.ann.costs <- (1+mean.ret.mon.costs)^12-1
    
    # Standard deviation:
    sd.mon.costs <- sd(Returns_TER, na.rm = TRUE)
    sd.ann.costs <- sd.mon.costs*sqrt(12)
    
    # Sharpe Ratio:
    SR.ann <- (mean.ret.ann.costs-mean.RF.ann)/sd.ann.costs
    
    # Sharpe Ratio Loss:
    SR.loss <- SR.ann/SR.first-1
    
    # Sortino Ratio:
    SortinoR.mon.costs <- SortinoRatio(Returns_TER-RF, MAR = 0)
    SortinoR.ann.costs <- SortinoR.mon.costs*sqrt(12)
    
    # Value at Risk:
    VaR.mon.costs <- abs(as.numeric(VaR(Returns_TER, p = VaR.CI, method = "historical")))
    VaR.ann.costs <- VaR.mon.costs*sqrt(12)
    
    # Maximum Drawdown:
    MDD.costs <- as.numeric(maxDrawdown(Returns_TER))
    
    return(list(mean.ret.ann = mean.ret.ann.costs,
                sd.ann = sd.ann.costs,
                SR.ann = SR.ann,
                SR.loss = SR.loss,
                SortinoR.ann = SortinoR.ann.costs,
                VaR.ann = VaR.ann.costs,
                MaxDraw = MDD.costs,
                ret.Costs = Returns_TER))
  })
  
  names(res.costs) <- paste0(trans.costs * 10000, "bps")

  # Combine lists using `c()`, which preserves names better than `append()`
  res.all <- c(list("no costs" = list(mean.ret.ann = mean.ret.ann,
                                      sd.ann = SD.ann,
                                      SR.ann = SR.ann,
                                      SR.loss = SR.loss,
                                      SortinoR.ann = SortinoR.ann,
                                      VaR.ann = VaR.ann,
                                      MaxDraw = MDD,
                                      ret.noCosts = ret.bench)),
               res.costs)
  
  return(res.all)
}
```

#### 3.1.5.3 Long-Only Portfolio
The ETFs within the long-only portfolios can be weighted in two ways: First, the equally weighted (1/N) approach and second, the rank weighted procedure. Both approaches are computed for a fixed number N of ETFs. Thereby, this number can be determined manually (see input variables) or via the definition pr>0 (i.e. only invest in ETFs which predicted cumulative returns are larger than zero). If the number is set manually and less ETFs are defined than there are in our data set, the ETFs with the lowest predicted returns are discarded

```{r Long-Only Portfolio, warning=FALSE}
LONG.ONLY <- function(y_test, cum.pred = NULL, use.long.only, counter = 1, t = 1, horizon, portf.EW.all, portf.RW.all,
                      trans.costs, TER.monthly, all.ret.mon.portf.EW, all.ret.mon.portf.RW, fix.tc, res.all){
  
  # Check if horizon is set correctly (i.e. if we are in the last iteration)
  if((counter+horizon-1) > nrow(y_test)){
    horizon <- nrow(y_test) - counter + 1
  }
  
  ######## Select ETFs to invest in: ########
  # If return predictions are available
  if(!is.null(cum.pred)){
    # Assign correct ETF-names
    colnames(cum.pred) <- colnames(y_test)
    # Order ETFs decreasingly according to theier predictions:
    order.t <- cum.pred[t,][order(cum.pred[t,], decreasing = TRUE)]
    order.t <- rbind(order.t, c(1:length(order.t)))
    # Select share of ETFs to invest in (i.e. create ETF-portfolio list with predicted returns)
    consider <- round(use.long.only*ncol(order.t), 0)
    portf.names <- names(order.t[1, c(1:consider)])
  }
  
  # If no return predictions are available, use all ETFs
  if(is.null(cum.pred)){
    portf.names <- colnames(y_test)
  }
  
  ######## Compute weights: ########
  # Equal weighted
  portf.EW <- EQUAL.WEIGHTS(portf.names = portf.names)
  portf.EW.all[[t]] <- portf.EW
  
  # Rank weighted (only if return predictions are available)
  if(!is.null(cum.pred)){
    portf.RW <- RANK.WEIGHTS(portf.names = portf.names)
    portf.RW.all[[t]] <- portf.RW
  }
  
  ######## Compute Returns: ########
  # Select out-of-sample returns for the next investing period (next "horizon" months)
  ret.hor <- y_test[counter:(counter+horizon-1),]
  
  ## Returns for the equally weighted portfolio
  # For the first iteration
  if(t==1){
    ret.portf.EW <- RET(ret = ret.hor, portf = portf.EW, trans.costs = trans.costs, TER.monthly = TER.monthly, 
                        old.portf = portf.EW.all, all.ret.mon.portf = all.ret.mon.portf.EW, t = t, 
                        fix.tc = fix.tc, res.costs = res.all$ret.portf.EW)
  }
  # For all other iterations
  if(t!=1){
    ret.portf.EW <- RET(ret = ret.hor, portf = portf.EW, trans.costs = trans.costs, TER.monthly = TER.monthly, 
                        old.portf = portf.EW.all[[t-1]], all.ret.mon.portf = all.ret.mon.portf.EW, t = t, 
                        fix.tc = fix.tc, res.costs = res.all$ret.portf.EW)
  }
  
  ## Returns for the rank weighted portfolio
  # For the first iteration
  if(!is.null(cum.pred)){
    if(t==1){
      ret.portf.RW <- RET(ret = ret.hor, portf = portf.RW, trans.costs = trans.costs, TER.monthly = TER.monthly, 
                          old.portf = portf.RW.all, all.ret.mon.portf = all.ret.mon.portf.RW, t = t, 
                          fix.tc = fix.tc, res.costs = res.all$ret.portf.RW)
    }
    # For all other iterations
    if(t!=1){
      ret.portf.RW <- RET(ret = ret.hor, portf = portf.RW, trans.costs = trans.costs, TER.monthly = TER.monthly, 
                          old.portf = portf.RW.all[[t-1]], all.ret.mon.portf = all.ret.mon.portf.RW, t = t, 
                          fix.tc = fix.tc, res.costs = res.all$ret.portf.RW)
    }
  }
  
  t <-  t + 1
  counter <- counter + horizon
  
  if(!is.null(cum.pred)){
    res <- list(ret.portf.EW = ret.portf.EW,
                ret.portf.RW = ret.portf.RW,
                t = t,
                counter = counter,
                portf.EW.all = portf.EW.all,
                portf.RW.all = portf.RW.all
                )
  }
  if(is.null(cum.pred)){
    res <- list(ret.portf.EW = ret.portf.EW,
                t = t,
                counter = counter,
                portf.EW.all = portf.EW.all
                )
  }
  
  return(res)
}
```

#### 3.1.5.4 Long-Short Portfolio
Next, the Long-Short Portfolio is implemented. As the name already says it not only considers the long positions for the predicted top-performers but also short positions of the predicted low performers if they are predicted to be negative. Now, we expect this strategy to only yield better results if the return predictions for the ETFs are really precise for two reasons.\
First, because in section 2.4.1 (table "Ret.overview") we showed that all assets have a positive annualized return in the mean. This means that it will be more difficult to catch the downward trends in general and that the short positions should never be held for too long in the portfolio. In our case this is going to be a challenge because we primarily take a look at longer-term investments where the times between rebalancings are multiple months. However, we hope that when looking at the robustness checks for shorter term horizons this strategy gives us an advantage.\
Second, for short positions there is something called "path dependencies". It states that once a short position is entered and the price of the security rises further and further it becomes event more difficult to get a profit. For example, if you take a short position on some asset which is worth 100 at time t and the next day it rises by 10% to 110 and the day after that it falls back to 100 you're not making zero but a loss of 0.91%. The reason for that is that for the second day the reference basis is not 100 but 110. Hence, the asset doesn't fall by 10% but by 9.1%. Since you have a short position and you lost 10% on the first day and only got 9.1% on the second day you lost overall. Therefore, short positions should always be bought right on time which in our case means that we need precise predictions.

Note that other than the LONG.ONLY function the LONG.SHORT function **requires** a return prediction set because otherwise the short positions (and also all long positions) would be selected randomly.

```{r Long-Short Portfolio, warning=FALSE}
LONG.SHORT <- function(y_test, cum.pred, use.long.short, disc.positive = F, lend = 1, counter = 1, t = 1, horizon, portf.EW.all, portf.RW.all,
                       trans.costs, TER.monthly, all.ret.mon.portf.EW, all.ret.mon.portf.RW, fix.tc, res.all){
  
  # Check if horizon is set correctly (i.e. if we are in the last iteration)
  if((counter+horizon-1) > nrow(y_test)){
    horizon <- nrow(y_test) - counter + 1
  }
  
  ######## Select ETFs to invest in: ########
  # Assign correct ETF-names
  colnames(cum.pred) <- colnames(y_test)
  # Order ETFs decreasingly according to their predictions:
  order.t <- cum.pred[t,][order(cum.pred[t,], decreasing = TRUE)]
  order.t <- rbind(order.t, c(1:length(order.t)))
  # Select share of ETFs to invest in (i.e. create ETF-portfolio list with predicted returns)
  consider.long <- round(use.long.short*ncol(order.t), 0)
  # Select ETFs to go long
  portf.names.long <- names(order.t[1, c(1:consider.long)])
  # Select ETFs to short
  portf.names.short <- names(order.t[1, c((ncol(order.t) - consider.long + 1):ncol(order.t))])
  # Check if only ETFs with negative predicted cumulative returns shall be considered
  if(disc.positive == T){
    tmp.shorts <- order.t[1, c((ncol(order.t) - consider.long + 1):ncol(order.t))]
    tmp.shorts <- tmp.shorts[-which(tmp.shorts>0)]
    portf.names.short <- names(tmp.shorts)
    if(identical(portf.names.short, character(0))){
      # Only use worst predicted ETF if no ETFs are predicted to be negative
      tmp.shorts <- order.t[1, c((ncol(order.t) - consider.long + 1):ncol(order.t))]
      tmp.shorts <- tmp.shorts[length(tmp.shorts)]
      portf.names.short <- names(tmp.shorts)
    }
  }
  
  ######## Compute weights: ########
  # Equal weighted
  portf.EW.long <- as.matrix(EQUAL.WEIGHTS(portf.names = portf.names.long, short = FALSE)/2*lend)
  portf.EW.short <- as.matrix(EQUAL.WEIGHTS(portf.names = portf.names.short, short = TRUE)/2*lend)
  portf.EW <- cbind(portf.EW.long, portf.EW.short)
  portf.EW.all[[t]] <- portf.EW
  
  # Rank weighted
  portf.RW.long <- as.matrix(RANK.WEIGHTS(portf.names = portf.names.long, short = FALSE)/2*lend)
  portf.RW.short <- as.matrix(RANK.WEIGHTS(portf.names = portf.names.short, short = TRUE)/2*lend)
  portf.RW <- cbind(portf.RW.long, portf.RW.short)
  portf.RW.all[[t]] <- portf.RW
  
  ####### Compute Returns: ########
  # Select out-of-sample returns for the next investing period (next "horizon" months)
  ret.hor <- y_test[counter:(counter+horizon-1),]
  
  ## Returns for the equally weighted portfolio
  # For the first iteration
  if(t==1){
    ret.portf.EW <- RET(ret = ret.hor, portf = portf.EW, trans.costs = trans.costs, TER.monthly = TER.monthly, 
                        old.portf = portf.EW.all, all.ret.mon.portf = all.ret.mon.portf.EW, t = t, 
                        fix.tc = fix.tc, res.costs = res.all$ret.portf.EW)
  }
  # For all other iterations
  if(t!=1){
    ret.portf.EW <- RET(ret = ret.hor, portf = portf.EW, trans.costs = trans.costs, TER.monthly = TER.monthly, 
                        old.portf = portf.EW.all[[t-1]], all.ret.mon.portf = all.ret.mon.portf.EW, t = t, 
                        fix.tc = fix.tc, res.costs = res.all$ret.portf.EW)
  }
  
  ## Returns for the rank weighted portfolio
  # For the first iteration
  if(!is.null(cum.pred)){
    if(t==1){
      ret.portf.RW <- RET(ret = ret.hor, portf = portf.RW, trans.costs = trans.costs, TER.monthly = TER.monthly, 
                          old.portf = portf.RW.all, all.ret.mon.portf = all.ret.mon.portf.RW, t = t, 
                          fix.tc = fix.tc, res.costs = res.all$ret.portf.RW)
    }
    # For all other iterations
    if(t!=1){
      ret.portf.RW <- RET(ret = ret.hor, portf = portf.RW, trans.costs = trans.costs, TER.monthly = TER.monthly, 
                          old.portf = portf.RW.all[[t-1]], all.ret.mon.portf = all.ret.mon.portf.RW, t = t, 
                          fix.tc = fix.tc, res.costs = res.all$ret.portf.RW)
    }
  }
  
  t <-  t + 1
  counter <- counter + horizon
  
  res <- list(ret.portf.EW = ret.portf.EW,
              ret.portf.RW = ret.portf.RW,
              t = t,
              counter = counter,
              portf.EW.all = portf.EW.all,
              portf.RW.all = portf.RW.all
              )
  return(res)
}
```

#### 3.1.5.5 Minimum Variance Portfolios
The Minimum Variance function from the package "NMOF" by E. Schumann determines the optimal portfolio weights according to the MV optimization approach. If the dummy variable "shrink" is equal 1 the covariance matrix will be shrinked (see Ledoit and Wolf [2004]) (default). When the variable is 0 the normal sample covariance matrix will be applied. But first, let's have a look at the Minimum Variance optimization by Markowitz (1952). The initial problem is defined by

$$\min_{w}\{w'\Sigma w\},\; \;s.t. \; w'\textbf{1}\overset{!}{=}1$$

where $\Sigma$ is the variance-covariance matrix. If we solve the optimization problem via a Lagrange function we get

$$w^*=\frac{\Sigma^{-1}\textbf{1}}{\textbf{1}'\Sigma^{-1}\textbf{1}}$$

for the optimal weight vector $w^*$ which minimizes the variance within the variance-covariance matrix.

When it comes to the Markowitz portfolio optimization it is crucial to consistently estimate the covariance matrix. Thereby, the sample covarinace matrix often performs poorly when the number of variables is large compared to the number of observations (i.e. has large estimation errors). This issue can lead to unstable estimates that are not invertible, posing significant problems for practical applications.

Therefore, Ledoit and Wolf (2004) developed a method called "Shrinkage". Essentially, the main goal of this procedure is to pull extreme coefficients towards more central values by finding the optimal shrinkage intensity parameter $\delta \in \,[0,1]$ that minimizes the error of the sample covariance matrix. This in turn should lead to obtaining a more accurate estimate for the true and unobservable covariance matrix $\Sigma$. The key idea is to improve the estimation by combining the sample covariance matrix with a structured target matrix $F$, effectively "shrinking" the sample estimates toward the target. Hence, the optimization problem can be defined as

$$\hat{\Sigma}=\delta F + (1-\delta)S$$

where $\hat{\Sigma}$ is the shrinkage estimator of the covariance matrix (i.e. the shrinked matrix) and $S$ the sample variance-covariance matrix.\
Ledoit and Wolf (2004) derive a formula for the optimal shrinkage intensity parameter which minimizes the mean squared error between the true covariance matrix and the shrinkage estimator which is described as

$$\delta^*=\frac{Var(S_{ij})}{Bias^2(F_{ij})+Var(S{ij})},\; \; \forall \, i \neq j$$

with $Bias(F_{ij}) = E\left[F_{ij}-\Sigma_{ij} \right]$\
and $Var(S_{ij})=E\left[ \left( S_{ij}-\Sigma_{ij}\right)^2\right]$.\
Then, $\delta^*$ is defined as the optimal weight to assign to the target matrix $F$ versus the sample covariance matrix $S$, which improves the estimator's accuracy.

Implementing this shrinkage technique should result in a more reliable covariance matrix estimate, especially in high-dimensional settings. Hence, also the stability of statistical procedures like portfolio optimization might enhance, leading to better performance in practical applications.
 
```{r Minimum Variance Portfolio, warning=FALSE}
MIN.VAR <- function(ret, train.rows, y_test, cum.pred, use.minvar, counter = 1, t = 1, horizon, portf.shrink.all, portf.sample.all,
                    trans.costs, TER.monthly, all.ret.mon.portf.shrink, all.ret.mon.portf.sample, limit, fix.tc, min.max, res.all){
  
  # Check if horizon is set correctly (i.e. if we are in the last iteration)
  if((counter+horizon-1) > nrow(y_test)){
    horizon <- nrow(y_test) - counter + 1
  }
  
  ######## Select ETFs to invest in: ########
  # Assign correct ETF-names
  colnames(cum.pred) <- colnames(y_test)
  # Order ETFs decreasingly according to their predictions:
  order.t <- cum.pred[t,][order(cum.pred[t,], decreasing = TRUE)]
  order.t <- rbind(order.t, c(1:length(order.t)))
  # Select share of ETFs to invest in (i.e. create ETF-portfolio list with predicted returns)
  consider<- round(use.minvar*ncol(order.t), 0)
  portf.names <- names(order.t[1, c(1:consider)])
  
  ######## Select historical observations (tine window) to compute the covariance matrix with ######## 
  if(!is.na(limit) && limit < length(train.rows)){
    train.rows.tmp <- train.rows[(length(train.rows) - limit + 1):length(train.rows)]
  }
  if(!is.na(limit) && limit > length(train.rows)){
    train.rows.tmp <- train.rows
  }
  # If no limit is set do nothing
  if(is.na(limit)){
    train.rows.tmp <- train.rows
  }
  
  # For the last iteration
  if(!is.na(limit) && max(train.rows) >= nrow(ret)){
    train.rows.tmp <- c(min(train.rows):nrow(ret))[(length(train.rows) - limit + 1):length(train.rows)]
  }
  if(is.na(limit) && max(train.rows) >= nrow(ret)){
    train.rows.tmp <- c(min(train.rows):nrow(ret))
  }
  
  ######## Compute weights: ########
  # Select out-of-sample returns for the next investing period (next "horizon" months)
  ret.hor <- y_test[counter:(counter+horizon-1),]
  # Data to compute the covariance matrix with
  ret.hist <- ret[train.rows.tmp, portf.names]
  # Calculate sample covariance matrix
  cov.sample <- cov(na.omit(ret.hist))
  # Calculate shrinked covariance matrix
  cov.shrink <- linshrink_cov2(na.omit(ret.hist))
  
  # Rank based weight constraint
   if(!is.null(cum.pred) && identical(min.max, "rank")){
    w.max <- ((1 / (1:ncol(ret.hist)))/sum(1 / (1:ncol(ret.hist))))[1]
    w.min <- ((1 / (1:ncol(ret.hist)))/sum(1 / (1:ncol(ret.hist))))
    w.min <- w.min[length(w.min)]
   }
  # Manual weight constraint
  if(is.numeric(min.max) == T && length(min.max) == 2){
    w.min <- min.max[1]
    w.max <- min.max[2]
  }
  
  # Minimum Variance optimization with sample cov matrix
  weights.sample.wmax <- minvar(cov.sample, wmin = w.min, wmax = w.max, method = "qp")
  portf.sample <- t(as.matrix(weights.sample.wmax))
  colnames(portf.sample) <- portf.names
  portf.sample.all[[t]] <- portf.sample
  
  # Minimum Variance optimization with shrinked cov matrix
  weights.shrink.wmax <- minvar(cov.shrink, wmin = w.min, wmax = w.max, method = "qp")
  portf.shrink <- t(as.matrix(weights.shrink.wmax))
  colnames(portf.shrink) <- portf.names
  portf.shrink.all[[t]] <- portf.shrink
  
  ####### Compute Returns: ########
  ## Sample Version:
  # For the first iteration
  if(t==1){
    ret.portf.sample <- RET(ret = ret.hor, portf = portf.sample, trans.costs = trans.costs, TER.monthly = TER.monthly,
                            old.portf = portf.sample.all, all.ret.mon.portf = all.ret.mon.portf.sample, t = t,
                            fix.tc = fix.tc, res.costs = res.all$ret.portf.sample)
  }
  # For all other iterations
  if(t!=1){
    ret.portf.sample <- RET(ret = ret.hor, portf = portf.sample, trans.costs = trans.costs, TER.monthly = TER.monthly,
                            old.portf = portf.sample.all[[t-1]], all.ret.mon.portf = all.ret.mon.portf.sample, t = t,
                            fix.tc = fix.tc, res.costs = res.all$ret.portf.sample)
  }
  ## Shrinked Version:
  # For the first iteration
  if(t==1){
    ret.portf.shrink <- RET(ret = ret.hor, portf = portf.shrink, trans.costs = trans.costs, TER.monthly = TER.monthly,
                            old.portf = portf.shrink.all, all.ret.mon.portf = all.ret.mon.portf.shrink, t = t,
                            fix.tc = fix.tc, res.costs = res.all$ret.portf.shrink)
  }
  # For all other iterations
  if(t!=1){
    ret.portf.shrink <- RET(ret = ret.hor, portf = portf.shrink, trans.costs = trans.costs, TER.monthly = TER.monthly,
                            old.portf = portf.shrink.all[[t-1]], all.ret.mon.portf = all.ret.mon.portf.shrink, t = t,
                            fix.tc = fix.tc, res.costs = res.all$ret.portf.shrink)
  }
  
  # Update the indices
  train.rows <- c(train.rows, c(train.rows[length(train.rows)]+c(1:horizon)))
  t <-  t + 1
  counter <- counter + horizon
  
  res <- list(ret.portf.sample = ret.portf.sample,
              ret.portf.shrink = ret.portf.shrink,
              portf.sample.all = portf.sample.all,
              portf.shrink.all = portf.shrink.all,
              train.rows = train.rows,
              t = t,
              counter = counter)
  
  return(res)
}
```

## 3.2 Return Predictions
From this subsections on the functions programmed in section 3.1 are applied. In this specific subsection the return prediction functions from section 3.1.2 and 3.1.3 are executed. This means, that we now perform the out-of-sample predictions and performance tests for our models. The window of the out-of-sample period (investment period) is defined via the "train.perc" variable (i.e. if train.perc == 0.5, then the second half of the whole data set is used as the evaluation period). Thereby, the code iterates through the data set with a while loop. New predictions are computed after each "horizon" (see input parameters) months (i.e. after "horizon" months when a rebalancing occurs).\
Note that all the prediction results are stored in tables (see section 3.1.5) which can be compared subsequently.

### 3.2.1 Prevailing Mean
We start with the easiest (comparison) prediction model - the prevailing mean.

```{r Return Predictions - Compute Prevailing Mean, warning=FALSE}
# If no Z-Score trans is wished
tmp <- ret
# If Z-score transformation is wished
if(trans.Z == T){
  tmp <- Z.TRANS(ret = ret, Names = Names, last = last)
}
# Initial number of training rows:
train.rows <- Train.Rows(ret = tmp, train.perc = train.perc)
# All test values (IMPORTANT: NOW USE "ret"):
y_test <- Test_DS(ret = tmp, train.rows = train.rows, horizon = horizon)

mean.ret.mon.all <- NULL
mean.ret.cum.all <- NULL
t=1

## Start predictions:
while(t<nrow(y_test$y_test)){
  
  res.prev <- PREVAILING.MEAN(ret = tmp, horizon = horizon, 
                              train.rows = train.rows, limit = limit, 
                              counter = t, mean.ret.mon.all = mean.ret.mon.all,
                              mean.ret.cum.all = mean.ret.cum.all, 
                              y_test = y_test$y_test)
  
  t <- res.prev$counter
  train.rows <- res.prev$train.rows
  mean.ret.mon.all <- res.prev$mean.ret.mon.all
  mean.ret.cum.all <- res.prev$mean.ret.cum.all
  
}

rownames(mean.ret.cum.all) <- c(1:nrow(mean.ret.cum.all))

## Evaluation for monthly and cumulative return predictions:
eval.pr.mean <- EVAL(y_predictions = mean.ret.mon.all, y_actual = y_test$y_test,
                     y_predictions.cum = mean.ret.cum.all, 
                     y_actual.cum = y_test$y_test.cum)
eval.pr.mean <- do.call(rbind, eval.pr.mean)
round(eval.pr.mean,4)
rowMeans(eval.pr.mean)

```

### 3.2.2 Random Forest
Before you execute the next chunk, you might consider to just import the resulting tables for your input parameters (if available) in section 5.1. The reason for that is that depending whether you use hyperparameter tuning and/or cross validation, the computation can take up to two hours if you only use one core (i.e. cluster == NULL)! But even with seven or eight clusters you might wait 40 minutes or so. Hence, consider just importing the resulting tables.

However, if no results are available for your input parameters, the predictions are calculated in the next chunk. We run the return predictions separately from the portfolio strategies for two reasons. First, the predictions (need to) stay the same for the different portfolio strategies. Second, by running the predictions only once, we reduce the computational effort dramatically (because the out-of-sample predictions need to be calculated only once [instead of the quantity of our portfolio strategies]) and we don't have to set a seed every time we're running the model.

*Note: The model will run with the input parameters you specified at the beginning of this chapter!*

```{r Return Predictions - Compute Random Forest, warning=FALSE}
# If no Z-Score trans is wished
tmp <- ret
# If Z-score transformation is wished
if(trans.Z == T){
  tmp <- Z.TRANS(ret = ret, Names = Names, last = last)
}
# Initial number of training rows:
train.rows <- Train.Rows(ret = tmp, train.perc = train.perc)
# Compute EMAs with max. 5 years of data laying back for Macro variables:
macro.ema <- TRANS.MACRO(data = macro, lookback = lookback)
# All test values
y_test <- Test_DS(ret = tmp, train.rows = train.rows, horizon = horizon)
if(!is.null(clusters)){
  print("!!Attention: You set the variable clusters. Don't perform several other (complex) parallel tasks on your machine while the loop is running!!")
}
if(round(train.perc*nrow(ret)-lag,0) < (horizon+1)){
  print("!!ATTENTION: INTERFERENCE OF INITIAL TRAINING ROWS WITH TIME LAG AND HORIZON --> RANDOM FOREST CAN'T BE EXECUTED!!")
}
if((limit-lag) < (horizon+1)){
  print("!!ATTENTION: INTERFERENCE OF LIMIT WITH TIME LAG AND HORIZON --> RANDOM FOREST CAN'T BE EXECUTED!!")
}
t=1

## Start predictions:
while(t<nrow(y_test$y_test)){
  
  input <- Train_DS(ret = tmp, macro.ema = macro.ema, train.rows = train.rows, 
                    lag = lag, limit = limit)
  
  res <- RANDOM_FOREST(input = input, horizon = horizon, y_test = y_test, counter =  t, old.forecasts = old.forecasts,
                       cum.perf = cum.perf, tune_grid = tune_grid, train_control = train_control, clusters = clusters, 
                       limit = limit, n.trees = n.trees)
  
  t <- res$counter
  train.rows <- res$train.rows
  old.forecasts <- res$old.forecasts
  cum.perf <- res$cum.perf
  
}

## Extract return predictions:
monthly.pred <- do.call(cbind, res$old.forecasts)
cumulative.pred <- do.call(cbind, res$cum.perf)

## Evaluation for monthly and cumulative return predictions:
eval <- EVAL(y_predictions = res$old.forecasts, y_actual = y_test$y_test,
             y_predictions.cum = res$cum.perf, y_actual.cum = y_test$y_test.cum)
eval <- do.call(rbind, eval)
round(eval,4)
rowMeans(eval)

```

Note that if you set a "limit", even though the index "train.rows" returns all rows (for the last iteration), for the computation only all the last "limit" rows were used, this is because the training set is created within the function "Train_DS" which adjusts the training data set according to their limit, but doesn't return the adjusted "train.rows". Hence, the desired number of rows (according to the variable "limit") is used for the training data set.

## 3.3 Backtests
In this subsections the specific portfolios are formed upon the return predictions in subsection 3.2 (if there are any). Their performance is evaluated upon the out-of-sample (backtesting) period determined by the input variable "train.perc" (i.e. the other half will be used as the backtesting period). As before we use a walk forward approach with or without a "lookback" limit defined by the input variable "limit".\
A new portfolio is formed after each "horizon" (see input parameters) months (i.e. after "horizon" months a rebalancing is performed).\
Note that all performance-based evaluations for the various strategies (section 3.1.4) are also performed in this subsections after the backtests are executed.

### 3.3.1 Benchmarks
For that, we start with the ("easier") benchmark strategies.

#### 3.3.1.1 Buy-and-Hold MSCI World
Since, the buy-and-hold strategy is only evaluated for one ETF and we know the time frame of the backtesting period, no loop is required and the performance computation can be done in a vectorized way. Also note, that here we have no information about the turnover because we only buy the asset once and then no rebalancing is performed. Hence, this measure becomes superfluous.

```{r, warning=FALSE}
train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
BT.Dates <- index(y_test$y_test)
RF <- rf

## Start the backtest
res.bench <- B.A.H(bench = bench, BT.Dates = BT.Dates, trans.costs = trans.costs, TER.monthly = TER.monthly, RF = rf, VaR.CI = VaR.CI)

## Summary statistics:
stat.B.A.H <- do.call(rbind, res.bench)[,-ncol(do.call(rbind, res.bench))]
stat.B.A.H

## Distribution of returns:
tmp.nocost <- res.bench$`no costs`$ret.noCosts
colnames(tmp.nocost) <- "BuyandHold.noCost"
tmp.50bps <- res.bench$`50bps`$ret.Costs
colnames(tmp.50bps) <- "BuyandHold.50bps"
DISTRIBUTION(res = as.data.frame(do.call(cbind,list(BuyandHold.NoCosts = tmp.nocost,
                                                    BuyandHold.50bps = tmp.50bps))))

## Positional exposure:
# == Is always one for the single ETF case

```

Note that the Maximum Drawdown is the same for all transaction costs because the first period of the MDD doesn't start in the first observation (month). Only then the different transaction costs would have an influence on the MDD. Also since the total costs (TER) stay the same for all return vectors they also don't affect the MDD.

#### 3.3.1.2 50-50 MSCI World & 20Y+ US Gov Bond
The backtest for the 50-50 benchmark is executed via the LONG.ONLY function defined in section 3.1.5.3.

```{r, warning=FALSE}
train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
BT.Dates <- index(y_test$y_test)
B.a.H <- bench[BT.Dates,]
B.a.H <- cbind(B.a.H, y_test$y_test[,"Y20+ Treasury Bond"])
colnames(B.a.H) <- c("MSCI World", "Y20+ Treasury Bond")
counter = 1
t = 1
portf.EW.all <- list()
portf.RW.all <- list()
all.ret.mon.portf.EW <- NULL
all.ret.mon.portf.RW <- NULL
res.50_50 <- NULL

## Start backtest:
while(counter<nrow(y_test$y_test)){
  
  #print(t)
  
  res.50_50 <- LONG.ONLY(y_test = B.a.H, cum.pred = NULL, use.long.only = NULL, counter = counter, 
                         t = t, horizon = horizon, portf.EW.all = portf.EW.all, portf.RW.all = list(),
                         all.ret.mon.portf.EW = all.ret.mon.portf.EW, all.ret.mon.portf.RW = NULL, fix.tc = fix.tc,
                         trans.costs = trans.costs, TER.monthly = TER.monthly, res.all = res.50_50)
  t <- res.50_50$t
  counter <- res.50_50$counter
  portf.EW.all <- res.50_50$portf.EW.all
  all.ret.mon.portf.EW <- res.50_50$ret.portf.EW$`No costs`$`Monthly Portfolio Return`
  
}

## Summary statistics:
stat.B.A.H <- STATISTICS(res = res.50_50$ret.portf.EW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
stat.B.A.H

## Distribution of returns:
# ATTENTION: THE NAMING OF THE VECTORS IS ESSENTIAL AND HAS TO FOLLOW THE SEQUENCE "WEIGHTINGTYPE.COSTS"
DISTRIBUTION(res = as.data.frame(do.call(cbind,list(EquallyWeightedBench.NoCosts = res.50_50$ret.portf.EW$`No costs`$`Monthly Portfolio Return`,
                                                    EquallyWeightedBench.50bps = res.50_50$ret.portf.EW$`50bps`$`Monthly Portfolio Return`))))

## Positional exposure:
EXPOSURE(weights.init = portf.EW.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)

```

### 3.3.2 Prevailing Mean Method
Next, we are going to test the portfolios which are built upon the return predictions of the Prevailing Mean method. Therefore, we are evaluating both weighting methods (equally and rank weighted) for the long-only and long-short portfolios as well as the minimum variance optimization procedure.

#### 3.3.2.1 Long-Only

```{r, warning=FALSE}
# If no Z-Score trans is wished
tmp <- ret
# If Z-score transformation is wished
if(trans.Z == T){
  tmp <- Z.TRANS(ret = ret, Names = Names, last = last)
}
train.rows <- Train.Rows(ret = tmp, train.perc = train.perc)
dates <- index(Test_DS(ret = tmp, train.rows = train.rows, horizon = horizon)$y_test)
y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
y_test$y_test <- y_test$y_test[dates,]
counter = 1
t = 1
portf.EW.all <- list()
portf.RW.all <- list()
all.ret.mon.portf.EW <- NULL
all.ret.mon.portf.RW <- NULL
res.PR.LO <- NULL

## Start the backtest
while(counter < nrow(y_test$y_test)){
  
  #print(t)
  
  res.PR.LO <- LONG.ONLY(y_test = y_test$y_test, cum.pred = mean.ret.cum.all, use.long.only = use.long.only,
                          counter = counter, t = t, horizon = horizon, portf.EW.all = portf.EW.all, portf.RW.all = portf.RW.all,
                          all.ret.mon.portf.EW = all.ret.mon.portf.EW, all.ret.mon.portf.RW = all.ret.mon.portf.RW, fix.tc = fix.tc,
                          trans.costs = trans.costs, TER.monthly = TER.monthly, res.all = res.PR.LO)
  
  t <- res.PR.LO$t
  counter <- res.PR.LO$counter
  # Extract initial weights
  portf.EW.all <- res.PR.LO$portf.EW.all
  portf.RW.all <- res.PR.LO$portf.RW.all
  # All other performance results
  all.ret.mon.portf.EW <- res.PR.LO$ret.portf.EW$`No costs`$`Monthly Portfolio Return`
  all.ret.mon.portf.RW <- res.PR.LO$ret.portf.RW$`No costs`$`Monthly Portfolio Return`
}

## Summary statistics:
# EW:
stat.EW.L.O.PR <- STATISTICS(res = res.PR.LO$ret.portf.EW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
# RW:
stat.RW.L.O.PR <- STATISTICS(res = res.PR.LO$ret.portf.RW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
LO.PR <- list(Equally.Weighted.L.O = stat.EW.L.O.PR, Rank.Weighted.L.O = stat.RW.L.O.PR)
LO.PR

## Distribution of returns:
# ATTENTION: THE NAMING OF THE VECTORS IS ESSENTIAL AND HAS TO FOLLOW THE SEQUENCE "WEIGHTINGTYPE.COSTS"
DISTRIBUTION(res = as.data.frame(do.call(cbind,list(EquallyWeightedLO.NoCosts = res.PR.LO$ret.portf.EW$`No costs`$`Monthly Portfolio Return`,
                                                    EquallyWeightedLO.50bps = res.PR.LO$ret.portf.EW$`50bps`$`Monthly Portfolio Return`,
                                                    RankWeightedLO.NoCosts = res.PR.LO$ret.portf.RW$`No costs`$`Monthly Portfolio Return`,
                                                    RankWeightedLO.50bps = res.PR.LO$ret.portf.RW$`50bps`$`Monthly Portfolio Return`))))

## Positional exposure:
# EW:
EXPOSURE(weights.init = portf.EW.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)
# RW:
EXPOSURE(weights.init = portf.RW.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)

```

#### 3.3.2.2 Long-Short Portfolio

```{r, warning=FALSE}
train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
counter = 1
t = 1
portf.EW.all <- list()
portf.RW.all <- list()
all.ret.mon.portf.EW <- NULL
all.ret.mon.portf.RW <- NULL
res.PR.L.S <- NULL

while(counter < nrow(y_test$y_test)){
  
  #print(t)
  
  res.PR.L.S <- LONG.SHORT(y_test = y_test$y_test, cum.pred = mean.ret.cum.all, disc.positive = disc.positive, 
                           use.long.short = use.long.short, lend = lend, counter = counter, t = t, horizon = horizon, 
                           portf.EW.all = portf.EW.all, portf.RW.all = portf.RW.all, all.ret.mon.portf.EW = all.ret.mon.portf.EW, 
                           all.ret.mon.portf.RW = all.ret.mon.portf.RW, fix.tc = fix.tc, trans.costs = trans.costs, 
                           TER.monthly = TER.monthly, res.all = res.PR.L.S)
  
  t <- res.PR.L.S$t
  counter <- res.PR.L.S$counter
  # Extract initial weights
  portf.EW.all <- res.PR.L.S$portf.EW.all
  portf.RW.all <- res.PR.L.S$portf.RW.all
  # All other performance results
  all.ret.mon.portf.EW <- res.PR.L.S$ret.portf.EW$`No costs`$`Monthly Portfolio Return`
  all.ret.mon.portf.RW <- res.PR.L.S$ret.portf.RW$`No costs`$`Monthly Portfolio Return`
}

## Summary statistics:
# EW:
stat.EW.L.S.PR <- STATISTICS(res = res.PR.L.S$ret.portf.EW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
# RW:
stat.RW.L.S.PR <- STATISTICS(res = res.PR.L.S$ret.portf.RW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
LS.PR <- list(Equally.Weighted.L.S = stat.EW.L.S.PR, Rank.Weighted.L.S = stat.RW.L.S.PR)
LS.PR

## Distribution of returns:
# ATTENTION: THE NAMING OF THE VECTORS IS ESSENTIAL AND HAS TO FOLLOW THE SEQUENCE "WEIGHTINGTYPE.COSTS"
DISTRIBUTION(res = as.data.frame(do.call(cbind,list(EquallyWeightedLO.NoCosts = res.PR.L.S$ret.portf.EW$`No costs`$`Monthly Portfolio Return`,
                                                    EquallyWeightedLO.50bps = res.PR.L.S$ret.portf.EW$`50bps`$`Monthly Portfolio Return`,
                                                    RankWeightedLO.NoCosts = res.PR.L.S$ret.portf.RW$`No costs`$`Monthly Portfolio Return`,
                                                    RankWeightedLO.50bps = res.PR.L.S$ret.portf.RW$`50bps`$`Monthly Portfolio Return`))))

## Positional exposure:
# EW:
EXPOSURE(weights.init = portf.EW.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)
# RW:
EXPOSURE(weights.init = portf.RW.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)

```

#### 3.3.2.3 Minimum Variance
Now the ETFs are pre-selected according to the Prevailing Mean model.

```{r, warning=FALSE}
train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
counter = 1
t = 1
portf.sample.all <- list()
portf.shrink.all <- list()
all.ret.mon.portf.sample <- NULL
all.ret.mon.portf.shrink <- NULL
res.MV.PR <- NULL

while(counter < nrow(y_test$y_test)){
  
  #print(t)
  
  res.MV.PR <- MIN.VAR(ret = ret, train.rows = train.rows, y_test = y_test$y_test, cum.pred = mean.ret.cum.all,
                       use.minvar = use.minvar,counter = counter, t = t, horizon = horizon,
                       portf.shrink.all = portf.shrink.all, portf.sample.all = portf.sample.all,trans.costs = trans.costs, 
                       TER.monthly = TER.monthly, all.ret.mon.portf.shrink = all.ret.mon.portf.shrink,
                       all.ret.mon.portf.sample = all.ret.mon.portf.sample, limit = limit, fix.tc = fix.tc, 
                       min.max = min.max, res.all = res.MV.PR)
  
  train.rows <- res.MV.PR$train.rows
  t <- res.MV.PR$t
  counter <- res.MV.PR$counter
  # Extract initial weights
  portf.sample.all <- res.MV.PR$portf.sample.all
  portf.shrink.all <- res.MV.PR$portf.shrink.all
  # All other performance results
  all.ret.mon.portf.sample<- res.MV.PR$ret.portf.sample$`No costs`$`Monthly Portfolio Return`
  all.ret.mon.portf.shrink <- res.MV.PR$ret.portf.shrink$`No costs`$`Monthly Portfolio Return`
}

## Summary statistics:
# EW:
stat.MV.sample.PR <- STATISTICS(res = res.MV.PR$ret.portf.sample, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
# RW:
stat.MV.shrink.PR <- STATISTICS(res = res.MV.PR$ret.portf.shrink, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
MV.PR <- list(sample.MV = stat.MV.sample.PR, shrink.MV = stat.MV.shrink.PR)
MV.PR

## Distribution of returns:
# ATTENTION: THE NAMING OF THE VECTORS IS ESSENTIAL AND HAS TO FOLLOW THE SEQUENCE "WEIGHTINGTYPE.COSTS"
DISTRIBUTION(res = as.data.frame(do.call(cbind,list(SampleMV.NoCosts = res.MV.PR$ret.portf.sample$`No costs`$`Monthly Portfolio Return`,
                                                    SampleMV.50bps = res.MV.PR$ret.portf.sample$`50bps`$`Monthly Portfolio Return`,
                                                    ShrinkMV.NoCosts = res.MV.PR$ret.portf.shrink$`No costs`$`Monthly Portfolio Return`,
                                                    ShrinkMV.50bps = res.MV.PR$ret.portf.shrink$`50bps`$`Monthly Portfolio Return`))))

## Positional exposure:
# EW:
EXPOSURE(weights.init = portf.sample.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)
# RW:
EXPOSURE(weights.init = portf.shrink.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)

```

### 3.3.3 Random Forest Method
Next, we are going to test the portfolios which are built upon the return predictions of the Random Forest forecast method. Therefore, we are evaluating both weighting methods (equally and rank weighted) for the long-only and long-short portfolios as well as the minimum variance optimization procedure.

#### 3.3.3.1 Long-Only

```{r, warning=FALSE}
# If no Z-Score trans is wished
tmp <- ret
# If Z-score transformation is wished
if(trans.Z == T){
  tmp <- Z.TRANS(ret = ret, Names = Names, last = last)
}
train.rows <- Train.Rows(ret = tmp, train.perc = train.perc)
dates <- index(Test_DS(ret = tmp, train.rows = train.rows, horizon = horizon)$y_test)
y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
y_test$y_test <- y_test$y_test[dates,]
counter = 1
t = 1
portf.EW.all <- list()
portf.RW.all <- list()
all.ret.mon.portf.EW <- NULL
all.ret.mon.portf.RW <- NULL
res.RF.LO <- NULL
cumulative.pred <- as.matrix(cumulative.pred)
colnames(cumulative.pred) <- colnames(mean.ret.cum.all)

## Start the backtest
while(counter < nrow(y_test$y_test)){
  
  #print(t)
  
  res.RF.LO <- LONG.ONLY(y_test = y_test$y_test, cum.pred = cumulative.pred, use.long.only = use.long.only,
                          counter = counter, t = t, horizon = horizon, portf.EW.all = portf.EW.all, portf.RW.all = portf.RW.all,
                          all.ret.mon.portf.EW = all.ret.mon.portf.EW, all.ret.mon.portf.RW = all.ret.mon.portf.RW, 
                          fix.tc = fix.tc, trans.costs = trans.costs, TER.monthly = TER.monthly, res.all = res.RF.LO)
  
  t <- res.RF.LO$t
  counter <- res.RF.LO$counter
  # Extract initial weights
  portf.EW.all <- res.RF.LO$portf.EW.all
  portf.RW.all <- res.RF.LO$portf.RW.all
  # All other performance results
  all.ret.mon.portf.EW <- res.RF.LO$ret.portf.EW$`No costs`$`Monthly Portfolio Return`
  all.ret.mon.portf.RW <- res.RF.LO$ret.portf.RW$`No costs`$`Monthly Portfolio Return`
}

## Summary statistics:
# EW:
stat.EW.LO.RF <- STATISTICS(res = res.RF.LO$ret.portf.EW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
# RW:
stat.RW.LO.RF <- STATISTICS(res = res.RF.LO$ret.portf.RW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
LO.RF <- list(Equally.Weighted.L.O = stat.EW.LO.RF, Rank.Weighted.L.O = stat.RW.LO.RF)
LO.RF

## Distribution of returns:
DISTRIBUTION(res = as.data.frame(do.call(cbind,list(EquallyWeightedRF.NoCosts = res.RF.LO$ret.portf.EW$`No costs`$`Monthly Portfolio Return`,
                                                    EquallyWeightedRF.50bps = res.RF.LO$ret.portf.EW$`50bps`$`Monthly Portfolio Return`,
                                                    RankWeightedRF.NoCosts = res.RF.LO$ret.portf.RW$`No costs`$`Monthly Portfolio Return`,
                                                    RankWeightedRF.50bps = res.RF.LO$ret.portf.RW$`50bps`$`Monthly Portfolio Return`))))

## Positional exposure:
# EW:
EXPOSURE(weights.init = portf.EW.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)
# RW:
EXPOSURE(weights.init = portf.RW.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)

```

#### 3.3.3.2 Long-Short Portfolio

```{r, warning=FALSE}
train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
counter = 1
t = 1
portf.EW.all <- list()
portf.RW.all <- list()
all.ret.mon.portf.EW <- NULL
all.ret.mon.portf.RW <- NULL
res.RF.L.S <- NULL
cumulative.pred <- as.matrix(cumulative.pred)
colnames(cumulative.pred) <- colnames(mean.ret.cum.all)

while(counter < nrow(y_test$y_test)){
  
  #print(t)
  
  res.RF.L.S <- LONG.SHORT(y_test = y_test$y_test, cum.pred = cumulative.pred, use.long.short = use.long.short, lend = lend,
                           counter = counter, t = t, horizon = horizon, portf.EW.all = portf.EW.all, portf.RW.all = portf.RW.all,
                           all.ret.mon.portf.EW = all.ret.mon.portf.EW, all.ret.mon.portf.RW = all.ret.mon.portf.RW, fix.tc = fix.tc,
                           trans.costs = trans.costs, TER.monthly = TER.monthly, res.all = res.RF.L.S)
  
  t <- res.RF.L.S$t
  counter <- res.RF.L.S$counter
  # Extract initial weights
  portf.EW.all <- res.RF.L.S$portf.EW.all
  portf.RW.all <- res.RF.L.S$portf.RW.all
  # All other performance results
  all.ret.mon.portf.EW <- res.RF.L.S$ret.portf.EW$`No costs`$`Monthly Portfolio Return`
  all.ret.mon.portf.RW <- res.RF.L.S$ret.portf.RW$`No costs`$`Monthly Portfolio Return`
}

## Summary statistics:
# EW:
stat.EW.L.S.RF <- STATISTICS(res = res.RF.L.S$ret.portf.EW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
# RW:
stat.RW.L.S.RF <- STATISTICS(res = res.RF.L.S$ret.portf.RW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
LS.RF <- list(Equally.Weighted.L.S = stat.EW.L.S.RF, Rank.Weighted.L.S = stat.RW.L.S.RF)
LS.RF

## Distribution of returns:
# ATTENTION: THE NAMING OF THE VECTORS IS ESSENTIAL AND HAS TO FOLLOW THE SEQUENCE "WEIGHTINGTYPE.COSTS"
DISTRIBUTION(res = as.data.frame(do.call(cbind,list(EquallyWeightedLO.NoCosts = res.RF.L.S$ret.portf.EW$`No costs`$`Monthly Portfolio Return`,
                                                    EquallyWeightedLO.50bps = res.RF.L.S$ret.portf.EW$`50bps`$`Monthly Portfolio Return`,
                                                    RankWeightedLO.NoCosts = res.RF.L.S$ret.portf.RW$`No costs`$`Monthly Portfolio Return`,
                                                    RankWeightedLO.50bps = res.RF.L.S$ret.portf.RW$`50bps`$`Monthly Portfolio Return`))))

## Positional exposure:
# EW:
EXPOSURE(weights.init = portf.EW.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)
# RW:
EXPOSURE(weights.init = portf.RW.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)

```

#### 3.3.3.3 Minimum Variance
Now the ETFs are pre-selected according to the Prevailing Mean model.

```{r, warning=FALSE}
train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
counter = 1
t = 1
portf.sample.all <- list()
portf.shrink.all <- list()
all.ret.mon.portf.sample <- NULL
all.ret.mon.portf.shrink <- NULL
res.MV.RF <- NULL
cumulative.pred <- as.matrix(cumulative.pred)
colnames(cumulative.pred) <- colnames(mean.ret.cum.all)

while(counter < nrow(y_test$y_test)){
  
  #print(t)
  
  res.MV.RF <- MIN.VAR(ret = ret, train.rows = train.rows, y_test = y_test$y_test, cum.pred = cumulative.pred, 
                       use.minvar = use.minvar, counter = counter, t = t, horizon = horizon,
                       portf.shrink.all = portf.shrink.all, portf.sample.all = portf.sample.all,
                       trans.costs = trans.costs, TER.monthly = TER.monthly, all.ret.mon.portf.shrink = all.ret.mon.portf.shrink,
                       all.ret.mon.portf.sample = all.ret.mon.portf.sample, limit = limit, fix.tc = fix.tc, min.max = min.max, 
                       res.all = res.MV.RF)
  
  train.rows <- res.MV.RF$train.rows
  t <- res.MV.RF$t
  counter <- res.MV.RF$counter
  # Extract initial weights
  portf.sample.all <- res.MV.RF$portf.sample.all
  portf.shrink.all <- res.MV.RF$portf.shrink.all
  # All other performance results
  all.ret.mon.portf.sample<- res.MV.RF$ret.portf.sample$`No costs`$`Monthly Portfolio Return`
  all.ret.mon.portf.shrink <- res.MV.RF$ret.portf.shrink$`No costs`$`Monthly Portfolio Return`
}

## Summary statistics:
# EW:
stat.MV.sample.RF <- STATISTICS(res = res.MV.RF$ret.portf.sample, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
# RW:
stat.MV.shrink.RF <- STATISTICS(res = res.MV.RF$ret.portf.shrink, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
MV.RF <- list(sample.MV = stat.MV.sample.RF, shrink.MV = stat.MV.shrink.RF)
MV.RF

## Distribution of returns:
# ATTENTION: THE NAMING OF THE VECTORS IS ESSENTIAL AND HAS TO FOLLOW THE SEQUENCE "WEIGHTINGTYPE.COSTS"
DISTRIBUTION(res = as.data.frame(do.call(cbind,list(SampleMV.NoCosts = res.MV.RF$ret.portf.sample$`No costs`$`Monthly Portfolio Return`,
                                                    SampleMV.50bps = res.MV.RF$ret.portf.sample$`50bps`$`Monthly Portfolio Return`,
                                                    ShrinkMV.NoCosts = res.MV.RF$ret.portf.shrink$`No costs`$`Monthly Portfolio Return`,
                                                    ShrinkMV.50bps = res.MV.RF$ret.portf.shrink$`50bps`$`Monthly Portfolio Return`))))

## Positional exposure:
# EW:
EXPOSURE(weights.init = portf.sample.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)
# RW:
EXPOSURE(weights.init = portf.shrink.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)

```

### 3.3.4 Minimum Variance Raw
Means, only long-only weight constraint is imposed and all available ETFs are used in all portfolios.

```{r, warning=FALSE}
train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
counter = 1
t = 1
portf.sample.all <- list()
portf.shrink.all <- list()
all.ret.mon.portf.sample <- NULL
all.ret.mon.portf.shrink <- NULL
res.MV.raw <- NULL
use.minvar = 1 # Use all ETFs
min.max = c(0,1)

while(counter < nrow(y_test$y_test)){
  
  #print(t)
  
  res.MV.raw <- MIN.VAR(ret = ret, train.rows = train.rows, y_test = y_test$y_test, cum.pred = mean.ret.cum.all,
                        use.minvar = use.minvar,counter = counter, t = t, horizon = horizon, 
                        portf.shrink.all = portf.shrink.all, portf.sample.all = portf.sample.all,
                        trans.costs = trans.costs, TER.monthly = TER.monthly, all.ret.mon.portf.shrink = all.ret.mon.portf.shrink,
                        all.ret.mon.portf.sample = all.ret.mon.portf.sample, limit = limit, fix.tc = fix.tc,
                        min.max = min.max, res.all = res.MV.raw)
  
  train.rows <- res.MV.raw$train.rows
  t <- res.MV.raw$t
  counter <- res.MV.raw$counter
  # Extract initial weights
  portf.sample.all <- res.MV.raw$portf.sample.all
  portf.shrink.all <- res.MV.raw$portf.shrink.all
  # All other performance results
  all.ret.mon.portf.sample<- res.MV.raw$ret.portf.sample$`No costs`$`Monthly Portfolio Return`
  all.ret.mon.portf.shrink <- res.MV.raw$ret.portf.shrink$`No costs`$`Monthly Portfolio Return`
}

## Summary statistics:
# EW:
stat.MV.sample <- STATISTICS(res = res.MV.raw$ret.portf.sample, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
# RW:
stat.MV.shrink <- STATISTICS(res = res.MV.raw$ret.portf.shrink, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
list(sample.MV = stat.MV.sample, shrink.MV = stat.MV.shrink)

## Distribution of returns:
# ATTENTION: THE NAMING OF THE VECTORS IS ESSENTIAL AND HAS TO FOLLOW THE SEQUENCE "WEIGHTINGTYPE.COSTS"
DISTRIBUTION(res = as.data.frame(do.call(cbind,list(SampleMV.NoCosts = res.MV.raw$ret.portf.sample$`No costs`$`Monthly Portfolio Return`,
                                                    SampleMV.50bps = res.MV.raw$ret.portf.sample$`50bps`$`Monthly Portfolio Return`,
                                                    ShrinkMV.NoCosts = res.MV.raw$ret.portf.shrink$`No costs`$`Monthly Portfolio Return`,
                                                    ShrinkMV.50bps = res.MV.raw$ret.portf.shrink$`50bps`$`Monthly Portfolio Return`))))

## Positional exposure:
# EW:
EXPOSURE(weights.init = portf.sample.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)
# RW:
EXPOSURE(weights.init = portf.shrink.all, horizon = horizon, y_test = y_test$y_test, asset.classes = asset.classes)

```

## 3.4 Wealth Development Simulation
In this subsection we further evaluate the performance of the portfolio strategies by analyzing the wealth development of the methods. Since the differences between the transaction costs scenarios are not that significant we are only going to compare the "no costs" scenario with the "50bps" scenario.

### 3.4.1 Benchmarks

#### 3.4.1.1 Buy-and-Hold MSCI World
e start by executing the wealth simulation.

```{r, warning=FALSE}
BAH.noCost <- WEALTH.SIMULATION(ret = res.bench$`no costs`$ret.noCosts, init = init)
BAH.50bps <- WEALTH.SIMULATION(ret = res.bench$`50bps`$ret.Costs, init = init)
```

Next, we plot the no cost scenario versus the 50bps TC scenario. Therefore, we first need to extract the out-of-sample dates.

```{r, warning=FALSE}
# Extract out-of-sample dates
date <- index(BAH.noCost$Wealth)

# Representation of EW and RW strategy each with noCost and 50bps scenario in one plot
ggplot(BAH.noCost$Wealth) +
  geom_line(aes(x=date, y = Wealth, color = "Buy-and-Hold Benchmark no Costs")) +
  geom_line(aes(x=date, y = BAH.50bps$Wealth, color = "Buy-and-Hold Benchmark 50bps")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual("Legend", values = c("Buy-and-Hold Benchmark no Costs" = "skyblue", "Buy-and-Hold Benchmark 50bps" = "orange")) +
  labs(title = "Wealth Development Buy-and-Hold Benchmark", x = "Dates", y = "Wealth") +
  theme_minimal()
```

Now let's have a look at the Maximum Drawdowns.

```{r, warning=FALSE}
# Show Maximum Drawdowns
rbind(BAHBenchmark.noCosts = BAH.noCost$maxDraw, BAHBenchmark.50bps = BAH.50bps$maxDraw)
```

Last but not least, let's compare the absolute and relative returns for the given scenarios

```{r, warning=FALSE}
# Display absolute and relative returns in a table:
returns.BAHBench.Wealth <- list(BAH.abs.noCost = BAH.noCost$abs.ret, 
                                  BAH.abs.50bps = BAH.50bps$abs.ret,
                                  BAH.rel.noCost = BAH.noCost$rel.ret, 
                                  BAH.rel.50bps = BAH.50bps$rel.ret)

returns.BAHBench.Wealth <- bind_rows(lapply(names(returns.BAHBench.Wealth), function(name){
  data_frame <- data.frame(value = returns.BAHBench.Wealth[[name]])
  data_frame$Type <- name  # Add the list name as a new column
  return(data_frame)
}))

returns.BAHBench.Wealth <- returns.BAHBench.Wealth %>%
    mutate(
      Strategy = ifelse(grepl("^BAH", Type), "Buy-and-Hold"),
      Return_Type = ifelse(grepl("rel", Type), "rel", "abs"),
      Cost = ifelse(grepl("noCost", Type), "noCost", "50bps")
      ) %>%
  select(-Type)

# Reshape the data to a wide format table
returns.BAHBench.Wealth <- returns.BAHBench.Wealth %>%
  pivot_wider(names_from = Return_Type, values_from = value) %>%
  arrange(Strategy, Cost)

returns.BAHBench.Wealth

```

#### 3.4.1.2 50-50 MSCI World & 20Y+ US Gov Bond
We start by executing the wealth simulation.

```{r, warning=FALSE}
eqBench.noCost <- WEALTH.SIMULATION(ret = res.50_50$ret.portf.EW$`No costs`$`Monthly Portfolio Return`, init = init)
eqBench.50bps <- WEALTH.SIMULATION(ret = res.50_50$ret.portf.EW$`50bps`$`Monthly Portfolio Return`, init = init)
```

Next, we plot the no cost scenario versus the 50bps TC scenario. Therefore, we first need to extract the out-of-sample dates.

```{r, warning=FALSE}
# Extract out-of-sample dates
date <- index(eqBench.noCost$Wealth)

# Representation of EW and RW strategy each with noCost and 50bps scenario in one plot
ggplot(eqBench.noCost$Wealth) +
  geom_line(aes(x=date, y = Wealth, color = "50-50 Benchmark no Costs")) +
  geom_line(aes(x=date, y = eqBench.50bps$Wealth, color = "50-50 Benchmark 50bps")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual("Legend", values = c("50-50 Benchmark no Costs" = "skyblue", "50-50 Benchmark 50bps" = "orange")) +
  labs(title = "Wealth Development 50-50 Benchmark", x = "Dates", y = "Wealth") +
  theme_minimal()
```

Now let's have a look at the Maximum Drawdowns.

```{r, warning=FALSE}
# Show Maximum Drawdowns
rbind(EquallyWeightedBenchmark.noCosts = eqBench.noCost$maxDraw, EquallyWeightedBenchmark.50bps = eqBench.50bps$maxDraw)
```

Last but not least, let's compare the absolute and relative returns for the given scenarios

```{r, warning=FALSE}
# Display absolute and relative returns in a table:
returns.50_50Bench.Wealth <- list(EquallyWeightedBenchmark.abs.noCost = eqBench.noCost$abs.ret, 
                                  EquallyWeightedBenchmark.abs.50bps = eqBench.50bps$abs.ret,
                                  EquallyWeightedBenchmark.rel.noCost = eqBench.noCost$rel.ret, 
                                  EquallyWeightedBenchmark.rel.50bps = eqBench.50bps$rel.ret)

returns.50_50Bench.Wealth <- bind_rows(lapply(names(returns.50_50Bench.Wealth), function(name){
  data_frame <- data.frame(value = returns.50_50Bench.Wealth[[name]])
  data_frame$Type <- name  # Add the list name as a new column
  return(data_frame)
}))

returns.50_50Bench.Wealth <- returns.50_50Bench.Wealth %>%
    mutate(
      Strategy = ifelse(grepl("^EquallyWeightedBenchmark", Type), "Benchmark"),
      Return_Type = ifelse(grepl("rel", Type), "rel", "abs"),
      Cost = ifelse(grepl("noCost", Type), "noCost", "50bps")
      ) %>%
  select(-Type)

# Reshape the data to a wide format table
returns.50_50Bench.Wealth <- returns.50_50Bench.Wealth %>%
  pivot_wider(names_from = Return_Type, values_from = value) %>%
  arrange(Strategy, Cost)

returns.50_50Bench.Wealth

```

### 3.4.2 Prevailing Mean Method

#### 3.4.2.1 Long-Only
We start by executing the wealth simulation.

```{r, warning=FALSE}
# Compute Wealth
EW.PR.noCost <- WEALTH.SIMULATION(ret = res.PR.LO$ret.portf.EW$`No costs`$`Monthly Portfolio Return`, init = init)
EW.PR.50bps <- WEALTH.SIMULATION(ret = res.PR.LO$ret.portf.EW$`50bps`$`Monthly Portfolio Return`, init = init)
RW.PR.noCost <- WEALTH.SIMULATION(ret = res.PR.LO$ret.portf.RW$`No costs`$`Monthly Portfolio Return`, init = init)
RW.PR.50bps <- WEALTH.SIMULATION(ret = res.PR.LO$ret.portf.RW$`50bps`$`Monthly Portfolio Return`, init = init)
```

Next, we plot the no cost scenario versus the 50bps TC scenario. Therefore, we first need to extract the out-of-sample dates.

```{r, warning=FALSE}
# Extract out-of-sample dates
date <- index(EW.PR.noCost$Wealth)

# Representation of EW and RW strategy each with noCost and 50bps scenario in one plot
ggplot(EW.PR.noCost$Wealth) +
  geom_line(aes(x=date, y = Wealth, color = "Equal weights Wealth no costs")) +
  geom_line(aes(x=date, y = EW.PR.50bps$Wealth, color = "Equal weights Wealth 50bps")) +
  geom_line(aes(x=date, y = RW.PR.noCost$Wealth, color = "Rank weights Wealth no costs")) +
  geom_line(aes(x=date, y = RW.PR.50bps$Wealth, color = "Rank weights Wealth 50bps")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual("Legend", values = c("Equal weights Wealth no costs" = "blue", "Equal weights Wealth 50bps" = "red",
                                          "Rank weights Wealth no costs" = "skyblue", "Rank weights Wealth 50bps" = "orange")) +
  labs(title = "Wealth Development Long Only Prevailing Mean", x = "Dates", y = "Wealth") +
  theme_minimal()
```

Now let's have a look at the Maximum Drawdowns.

```{r, warning=FALSE}
# Show Maximum Drawdowns
rbind(EquallyWeighted.noCosts = EW.PR.noCost$maxDraw, EquallyWeighted.50bps = EW.PR.50bps$maxDraw,
      RankWeighted.noCosts = RW.PR.noCost$maxDraw, RankWeighted.50bps = RW.PR.50bps$maxDraw)
```

Last but not least, let's compare the absolute and relative returns for the given scenarios

```{r, warning=FALSE}
# Display absolute and relative returns in a table:
returns.PR.Wealth <- list(EW.abs.noCost = EW.PR.noCost$abs.ret, EW.abs.50bps = EW.PR.50bps$abs.ret,
                          EW.rel.noCost = EW.PR.noCost$rel.ret, EW.rel.50bps = EW.PR.50bps$rel.ret,
                          RW.abs.noCost = RW.PR.noCost$abs.ret, RW.abs.50bps = RW.PR.50bps$abs.ret,
                          RW.rel.noCost = RW.PR.noCost$rel.ret, RW.rel.50bps = RW.PR.50bps$rel.ret)

returns.PR.Wealth <- bind_rows(lapply(names(returns.PR.Wealth), function(name){
  data_frame <- data.frame(value = returns.PR.Wealth[[name]])
  data_frame$Type <- name  # Add the list name as a new column
  return(data_frame)
}))

# Extract `EW`/`RW`, `rel`/`abs`, and `noCost`/`50bps` from the `Type` column
returns.PR.Wealth <- returns.PR.Wealth %>%
    mutate(
      Strategy = ifelse(grepl("^EW", Type), "EW", "RW"),
      Return_Type = ifelse(grepl("rel", Type), "rel", "abs"),
      Cost = ifelse(grepl("noCost", Type), "noCost", "50bps")
      ) %>%
  select(-Type)  # Remove the original Type column

# Reshape the data to a wide format table
returns.PR.Wealth <- returns.PR.Wealth %>%
  pivot_wider(names_from = Return_Type, values_from = value) %>%
  arrange(Strategy, Cost)

returns.PR.Wealth

```

#### 3.4.2.2 Long-Short Portfolio
We start by executing the wealth simulation.

```{r, warning=FALSE}
# Compute Wealth
EW.PR.noCost <- WEALTH.SIMULATION(ret = res.PR.L.S$ret.portf.EW$`No costs`$`Monthly Portfolio Return`, init = init)
EW.PR.50bps <- WEALTH.SIMULATION(ret = res.PR.L.S$ret.portf.EW$`50bps`$`Monthly Portfolio Return`, init = init)
RW.PR.noCost <- WEALTH.SIMULATION(ret = res.PR.L.S$ret.portf.RW$`No costs`$`Monthly Portfolio Return`, init = init)
RW.PR.50bps <- WEALTH.SIMULATION(ret = res.PR.L.S$ret.portf.RW$`50bps`$`Monthly Portfolio Return`, init = init)
```

Next, we plot the no cost scenario versus the 50bps TC scenario. Therefore, we first need to extract the out-of-sample dates.

```{r, warning=FALSE}
# Extract out-of-sample dates
date <- index(EW.PR.noCost$Wealth)

# Representation of EW and RW strategy each with noCost and 50bps scenario in one plot
ggplot(EW.PR.noCost$Wealth) +
  geom_line(aes(x=date, y = Wealth, color = "Equal weights Wealth no costs")) +
  geom_line(aes(x=date, y = EW.PR.50bps$Wealth, color = "Equal weights Wealth 50bps")) +
  geom_line(aes(x=date, y = RW.PR.noCost$Wealth, color = "Rank weights Wealth no costs")) +
  geom_line(aes(x=date, y = RW.PR.50bps$Wealth, color = "Rank weights Wealth 50bps")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual("Legend", values = c("Equal weights Wealth no costs" = "blue", "Equal weights Wealth 50bps" = "red",
                                          "Rank weights Wealth no costs" = "skyblue", "Rank weights Wealth 50bps" = "orange")) +
  labs(title = "Wealth Development Long-Short Prevailing Mean", x = "Dates", y = "Wealth") +
  theme_minimal()
```

Now let's have a look at the Maximum Drawdowns.

```{r, warning=FALSE}
# Show Maximum Drawdowns
rbind(EquallyWeighted.noCosts = EW.PR.noCost$maxDraw, EquallyWeighted.50bps = EW.PR.50bps$maxDraw,
      RankWeighted.noCosts = RW.PR.noCost$maxDraw, RankWeighted.50bps = RW.PR.50bps$maxDraw)
```

Last but not least, let's compare the absolute and relative returns for the given scenarios

```{r, warning=FALSE}
# Display absolute and relative returns in a table:
returns.PR.Wealth <- list(EW.abs.noCost = EW.PR.noCost$abs.ret, EW.abs.50bps = EW.PR.50bps$abs.ret,
                          EW.rel.noCost = EW.PR.noCost$rel.ret, EW.rel.50bps = EW.PR.50bps$rel.ret,
                          RW.abs.noCost = RW.PR.noCost$abs.ret, RW.abs.50bps = RW.PR.50bps$abs.ret,
                          RW.rel.noCost = RW.PR.noCost$rel.ret, RW.rel.50bps = RW.PR.50bps$rel.ret)

returns.PR.Wealth <- bind_rows(lapply(names(returns.PR.Wealth), function(name){
  data_frame <- data.frame(value = returns.PR.Wealth[[name]])
  data_frame$Type <- name  # Add the list name as a new column
  return(data_frame)
}))

# Extract `EW`/`RW`, `rel`/`abs`, and `noCost`/`50bps` from the `Type` column
returns.PR.Wealth <- returns.PR.Wealth %>%
    mutate(Strategy = ifelse(grepl("^EW", Type), "EW", "RW"),
           Return_Type = ifelse(grepl("rel", Type), "rel", "abs"),
           Cost = ifelse(grepl("noCost", Type), "noCost", "50bps")
           ) %>%
  select(-Type)  # Remove the original Type column

# Reshape the data to a wide format table
returns.PR.Wealth <- returns.PR.Wealth %>%
  pivot_wider(names_from = Return_Type, values_from = value) %>%
  arrange(Strategy, Cost)

returns.PR.Wealth

```

#### 3.4.2.3 Minimum Variance
We start by executing the wealth simulation.

```{r, warning=FALSE}
# Compute Wealth
MVsample.PR.noCost <- WEALTH.SIMULATION(ret = res.MV.PR$ret.portf.sample$`No costs`$`Monthly Portfolio Return`, init = init)
MVsample.PR.50bps <- WEALTH.SIMULATION(ret = res.MV.PR$ret.portf.sample$`50bps`$`Monthly Portfolio Return`, init = init)
MVshrink.PR.noCost <- WEALTH.SIMULATION(ret = res.MV.PR$ret.portf.shrink$`No costs`$`Monthly Portfolio Return`, init = init)
MVshrink.PR.50bps <- WEALTH.SIMULATION(ret = res.MV.PR$ret.portf.shrink$`50bps`$`Monthly Portfolio Return`, init = init)
```

Next, we plot the no cost scenario versus the 50bps TC scenario. Therefore, we first need to extract the out-of-sample dates.

```{r, warning=FALSE}
# Extract out-of-sample dates
date <- index(MVsample.PR.noCost$Wealth)

# Representation of EW and RW strategy each with noCost and 50bps scenario in one plot
ggplot(MVsample.PR.noCost$Wealth) +
  geom_line(aes(x=date, y = Wealth, color = "Sample MV Wealth no costs")) +
  geom_line(aes(x=date, y = MVsample.PR.50bps$Wealth, color = "Sample MV Wealth 50bps")) +
  geom_line(aes(x=date, y = MVshrink.PR.noCost$Wealth, color = "Shrink MV Wealth no costs")) +
  geom_line(aes(x=date, y = MVshrink.PR.50bps$Wealth, color = "Shrink MV Wealth 50bps")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual("Legend", values = c("Sample MV Wealth no costs" = "blue", "Sample MV Wealth 50bps" = "red",
                                          "Shrink MV Wealth no costs" = "skyblue", "Shrink MV Wealth 50bps" = "orange")) +
  labs(title = "Wealth Development MV Prevailing Mean", x = "Dates", y = "Wealth") +
  theme_minimal()
```

Now let's have a look at the Maximum Drawdowns.

```{r, warning=FALSE}
# Show Maximum Drawdowns
rbind(SampleMV.noCosts = MVsample.PR.noCost$maxDraw, SampleMV.50bps = MVsample.PR.50bps$maxDraw,
      ShrinkMV.noCosts = MVshrink.PR.noCost$maxDraw, ShrinkMV.PR.50bps = MVshrink.PR.50bps$maxDraw)
```

Last but not least, let's compare the absolute and relative returns for the given scenarios

```{r, warning=FALSE}
# Display absolute and relative returns in a table:
returns.MV.PR.Wealth <- list(MVsample.abs.noCost = MVsample.PR.noCost$abs.ret, MVsample.abs.50bps = MVsample.PR.50bps$abs.ret,
                             MVsample.rel.noCost = MVsample.PR.noCost$rel.ret, MVsample.rel.50bps = MVsample.PR.50bps$rel.ret,
                             MVshrink.abs.noCost = MVshrink.PR.noCost$abs.ret, MVshrink.abs.50bps = MVshrink.PR.50bps$abs.ret,
                             MVshrink.rel.noCost = MVshrink.PR.noCost$rel.ret, MVshrink.rel.50bps = MVshrink.PR.50bps$rel.ret)

returns.MV.PR.Wealth <- bind_rows(lapply(names(returns.MV.PR.Wealth), function(name){
  data_frame <- data.frame(value = returns.MV.PR.Wealth[[name]])
  data_frame$Type <- name  # Add the list name as a new column
  return(data_frame)
}))

# Extract `EW`/`RW`, `rel`/`abs`, and `noCost`/`50bps` from the `Type` column
returns.MV.PR.Wealth <- returns.MV.PR.Wealth %>%
  mutate(Strategy = ifelse(grepl("^MVsample", Type), "sample", "shrink"),
         Return_Type = ifelse(grepl("rel", Type), "rel", "abs"),
         Cost = ifelse(grepl("noCost", Type), "noCost", "50bps")
         ) %>%
  select(-Type)  # Remove the original Type column

# Reshape the data to a wide format table
returns.MV.PR.Wealth <- returns.MV.PR.Wealth %>%
  pivot_wider(names_from = Return_Type, values_from = value) %>%
  arrange(Strategy, Cost)

returns.MV.PR.Wealth

```

### 3.4.3 Random Forest Method

#### 3.4.3.1 Long-Only
We start by executing the wealth simulation.

```{r, warning=FALSE}
# Compute Wealth
EW.RF.noCost <- WEALTH.SIMULATION(ret = res.RF.LO$ret.portf.EW$`No costs`$`Monthly Portfolio Return`, init = init)
EW.RF.50bps <- WEALTH.SIMULATION(ret = res.RF.LO$ret.portf.EW$`50bps`$`Monthly Portfolio Return`, init = init)
RW.RF.noCost <- WEALTH.SIMULATION(ret = res.RF.LO$ret.portf.RW$`No costs`$`Monthly Portfolio Return`, init = init)
RW.RF.50bps <- WEALTH.SIMULATION(ret = res.RF.LO$ret.portf.RW$`50bps`$`Monthly Portfolio Return`, init = init)
```

Next, we plot the no cost scenario versus the 50bps TC scenario. Therefore, we first need to extract the out-of-sample dates.

```{r, warning=FALSE}
# Extract out-of-sample dates
date <- index(EW.RF.noCost$Wealth)

# Representation of EW and RW strategy each with noCost and 50bps scenario in one plot
ggplot(EW.RF.noCost$Wealth) +
  geom_line(aes(x=date, y = Wealth, color = "Equal weights Wealth no costs")) +
  geom_line(aes(x=date, y = EW.RF.50bps$Wealth, color = "Equal weights Wealth 50bps")) +
  geom_line(aes(x=date, y = RW.RF.noCost$Wealth, color = "Rank weights Wealth no costs")) +
  geom_line(aes(x=date, y = RW.RF.50bps$Wealth, color = "Rank weights Wealth 50bps")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual("Legend", values = c("Equal weights Wealth no costs" = "blue", "Equal weights Wealth 50bps" = "red",
                                          "Rank weights Wealth no costs" = "skyblue", "Rank weights Wealth 50bps" = "orange")) +
  labs(title = "Wealth Development Long Only Random Forest", x = "Dates", y = "Wealth") +
  theme_minimal()
```

Now let's have a look at the Maximum Drawdowns.

```{r, warning=FALSE}
# Show Maximum Drawdowns
rbind(EquallyWeighted.noCosts = EW.RF.noCost$maxDraw, EquallyWeighted.50bps = EW.RF.50bps$maxDraw,
      RankWeighted.noCosts = RW.RF.noCost$maxDraw, RankWeighted.50bps = RW.RF.50bps$maxDraw)
```

Last but not least, let's compare the absolute and relative returns for the given scenarios

```{r, warning=FALSE}
# Display absolute and relative returns in a table:
returns.RF.Wealth <- list(EW.abs.noCost = EW.RF.noCost$abs.ret, EW.abs.50bps = EW.RF.50bps$abs.ret,
                          EW.rel.noCost = EW.RF.noCost$rel.ret, EW.rel.50bps = EW.RF.50bps$rel.ret,
                          RW.abs.noCost = RW.RF.noCost$abs.ret, RW.abs.50bps = RW.RF.50bps$abs.ret,
                          RW.rel.noCost = RW.RF.noCost$rel.ret, RW.rel.50bps = RW.RF.50bps$rel.ret)

returns.RF.Wealth <- bind_rows(lapply(names(returns.RF.Wealth), function(name){
  data_frame <- data.frame(value = returns.RF.Wealth[[name]])
  data_frame$Type <- name  # Add the list name as a new column
  return(data_frame)
}))

# Extract `EW`/`RW`, `rel`/`abs`, and `noCost`/`50bps` from the `Type` column
returns.RF.Wealth <- returns.RF.Wealth %>%
    mutate(
      Strategy = ifelse(grepl("^EW", Type), "EW", "RW"),
      Return_Type = ifelse(grepl("rel", Type), "rel", "abs"),
      Cost = ifelse(grepl("50bps", Type), "50bps", "noCost")) %>%
  select(-Type)  # Remove the original Type column

# Reshape the data to a wide format table
returns.RF.Wealth <- returns.RF.Wealth %>%
  pivot_wider(names_from = Return_Type, values_from = value) %>%
  arrange(Strategy, Cost)

returns.RF.Wealth

```

#### 3.3.3.2 Long-Short Portfolio
We start by executing the wealth simulation.

```{r, warning=FALSE}
# Compute Wealth
EW.RF.noCost <- WEALTH.SIMULATION(ret = res.RF.L.S$ret.portf.EW$`No costs`$`Monthly Portfolio Return`, init = init)
EW.RF.50bps <- WEALTH.SIMULATION(ret = res.RF.L.S$ret.portf.EW$`50bps`$`Monthly Portfolio Return`, init = init)
RW.RF.noCost <- WEALTH.SIMULATION(ret = res.RF.L.S$ret.portf.RW$`No costs`$`Monthly Portfolio Return`, init = init)
RW.RF.50bps <- WEALTH.SIMULATION(ret = res.RF.L.S$ret.portf.RW$`50bps`$`Monthly Portfolio Return`, init = init)
```

Next, we plot the no cost scenario versus the 50bps TC scenario. Therefore, we first need to extract the out-of-sample dates.

```{r, warning=FALSE}
# Extract out-of-sample dates
date <- index(EW.RF.noCost$Wealth)

# Representation of EW and RW strategy each with noCost and 50bps scenario in one plot
ggplot(EW.RF.noCost$Wealth) +
  geom_line(aes(x=date, y = Wealth, color = "Equal weights Wealth no costs")) +
  geom_line(aes(x=date, y = EW.RF.50bps$Wealth, color = "Equal weights Wealth 50bps")) +
  geom_line(aes(x=date, y = RW.RF.noCost$Wealth, color = "Rank weights Wealth no costs")) +
  geom_line(aes(x=date, y = RW.RF.50bps$Wealth, color = "Rank weights Wealth 50bps")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual("Legend", values = c("Equal weights Wealth no costs" = "blue", "Equal weights Wealth 50bps" = "red",
                                          "Rank weights Wealth no costs" = "skyblue", "Rank weights Wealth 50bps" = "orange")) +
  labs(title = "Wealth Development Long-Short Random Forest", x = "Dates", y = "Wealth") +
  theme_minimal()
```

Now let's have a look at the Maximum Drawdowns.

```{r, warning=FALSE}
# Show Maximum Drawdowns
rbind(EquallyWeighted.noCosts = EW.RF.noCost$maxDraw, EquallyWeighted.50bps = EW.RF.50bps$maxDraw,
      RankWeighted.noCosts = RW.RF.noCost$maxDraw, RankWeighted.50bps = RW.RF.50bps$maxDraw)
```

Last but not least, let's compare the absolute and relative returns for the given scenarios

```{r, warning=FALSE}
# Display absolute and relative returns in a table:
returns.RF.Wealth <- list(EW.abs.noCost = EW.RF.noCost$abs.ret, EW.abs.50bps = EW.RF.50bps$abs.ret,
                          EW.rel.noCost = EW.RF.noCost$rel.ret, EW.rel.50bps = EW.RF.50bps$rel.ret,
                          RW.abs.noCost = RW.RF.noCost$abs.ret, RW.abs.50bps = RW.RF.50bps$abs.ret,
                          RW.rel.noCost = RW.RF.noCost$rel.ret, RW.rel.50bps = RW.RF.50bps$rel.ret)

returns.RF.Wealth <- bind_rows(lapply(names(returns.RF.Wealth), function(name){
  data_frame <- data.frame(value = returns.RF.Wealth[[name]])
  data_frame$Type <- name  # Add the list name as a new column
  return(data_frame)
}))

# Extract `EW`/`RW`, `rel`/`abs`, and `noCost`/`50bps` from the `Type` column
returns.RF.Wealth <- returns.RF.Wealth %>%
    mutate(Strategy = ifelse(grepl("^EW", Type), "EW", "RW"),
           Return_Type = ifelse(grepl("rel", Type), "rel", "abs"),
           Cost = ifelse(grepl("noCost", Type), "noCost", "50bps")
           ) %>%
  select(-Type)  # Remove the original Type column

# Reshape the data to a wide format table
returns.RF.Wealth <- returns.RF.Wealth %>%
  pivot_wider(names_from = Return_Type, values_from = value) %>%
  arrange(Strategy, Cost)

returns.RF.Wealth

```

#### 3.4.3.3 Minimum Variance
We start by executing the wealth simulation.

```{r, warning=FALSE}
# Compute Wealth
MVsample.RF.noCost <- WEALTH.SIMULATION(ret = res.MV.RF$ret.portf.sample$`No costs`$`Monthly Portfolio Return`, init = init)
MVsample.RF.50bps <- WEALTH.SIMULATION(ret = res.MV.RF$ret.portf.sample$`50bps`$`Monthly Portfolio Return`, init = init)
MVshrink.RF.noCost <- WEALTH.SIMULATION(ret = res.MV.RF$ret.portf.shrink$`No costs`$`Monthly Portfolio Return`, init = init)
MVshrink.RF.50bps <- WEALTH.SIMULATION(ret = res.MV.RF$ret.portf.shrink$`50bps`$`Monthly Portfolio Return`, init = init)
```

Next, we plot the no cost scenario versus the 50bps TC scenario. Therefore, we first need to extract the out-of-sample dates.

```{r, warning=FALSE}
# Extract out-of-sample dates
date <- index(MVsample.RF.noCost$Wealth)

# Representation of EW and RW strategy each with noCost and 50bps scenario in one plot
ggplot(MVsample.RF.noCost$Wealth) +
  geom_line(aes(x=date, y = Wealth, color = "Sample MV Wealth no costs")) +
  geom_line(aes(x=date, y = MVsample.RF.50bps$Wealth, color = "Sample MV Wealth 50bps")) +
  geom_line(aes(x=date, y = MVshrink.RF.noCost$Wealth, color = "Shrink MV Wealth no costs")) +
  geom_line(aes(x=date, y = MVshrink.RF.50bps$Wealth, color = "Shrink MV Wealth 50bps")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual("Legend", values = c("Sample MV Wealth no costs" = "blue", "Sample MV Wealth 50bps" = "red",
                                          "Shrink MV Wealth no costs" = "skyblue", "Shrink MV Wealth 50bps" = "orange")) +
  labs(title = "Wealth Development MV Random Forest", x = "Dates", y = "Wealth") +
  theme_minimal()
```

Now let's have a look at the Maximum Drawdowns.

```{r, warning=FALSE}
# Show Maximum Drawdowns
rbind(SampleMV.noCosts = MVsample.RF.noCost$maxDraw, SampleMV.50bps = MVsample.RF.50bps$maxDraw,
      ShrinkMV.noCosts = MVshrink.RF.noCost$maxDraw, ShrinkMV.PR.50bps = MVshrink.RF.50bps$maxDraw)
```

Last but not least, let's compare the absolute and relative returns for the given scenarios

```{r, warning=FALSE}
# Display absolute and relative returns in a table:
returns.MV.RF.Wealth <- list(MVsample.abs.noCost = MVsample.RF.noCost$abs.ret, MVsample.abs.50bps = MVsample.RF.50bps$abs.ret,
                             MVsample.rel.noCost = MVsample.RF.noCost$rel.ret, MVsample.rel.50bps = MVsample.RF.50bps$rel.ret,
                             MVshrink.abs.noCost = MVshrink.RF.noCost$abs.ret, MVshrink.abs.50bps = MVshrink.RF.50bps$abs.ret,
                             MVshrink.rel.noCost = MVshrink.RF.noCost$rel.ret, MVshrink.rel.50bps = MVshrink.RF.50bps$rel.ret)

returns.MV.RF.Wealth <- bind_rows(lapply(names(returns.MV.RF.Wealth), function(name){
  data_frame <- data.frame(value = returns.MV.RF.Wealth[[name]])
  data_frame$Type <- name  # Add the list name as a new column
  return(data_frame)
}))

# Extract `EW`/`RW`, `rel`/`abs`, and `noCost`/`50bps` from the `Type` column
returns.MV.RF.Wealth <- returns.MV.RF.Wealth %>%
  mutate(Strategy = ifelse(grepl("^MVsample", Type), "sample", "shrink"),
         Return_Type = ifelse(grepl("rel", Type), "rel", "abs"),
         Cost = ifelse(grepl("noCost", Type), "noCost", "50bps")
         ) %>%
  select(-Type)  # Remove the original Type column

# Reshape the data to a wide format table
returns.MV.RF.Wealth <- returns.MV.RF.Wealth %>%
  pivot_wider(names_from = Return_Type, values_from = value) %>%
  arrange(Strategy, Cost)

returns.MV.RF.Wealth

```

### 3.4.4 Minimum Variance Raw
We start by executing the wealth simulation.

```{r, warning=FALSE}
# Compute Wealth
MVsample.raw.noCost <- WEALTH.SIMULATION(ret = res.MV.raw$ret.portf.sample$`No costs`$`Monthly Portfolio Return`, init = init)
MVsample.raw.50bps <- WEALTH.SIMULATION(ret = res.MV.raw$ret.portf.sample$`50bps`$`Monthly Portfolio Return`, init = init)
MVshrink.raw.noCost <- WEALTH.SIMULATION(ret = res.MV.raw$ret.portf.shrink$`No costs`$`Monthly Portfolio Return`, init = init)
MVshrink.raw.50bps <- WEALTH.SIMULATION(ret = res.MV.raw$ret.portf.shrink$`50bps`$`Monthly Portfolio Return`, init = init)
```

Next, we plot the no cost scenario versus the 50bps TC scenario. Therefore, we first need to extract the out-of-sample dates.

```{r, warning=FALSE}
# Extract out-of-sample dates
date <- index(MVsample.raw.noCost$Wealth)

# Representation of EW and RW strategy each with noCost and 50bps scenario in one plot
ggplot(MVsample.raw.noCost$Wealth) +
  geom_line(aes(x=date, y = Wealth, color = "Sample MV Wealth no costs")) +
  geom_line(aes(x=date, y = MVsample.raw.50bps$Wealth, color = "Sample MV Wealth 50bps")) +
  geom_line(aes(x=date, y = MVshrink.raw.noCost$Wealth, color = "Shrink MV Wealth no costs")) +
  geom_line(aes(x=date, y = MVshrink.raw.50bps$Wealth, color = "Shrink MV Wealth 50bps")) +
  scale_x_date(labels = date_format("%d-%m-%Y")) +
  scale_color_manual("Legend", values = c("Sample MV Wealth no costs" = "blue", "Sample MV Wealth 50bps" = "red",
                                          "Shrink MV Wealth no costs" = "skyblue", "Shrink MV Wealth 50bps" = "orange")) +
  labs(title = "Wealth Development (Raw) MV All ETFs", x = "Dates", y = "Wealth") +
  theme_minimal()
```

Now let's have a look at the Maximum Drawdowns.

```{r, warning=FALSE}
# Show Maximum Drawdowns
rbind(SampleMV.noCosts = MVsample.raw.noCost$maxDraw, SampleMV.50bps = MVsample.raw.50bps$maxDraw,
      ShrinkMV.noCosts = MVshrink.raw.noCost$maxDraw, ShrinkMV.PR.50bps = MVshrink.raw.50bps$maxDraw)
```

Last but not least, let's compare the absolute and relative returns for the given scenarios

```{r, warning=FALSE}
# Display absolute and relative returns in a table:
returns.MV.raw.Wealth <- list(MVsample.abs.noCost = MVsample.raw.noCost$abs.ret, MVsample.abs.50bps = MVsample.raw.50bps$abs.ret,
                             MVsample.rel.noCost = MVsample.raw.noCost$rel.ret, MVsample.rel.50bps = MVsample.raw.50bps$rel.ret,
                             MVshrink.abs.noCost = MVshrink.raw.noCost$abs.ret, MVshrink.abs.50bps = MVshrink.raw.50bps$abs.ret,
                             MVshrink.rel.noCost = MVshrink.raw.noCost$rel.ret, MVshrink.rel.50bps = MVshrink.raw.50bps$rel.ret)

returns.MV.raw.Wealth <- bind_rows(lapply(names(returns.MV.raw.Wealth), function(name){
  data_frame <- data.frame(value = returns.MV.raw.Wealth[[name]])
  data_frame$Type <- name  # Add the list name as a new column
  return(data_frame)
}))

# Extract `EW`/`RW`, `rel`/`abs`, and `noCost`/`50bps` from the `Type` column
returns.MV.raw.Wealth <- returns.MV.raw.Wealth %>%
  mutate(Strategy = ifelse(grepl("^MVsample", Type), "sample", "shrink"),
         Return_Type = ifelse(grepl("rel", Type), "rel", "abs"),
         Cost = ifelse(grepl("noCost", Type), "noCost", "50bps")
         ) %>%
  select(-Type)  # Remove the original Type column

# Reshape the data to a wide format table
returns.MV.raw.Wealth <- returns.MV.raw.Wealth %>%
  pivot_wider(names_from = Return_Type, values_from = value) %>%
  arrange(Strategy, Cost)

returns.MV.raw.Wealth

```

## 3.5 Robustnesscheck

### 3.5.1 Adaptation of the Forecasting Horizon

```{r, warning=FALSE}

```

### 3.5.2 Adaptation of the Training Data Set

```{r, warning=FALSE}

```

### 3.5.3 Adaptation of the Portfolio Construction Techniques

```{r, warning=FALSE}

```

### 3.5.4 Execution of Input Parameter Combinations
To get a more complete picture regarding the stability against the input parameters we now create a large set of input parameter combinations and analyze the grouped summary statistics more closely. Since running the code again for hundreds of different input combinations means a huge computational effort, we perform this **without** hyperparameter tuning via cross-validation and with 500 trees per forest.

```{r, eval = FALSE}
tune_grid <- NULL
train_control <- trainControl(method = "none")
lookback <-c(5*12,2*12,12)
train.perc <- c(0.5, 0.3, 0.7)
lag <- c(12,3*12,5*12,7*12)
horizon <- c(12,6,1)
limit <- c(NA,4*12, 7*12)
use <- c(0.25,0.5,1)
n.trees <- 500

# Create the combinations
input.grid <- expand.grid(lookback, train.perc, lag, horizon, limit, use)
colnames(input.grid) <- c("lookback", "train.perc", "lag", "horizon", "limit", "use")

# Remove combinations for which the RF predictions can't be computed
input.grid <- filter(input.grid, is.na(limit) | limit - lag >= horizon + 1)
input.grid <- filter(input.grid, round(train.perc*nrow(ret),0) - lag >= horizon + 1)

# Shuffle the table in case you can't have not much time available
input.grid <- input.grid[sample(nrow(input.grid)), ]
# In this case you get a better picture of the impact of different combinations
# Because the combinations are created systematically by columns. 
# Hence, after 20 min or so you might only get a picture of what the impact is, when you differ the combination between lookback and train.perc

# Create list to store the performance results in
results.perf <- vector("list", length = nrow(input.grid))
results.perf <- lapply(1:length(results.perf), function(x){ results.perf[[x]] <- input.grid[x,]})

for(x in 1:nrow(input.grid)){
  
  print(x)
  
  # EXTRACT INPUT PARAMETERS
  tryCatch({lookback <- input.grid$lookback[x]
  train.perc <- input.grid$train.perc[x]
  lag <- input.grid$lag[x]
  horizon <- input.grid$horizon[x]
  limit <- input.grid$limit[x]
  use.long.only <- input.grid$use[x]
  use.long.short <- input.grid$use[x]
  use.long.minvar <- input.grid$use[x]
  
  ###############################################################################################
  # PREVAILING MEAN
  # Initial number of training rows:
  train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
  # All test values:
  y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
  
  mean.ret.mon.all <- NULL
  mean.ret.cum.all <- NULL
  t=1
  
  ## Start predictions:
  while(t<nrow(y_test$y_test)){
    
    res.prev <- PREVAILING.MEAN(ret = ret, horizon = horizon, 
                                train.rows = train.rows, limit = limit, 
                                counter = t, mean.ret.mon.all = mean.ret.mon.all,
                                mean.ret.cum.all = mean.ret.cum.all, 
                                y_test = y_test$y_test)
    
    t <- res.prev$counter
    train.rows <- res.prev$train.rows
    mean.ret.mon.all <- res.prev$mean.ret.mon.all
    mean.ret.cum.all <- res.prev$mean.ret.cum.all
    
  }
  rownames(mean.ret.cum.all) <- c(1:nrow(mean.ret.cum.all))
  eval.pr.mean <- EVAL(y_predictions = mean.ret.mon.all, y_actual = y_test$y_test,
                       y_predictions.cum = mean.ret.cum.all, 
                       y_actual.cum = y_test$y_test.cum)
  eval.pr.mean <- do.call(rbind, eval.pr.mean)
  
  ###############################################################################################
  
  #RANDOM FOREST
  # Initial number of training rows:
  train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
  # Compute EMAs with max. 5 years of data laying back for Macro variables:
  macro.ema <- TRANS.MACRO(data = macro, lookback = lookback)
  # All test values
  y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
  if(!is.null(clusters)){
    print("!!Attention: You set the variable clusters. Don't perform several other (complex) parallel tasks on your machine while the loop is running!!")
  }
  t=1
  
  ## Start predictions:
  while(t<nrow(y_test$y_test)){
    
    input <- Train_DS(ret = ret, macro.ema = macro.ema, train.rows = train.rows, 
                      lag = lag, limit = limit)
    
    res <- RANDOM_FOREST(input = input, horizon = horizon, y_test = y_test,counter =  t, old.forecasts = old.forecasts,
                         cum.perf = cum.perf, tune_grid = tune_grid, train_control = train_control, clusters = clusters, 
                         limit = limit, n.trees = n.trees)
    
    t <- res$counter
    train.rows <- res$train.rows
    old.forecasts <- res$old.forecasts
    cum.perf <- res$cum.perf
    
  }
  ## Extract return predictions:
  monthly.pred <- do.call(cbind, res$old.forecasts)
  cumulative.pred <- do.call(cbind, res$cum.perf)
  
  eval.RF <- EVAL(y_predictions = res$old.forecasts, y_actual = y_test$y_test,
               y_predictions.cum = res$cum.perf, y_actual.cum = y_test$y_test.cum)
  eval.RF <- do.call(rbind, eval.RF)
  
  ###############################################################################################
  
  ###################
  #### BACKTESTS ####
  ###################
  
  
  ###############################################################################################
  # LO PR
  print("LO PR")
  train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
  y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
  counter = 1
  t = 1
  portf.EW.all <- list()
  portf.RW.all <- list()
  all.ret.mon.portf.EW <- NULL
  all.ret.mon.portf.RW <- NULL
  res.PR.LO <- NULL
  
  ## Start the backtest
  while(counter < nrow(y_test$y_test)){
    
    #print(t)
    
    res.PR.LO <- LONG.ONLY(y_test = y_test$y_test, cum.pred = mean.ret.cum.all, use.long.only = use.long.only,
                            counter = counter, t = t, horizon = horizon, portf.EW.all = portf.EW.all, portf.RW.all = portf.RW.all,
                            all.ret.mon.portf.EW = all.ret.mon.portf.EW, all.ret.mon.portf.RW = all.ret.mon.portf.RW, fix.tc = fix.tc,
                            trans.costs = trans.costs, TER.monthly = TER.monthly, res.all = res.PR.LO)
    
    t <- res.PR.LO$t
    counter <- res.PR.LO$counter
    # Extract initial weights
    portf.EW.all <- res.PR.LO$portf.EW.all
    portf.RW.all <- res.PR.LO$portf.RW.all
    # All other performance results
    all.ret.mon.portf.EW <- res.PR.LO$ret.portf.EW$`No costs`$`Monthly Portfolio Return`
    all.ret.mon.portf.RW <- res.PR.LO$ret.portf.RW$`No costs`$`Monthly Portfolio Return`
  }
  
  ## Summary statistics:
  # EW:
  stat.EW.L.O.PR <- STATISTICS(res = res.PR.LO$ret.portf.EW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  # RW:
  stat.RW.L.O.PR <- STATISTICS(res = res.PR.LO$ret.portf.RW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  LO.PR <- list(Equally.Weighted.L.O = stat.EW.L.O.PR, Rank.Weighted.L.O = stat.RW.L.O.PR)
  
  ###############################################################################################
  
  # LO RF
  print("LO RF")
  train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
  y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
  counter = 1
  t = 1
  portf.EW.all <- list()
  portf.RW.all <- list()
  all.ret.mon.portf.EW <- NULL
  all.ret.mon.portf.RW <- NULL
  res.RF.LO <- NULL
  cumulative.pred <- as.matrix(cumulative.pred)
  colnames(cumulative.pred) <- colnames(mean.ret.cum.all)
  
  ## Start the backtest
  while(counter < nrow(y_test$y_test)){
    
    #print(t)
    
    res.RF.LO <- LONG.ONLY(y_test = y_test$y_test, cum.pred = cumulative.pred, use.long.only = use.long.only,
                            counter = counter, t = t, horizon = horizon, portf.EW.all = portf.EW.all, portf.RW.all = portf.RW.all,
                            all.ret.mon.portf.EW = all.ret.mon.portf.EW, all.ret.mon.portf.RW = all.ret.mon.portf.RW, fix.tc = fix.tc, 
                            trans.costs = trans.costs, TER.monthly = TER.monthly, res.all = res.RF.LO)
    
    t <- res.RF.LO$t
    counter <- res.RF.LO$counter
    # Extract initial weights
    portf.EW.all <- res.RF.LO$portf.EW.all
    portf.RW.all <- res.RF.LO$portf.RW.all
    # All other performance results
    all.ret.mon.portf.EW <- res.RF.LO$ret.portf.EW$`No costs`$`Monthly Portfolio Return`
    all.ret.mon.portf.RW <- res.RF.LO$ret.portf.RW$`No costs`$`Monthly Portfolio Return`
  }
  
  ## Summary statistics:
  # EW:
  stat.EW.LO.RF <- STATISTICS(res = res.RF.LO$ret.portf.EW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  # RW:
  stat.RW.LO.RF <- STATISTICS(res = res.RF.LO$ret.portf.RW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  LO.RF <- list(Equally.Weighted.L.O = stat.EW.LO.RF, Rank.Weighted.L.O = stat.RW.LO.RF)
  
  ###############################################################################################
  
  # LS PR
  print("LS PR")
  train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
  y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
  counter = 1
  t = 1
  portf.EW.all <- list()
  portf.RW.all <- list()
  all.ret.mon.portf.EW <- NULL
  all.ret.mon.portf.RW <- NULL
  res.PR.L.S <- NULL
  
  while(counter < nrow(y_test$y_test)){
    
    #print(t)
    
    res.PR.L.S <- LONG.SHORT(y_test = y_test$y_test, cum.pred = mean.ret.cum.all, disc.positive = disc.positive, use.long.short = use.long.short, 
                             lend = lend, counter = counter, t = t, horizon = horizon, portf.EW.all = portf.EW.all, portf.RW.all = portf.RW.all,
                             all.ret.mon.portf.EW = all.ret.mon.portf.EW, all.ret.mon.portf.RW = all.ret.mon.portf.RW, fix.tc = fix.tc,
                             trans.costs = trans.costs, TER.monthly = TER.monthly, res.all = res.PR.L.S)
    
    t <- res.PR.L.S$t
    counter <- res.PR.L.S$counter
    # Extract initial weights
    portf.EW.all <- res.PR.L.S$portf.EW.all
    portf.RW.all <- res.PR.L.S$portf.RW.all
    # All other performance results
    all.ret.mon.portf.EW <- res.PR.L.S$ret.portf.EW$`No costs`$`Monthly Portfolio Return`
    all.ret.mon.portf.RW <- res.PR.L.S$ret.portf.RW$`No costs`$`Monthly Portfolio Return`
  }
  
  ## Summary statistics:
  # EW:
  stat.EW.L.S.PR <- STATISTICS(res = res.PR.L.S$ret.portf.EW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  # RW:
  stat.RW.L.S.PR <- STATISTICS(res = res.PR.L.S$ret.portf.RW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  LS.PR <- list(Equally.Weighted.L.S = stat.EW.L.S.PR, Rank.Weighted.L.S = stat.RW.L.S.PR)
  
  ###############################################################################################
  
  # LS RF
  print("LS RF")
  train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
  y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
  counter = 1
  t = 1
  portf.EW.all <- list()
  portf.RW.all <- list()
  all.ret.mon.portf.EW <- NULL
  all.ret.mon.portf.RW <- NULL
  res.RF.L.S <- NULL
  cumulative.pred <- as.matrix(cumulative.pred)
  colnames(cumulative.pred) <- colnames(mean.ret.cum.all)
  
  while(counter < nrow(y_test$y_test)){
    
    #print(t)
    
    res.RF.L.S <- LONG.SHORT(y_test = y_test$y_test, cum.pred = cumulative.pred, use.long.short = use.long.short, lend = lend,
                             counter = counter, t = t, horizon = horizon, portf.EW.all = portf.EW.all, portf.RW.all = portf.RW.all,
                             all.ret.mon.portf.EW = all.ret.mon.portf.EW, all.ret.mon.portf.RW = all.ret.mon.portf.RW, fix.tc = fix.tc,
                             trans.costs = trans.costs, TER.monthly = TER.monthly, res.all = res.RF.L.S)
    
    t <- res.RF.L.S$t
    counter <- res.RF.L.S$counter
    # Extract initial weights
    portf.EW.all <- res.RF.L.S$portf.EW.all
    portf.RW.all <- res.RF.L.S$portf.RW.all
    # All other performance results
    all.ret.mon.portf.EW <- res.RF.L.S$ret.portf.EW$`No costs`$`Monthly Portfolio Return`
    all.ret.mon.portf.RW <- res.RF.L.S$ret.portf.RW$`No costs`$`Monthly Portfolio Return`
  }
  
  ## Summary statistics:
  # EW:
  stat.EW.L.S.RF <- STATISTICS(res = res.RF.L.S$ret.portf.EW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  # RW:
  stat.RW.L.S.RF <- STATISTICS(res = res.RF.L.S$ret.portf.RW, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  LS.RF <- list(Equally.Weighted.L.S = stat.EW.L.S.RF, Rank.Weighted.L.S = stat.RW.L.S.RF)
  
  ###############################################################################################
  
  # MV PR
  print("MV PR")
  train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
  y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
  counter = 1
  t = 1
  portf.sample.all <- list()
  portf.shrink.all <- list()
  all.ret.mon.portf.sample <- NULL
  all.ret.mon.portf.shrink <- NULL
  res.MV.PR <- NULL
  
  while(counter < nrow(y_test$y_test)){
    
    #print(t)
    
    res.MV.PR <- MIN.VAR(ret = ret, train.rows = train.rows, y_test = y_test$y_test, cum.pred = mean.ret.cum.all,
                         use.minvar = use.minvar, counter = counter, t = t, horizon = horizon,
                         portf.shrink.all = portf.shrink.all, portf.sample.all = portf.sample.all,trans.costs = trans.costs, 
                         TER.monthly = TER.monthly, all.ret.mon.portf.shrink = all.ret.mon.portf.shrink,
                         all.ret.mon.portf.sample = all.ret.mon.portf.sample, limit = limit, fix.tc = fix.tc, 
                         min.max = min.max, res.all = res.MV.PR)
    
    train.rows <- res.MV.PR$train.rows
    t <- res.MV.PR$t
    counter <- res.MV.PR$counter
    # Extract initial weights
    portf.sample.all <- res.MV.PR$portf.sample.all
    portf.shrink.all <- res.MV.PR$portf.shrink.all
    # All other performance results
    all.ret.mon.portf.sample<- res.MV.PR$ret.portf.sample$`No costs`$`Monthly Portfolio Return`
    all.ret.mon.portf.shrink <- res.MV.PR$ret.portf.shrink$`No costs`$`Monthly Portfolio Return`
  }
  
  ## Summary statistics:
  # EW:
  stat.MV.sample.PR <- STATISTICS(res = res.MV.PR$ret.portf.sample, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  # RW:
  stat.MV.shrink.PR <- STATISTICS(res = res.MV.PR$ret.portf.shrink, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  MV.PR <- list(sample.MV = stat.MV.sample.PR, shrink.MV = stat.MV.shrink.PR)
  
  
  ###############################################################################################
  
  # MV RF
  print("MV RF")
  train.rows <- Train.Rows(ret = ret, train.perc = train.perc)
  y_test <- Test_DS(ret = ret, train.rows = train.rows, horizon = horizon)
  counter = 1
  t = 1
  portf.sample.all <- list()
  portf.shrink.all <- list()
  all.ret.mon.portf.sample <- NULL
  all.ret.mon.portf.shrink <- NULL
  res.MV.RF <- NULL
  cumulative.pred <- as.matrix(cumulative.pred)
  colnames(cumulative.pred) <- colnames(mean.ret.cum.all)
  
  while(counter < nrow(y_test$y_test)){
    
    #print(t)
    
    res.MV.RF <- MIN.VAR(ret = ret, train.rows = train.rows, y_test = y_test$y_test, cum.pred = cumulative.pred, 
                         use.minvar = use.minvar, counter = counter, t = t, horizon = horizon,
                         portf.shrink.all = portf.shrink.all, portf.sample.all = portf.sample.all,
                         trans.costs = trans.costs, TER.monthly = TER.monthly, all.ret.mon.portf.shrink = all.ret.mon.portf.shrink,
                         all.ret.mon.portf.sample = all.ret.mon.portf.sample, limit = limit, fix.tc = fix.tc, min.max = min.max, 
                         res.all = res.MV.RF)
    
    train.rows <- res.MV.RF$train.rows
    t <- res.MV.RF$t
    counter <- res.MV.RF$counter
    # Extract initial weights
    portf.sample.all <- res.MV.RF$portf.sample.all
    portf.shrink.all <- res.MV.RF$portf.shrink.all
    # All other performance results
    all.ret.mon.portf.sample<- res.MV.RF$ret.portf.sample$`No costs`$`Monthly Portfolio Return`
    all.ret.mon.portf.shrink <- res.MV.RF$ret.portf.shrink$`No costs`$`Monthly Portfolio Return`
  }
  
  ## Summary statistics:
  # EW:
  stat.MV.sample.RF <- STATISTICS(res = res.MV.RF$ret.portf.sample, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  # RW:
  stat.MV.shrink.RF <- STATISTICS(res = res.MV.RF$ret.portf.shrink, RF = rf, VaR.CI = VaR.CI, horizon = horizon, trans.costs = trans.costs)
  MV.RF <- list(sample.MV = stat.MV.sample.RF, shrink.MV = stat.MV.shrink.RF)
  
  ###############################################################################################
  
  
  #######################
  #### STORE RESULTS ####
  #######################
  
  
  ###############################################################################################
  
  results.perf[[x]] <- list(eval.PR = eval.pr.mean, eval.RF = eval.RF, # Prediction model results
                            LO.PR = LO.PR, LO.RF = LO.RF,
                            LS.PR = LS.PR, LS.RF = LS.RF,
                            MV.PR = MV.PR, MV.RF = MV.RF)
  results.perf[[x]] <- append(list(input.grid[x,]), results.perf[[x]])
  
  saveRDS(results.perf, file = "C:/Users/Berger/Documents/Studium/Master/5. Semester/Masterarbeit/Ergebnisse/Robustness Checks/results.perf.rds")
  }, 
  
  error = function(e){
    message("Error encountered in iteration ", x, ": ", e$message)
  })
}

#saveRDS(results.perf, file = "C:/Users/Berger/Documents/Studium/Master/5. Semester/Masterarbeit/Ergebnisse/Robustness Checks/results.perf.rds")
#x=180

#results.perf <- readRDS("C:/Users/Berger/Documents/Studium/Master/5. Semester/Masterarbeit/Ergebnisse/Robustness Checks/results.perf.rds")


results.LO <- do.call(rbind, lapply(1:length(results.perf), function(x){
  c(ifelse(is.null(results.perf[[x]]$LO.PR$Equally.Weighted.L.O[1,1]), NA, results.perf[[x]]$LO.PR$Equally.Weighted.L.O[1,1]),
    ifelse(is.null(results.perf[[x]]$LO.RF$Equally.Weighted.L.O[1,1]), NA, results.perf[[x]]$LO.RF$Equally.Weighted.L.O[1,1]),
    ifelse(is.null(results.perf[[x]]$LO.PR$Rank.Weighted.L.O[1,1]), NA, results.perf[[x]]$LO.PR$Rank.Weighted.L.O[1,1]),
    ifelse(is.null(results.perf[[x]]$LO.RF$Rank.Weighted.L.O[1,1]), NA, results.perf[[x]]$LO.RF$Rank.Weighted.L.O[1,1]))
  })
)

inputs <- do.call(rbind, lapply(results.perf, function(x) {
  if (is.data.frame(x)) {
    return(x)
  } else {
    return(x[[1]])
  }
}))

results.LO <- cbind(results.LO, inputs)

colnames(results.LO) <- c("LO.PR.EQ", "LO.RF.EQ", "LO.PR.RW", "LO.RF.RW", "lookback", "train.perc", "lag", "horizon", "limit", "use")


results.LO[which(as.numeric(results.LO$LO.RF.RW) > as.numeric(results.LO$LO.PR.RW)),]

which(as.numeric(results.LO$LO.RF.EW) > as.numeric(results.LO$LO.PR.EW))

results.LO[,-c(5,7,9,10)] %>%
  group_by(horizon) %>%
  summarize(mean.LO.PR.EQ = mean(as.numeric(LO.PR.EQ), na.rm = T),
            mean.LO.RF.EQ = mean(as.numeric(LO.RF.EQ), na.rm = T),
            mean.LO.PR.RW = mean(as.numeric(LO.PR.RW), na.rm = T),
            mean.LO.RF.RW = mean(as.numeric(LO.RF.RW), na.rm = T))
```

# IV. Extract Tables and Figures
**!!Note for this complete chapter: The paths where you're saving the .xlsx-files to needs to be adjusted properly!!**

## 4.1 Data

### 4.1.1 Clean Data Sets

```{r, warning=FALSE, eval=FALSE}
# Monthly RIs:
write.xlsx(as.data.frame(ETFs.mon), file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Daten\\Bereinigt", "ETFs monthly.xlsx"), colNames = T, rowNames = T)

# Monthly Returns:
write.xlsx(as.data.frame(Ret), file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Daten\\Bereinigt", "Returns monthly.xlsx"), colNames = T, rowNames = T)

# Lagged Returns:
write.xlsx(Ret.LAG, file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Daten\\Bereinigt", "Lagged Returns monthly.xlsx"), colNames = T, rowNames = T)

# Cumulative Returns:
write.xlsx(CUM.ret, file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Daten\\Bereinigt", "Cumulative Returns monthly.xlsx"), colNames = T, rowNames = T)

# Macros:
write.xlsx(as.data.frame(Macro), file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Daten\\Bereinigt", "Macros monthly.xlsx"), colNames = T, rowNames = T)

```

### 4.1.2 Descriptive Statistics

#### 4.1.2.1 General Summary and Outliers (Compare section 2.3.1)

**1. Return Data:**

```{r, warning=FALSE, eval=FALSE}
# Save table as .xlsx-file
write.xlsx(as.data.frame(Ret.overview)[,-1], file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Deskriptive Statistiken", "Base Statistics ETFs.xlsx"), colNames = T, rowNames = T)
Ret.overview
```

**2. Macro Data:**

```{r, warning=FALSE, eval=FALSE}
# Save table as .xlsx-file:
write.xlsx(as.data.frame(Macro.overview)[,-1], file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Deskriptive Statistiken", "Base Statistics Macros.xlsx"), colNames = T, rowNames = T)
head(Macro.overview)
```

#### 4.1.2.2 Time Series Analysis

**1. Return and ETF Data:**

```{r, warning=FALSE, eval=FALSE}
# Store the time series summary in the desired folder:
write.xlsx(TSret.overview, file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Deskriptive Statistiken", "TS summary Returns.xlsx"), colNames = T, rowNames = T)

# Save the time series summary in the desired folder:
write.xlsx(TStotalri.overview, file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Deskriptive Statistiken", "TS summary ETFs.xlsx"), colNames = T, rowNames = T)
```

**2. Macro Data:**

```{r, warning=FALSE, eval=FALSE}
# Save the TSmacro.overview table in the desired folder:
write.xlsx(TSmacro.overview, file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Deskriptive Statistiken", "TS summary Macro.xlsx"), colNames = T, row.names = T)
```

#### 4.1.2.3 Distribution of Returns

```{r, warning=FALSE, eval=FALSE}
# Save the table in the desired folder:
write.xlsx(as.data.frame(stats), file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Deskriptive Statistiken", "Skewness and Kurtosis.xlsx"), colNames = T, rowNames = T)
```

## 4.2 Return Predictions

### 4.2.1 Prevailing Mean

```{r warning=FALSE, eval=FALSE}
# Monthly Predictions:
write.xlsx(as.data.frame(mean.ret.mon.all), file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Prevailing Mean Vorhersagen", paste("Monthly", ifelse(all(ret == log(Ret[,-1]+1), na.rm = T)==T, "Log-", ""), "Return Predictions with lag", lag/12, "years, limit", ifelse(is.na(limit), 0, limit), "and horizon", horizon, ".xlsx")), colNames = T, rowNames = T)

# Cumulative Predictions:
write.xlsx(as.data.frame(mean.ret.cum.all), file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Prevailing Mean Vorhersagen", paste("Cumulative", ifelse(all(ret == log(Ret[,-1]+1), na.rm = T)==T, "Log-", ""), "Return Predictions with lag", lag/12, "years, limit", ifelse(is.na(limit), 0, limit), "and horizon", horizon, ".xlsx")), colNames = T, rowNames = T)

# Evaluation:
write.xlsx(as.data.frame(eval.pr.mean), file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Prevailing Mean Vorhersagen", paste("Evaluation of", ifelse(all(ret == log(Ret[,-1]+1), na.rm = T)==T, "Log-", ""), "Predictions with lag", lag/12, "years, limit", ifelse(is.na(limit), 0, limit), "and horizon", horizon, ".xlsx")), colNames = T, rowNames = T)
```

### 4.2.2 Random Forest

```{r, warning=FALSE, eval=FALSE}
# Monthly Predictions:
write.xlsx(as.data.frame(monthly.pred), file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Random Forest Vorhersagen", paste("Monthly", ifelse(all(ret == log(Ret[,-1]+1), na.rm = T)==T, "Log-", ""), "RF Return Predictions with lag", lag/12, "years, limit", ifelse(is.na(limit), 0, limit), ", horizon", horizon, ",", ifelse(is.null(tune_grid), "without hyperparameter tuning", "with hyperparameter tuning"), "and", ifelse(train_control$method == "none", "without cross-validation", "with cross-validation"), "equity only).xlsx")), colNames = T, rowNames = T)

# Cumulative Predictions:
write.xlsx(as.data.frame(cumulative.pred), file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Random Forest Vorhersagen", paste("Cumulative", ifelse(all(ret == log(Ret[,-1]+1), na.rm = T)==T, "Log-", ""), "RF Return Predictions with lag", lag/12, "years, limit", ifelse(is.na(limit), 0, limit),  ", horizon", horizon, ",", ifelse(is.null(tune_grid), "without hyperparameter tuning", "with hyperparameter tuning"), "and", ifelse(train_control$method == "none", "without cross-validation", "with cross-validation"), ".xlsx")), colNames = T, rowNames = T)

# Evaluation:
write.xlsx(as.data.frame(eval), file.path("C:\\Users\\Berger\\Documents\\Studium\\Master\\5. Semester\\Masterarbeit\\Ergebnisse\\Random Forest Vorhersagen", paste("Evaluation of RF", ifelse(all(ret == log(Ret[,-1]+1), na.rm = T)==T, "Log-", ""), "Predictions with lag", lag/12, "years, limit", ifelse(is.na(limit), 0, limit), ", horizon", horizon, ",", ifelse(is.null(tune_grid), "without hyperparameter tuning", "with hyperparameter tuning"), "and", ifelse(train_control$method == "none", "without cross-validation", "with cross-validation"), ".xlsx")), colNames = T, rowNames = T)
```

## 4.3 Backtests

```{r, warning=FALSE, eval=FALSE}

```

## 4.4 Wealth Development Simulations

```{r, warning=FALSE, eval=FALSE}

```

## 4.5 Robusnesscheck

```{r, warning=FALSE, eval=FALSE}

```

# V. Import Result Tables
If complex and computationally intensive computations (like the Random Forest with hyperparameter tuning and/or cross-validation) want to be avoided, the results of these computations can be imported in this chapter. Obviously, for this to work you need to have saved the resulting tables somewhere on your machine.

## 5.1 Random Forest Prediction
Before you run the code, check if the resulting tables for predicted returns and accuracy measures are already available. If results are available, you can import them with the next chunk.

```{r warning=FALSE, eval=FALSE}
# Set the path name where the results are stored:
path <- "C:/Users/Berger/Documents/Studium/Master/5. Semester/Masterarbeit/Ergebnisse/Random Forest Vorhersagen/"

# Monthly predictions
monthly.pred <- read.xlsx(paste0(path, "Monthly  RF Return Predictions with lag 4 years, limit 84 , horizon 12 , with hyperparameter tuning and with cross-validation .xlsx"), sheet = 1)[,-1]

# Cumulative predictions (over the investing horizon)
cumulative.pred <- read.xlsx(paste0(path, "Cumulative  RF Return Predictions with lag 4 years, limit 84 , horizon 12 , with hyperparameter tuning and with cross-validation .xlsx"), sheet = 1)[,-1]

# Accuracy measures
eval <- read.xlsx(paste0(path, "Evaluation of RF  Predictions with lag 4 years, limit 84 , horizon 12 , with hyperparameter tuning and with cross-validation .xlsx"), sheet = 1)
rownames(eval) <- eval[,1]
eval <- eval[,-1]
```

*Note: Pay attention that the path and file names for the tables are set correctly!*

## 5.2 Robusnesschecks Input Parameters

```{r warning=FALSE, eval=FALSE}
path <- "C:/Users/Berger/Documents/Studium/Master/5. Semester/Masterarbeit/Ergebnisse/Robustness Checks/"

results.perf <- read.xlsx(paste0(path, "Input Parameters Test Long Only.xlsx"), sheet = 1)[,-1]
```







